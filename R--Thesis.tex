% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  11pt,
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmainfont[]{Helvetica}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[left=35mm, right=20mm, top=30mm, bottom=30mm]{geometry}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{setspace}
\doublespacing
\usepackage{fancyhdr}
\pagestyle{fancy}
\renewcommand{\headrulewidth}{1.5pt}
\setlength{\headheight}{25.66263pt}
\renewcommand{\href}[2]{#2\footnote{\url{#1}}}
\usepackage{pdflscape}
\newcommand{\blandscape}{\begin{landscape}}
\newcommand{\elandscape}{\end{landscape}}
\usepackage{titlesec}
\titlespacing{\section}{0pt}{12pt plus 2pt minus 1pt}{0pt plus 1pt minus 1pt}
\titlespacing{\subsection}{0pt}{12pt plus 2pt minus 1pt}{0pt plus 1pt minus 1pt}
\titlespacing{\subsubsection}{0pt}{12pt plus 2pt minus 1pt}{0pt plus 1pt minus 1pt}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}

\author{}
\date{\vspace{-2.5em}}

\begin{document}

{
\setcounter{tocdepth}{4}
\tableofcontents
}
\newpage

\hypertarget{chapter-1}{%
\section{Chapter 1}\label{chapter-1}}

\hypertarget{lit-review}{%
\subsection{Lit Review}\label{lit-review}}

Hamilton and Geraci (2006)

IMPLICIT MEMORY: PSE results from conceptual processing of a picture's
distinctive features (rather than semantic information). General
semantic task: ``What is a used car sometimes called?'' No PSE.
Distinctive conceptual information task: ``What fruit is egg shaped?''
PSE.

EXPLICIT RECOGNITION: PSE always evident?

aMCI Show larger PSE effects than controls.

Impaired REC, so this PSE must rely on FAM?

Mixed findings whether fam is intact in aMCI. Intact - generally use
picture stim. Impaired - generally use verbal stim.

Is PSE in aMCI driven by intact FAM for pictures, but impaired FAM for
words? Yes (Embree, Budson, \& Ally, 2012): aMCI - Picture FAM - same as
healthy OAs aMCI - Word FAM - impaired compared to healthy OAs

Ally, McKeever, 2009: Examined early frontal old/new effect (FAM) in
aMCI: Intact for pictures. Impaired for words. BUT, P did not provide
subjective Rec/Fam reports.

Embree, Budson, \& Ally, 2012: Deep encoding (verbal like/dislike
response). Modified Old/New (6-point rating scale): 6. Certain the item
is old - to - 1. Certain the item is new.

Both used the same picture stim - colour photos.

\#\#\#----------------------------------------

\newpage

\hypertarget{chapter-2}{%
\section{Chapter 2}\label{chapter-2}}

Dual-process theories of recognition memory suggest that two independent
processes - recollection and familiarity - are implicated in the
successful recognition of previously encountered material (Paivio, 1971,
1972). Recollection typically refers to the conscious recall of encoded
information, whereby contextual details (usually obtained by mentally
re-experiencing a previous encounter with the stimulus) facilitate
successful recognition. Familiarity, on the other hand, describes the
unsubstantiated \emph{feeling} of having encountered the stimulus
before, and despite the inability to retrieve any associated diagnostic
information, is still able to produce accurate recognition (Schoemaker,
Gauthier, \& Pruessner, 2014). While single-process accounts of
recognition memory have been proposed, with the view that such
experiences can be understood simply as varying levels of memory
strength (Dunn, 2008; Squire, Wixted, \& Clark, 2007), the majority of
memory researchers agree that multiple processes are necessary to
account for a range of dissociable experimental findings (Yonelinas,
2002). Evidence from studies utilising event related potentials (ERPs;
Curran \& Doyle, 2011), functional magnetic resonance imaging (fMRI;
Scalici, Caltagirone, \& Carlesimo, 2017) and comparisons between
healthy and clinical subject groups (e.g.~Mild Cognitive Impairment;
Belleville, Ménard, \& Lepage, 2011) all implicate the existence of two
functionally distinct processes. Despite this consensus, disagreement
persists in the literature regarding the extent to which recollection
and familiarity are independent, and the methods that should be used to
measure them most effectively (Schoemaker et al., 2014; Yonelinas,
2002).

Experiments into recognition memory often focus on obtaining separate
estimates of recollection and familiarity using process-estimation
methods (Yonelinas, 2002). The most commonly used process-estimation
method is the Remember/Know (RK) paradigm (Tulving, 1985) - a task
endorsed by a wide body of literature (Gardiner, 2000; Jacoby, 1991;
Jacoby, Yonelinas, \& Jennings, 1997; Andrew P Yonelinas \& Jacoby,
1995). In a typical RK procedure, participants are generally tasked with
making `old' vs.~`new' recognition decisions toward a randomised list of
items, many of which were presented during an earlier encoding phase
(targets) amongst novel items with highly similar characteristics
(lures). When a subject recognises an item, and thus selects \emph{old},
a follow-up judgement probes how they arrived at this decision
(\emph{remember} or \emph{know}). If the subject was able to recognise
the item based on recollection (i.e.~conscious recall of some diagnostic
information: ``I remember seeing this item earlier''), they should
classify their recognition as \emph{remember}. If the subject arrived at
their recognition decision due to familiarity (i.e.~a feeling of
certainty that the item was studied in the encoding phase, but unable to
recall and details: ``I know I saw this item earlier, but cannot
determine why''), they should classify their recognition as
\emph{familiarity}.

The RK procedure has been modified in a number of ways since its
conception to adapt to evolving understandings of recollection and
familiarity processes. An early development was the ``independence
correction'' - a formula devised to `correct' the inherent
underestimation of familiarity responses within the paradigm (A. P.
Yonelinas \& Jacoby, 1995). Participants are generally only instructed
to select \emph{know} in the absence of recollection, an approach that
does not allow for the co-occurrence of recollection and familiarity;
proportions of \emph{know} responses are likely to be lower than
\emph{remember} if subjects perceive to experience both processes
simultaneously, since the presence of recollection necessitates that
they select \emph{remember}. A. P. Yonelinas \& Jacoby (1995) 's
independence correction estimates familiarity processes by also taking
into account the number of \emph{remember} responses (Schoemaker et al.,
2014).

More recently, many adaptations of the RK paradigm also include a
`Guess' option to allow for uncertainty (\emph{Remember/Know/Guess}), in
an effort to avoid biasing the total number of R and K responses
(Belleville et al., 2011; Eldridge, Sarfatti, \& Knowlton, 2002;
Gardiner \& Ramponi, 1998; Gardiner, Ramponi, \& Richardson-Klavehn,
2002; Tunney \& Fernie, 2007; Williams, Conway, \& Moulin, 2013;
Williams \& Moulin, 2014).

Others have allowed for the co-occurrence of recollection and
familiarity processes by also provided participants with a `Both'
response option (\emph{Remember/Know/Both} or
\emph{Recollection/Familiarity/Both}).

The RK procedure has been criticized for its reliance on participants'
subjective understanding of the provided instructions (Schoemaker et
al., 2014), and the introspective nature of recognition judgements make
it difficult to confirm whether all participants have understood the
definitions (and thus responded) similarly (Lombardi, Perri, Fadda,
Caltagirone, \& Carlesimo, 2016). Indeed, slight differences in the
experimental definition of ``knowing'' across studies and the way in
which the subjective memory states are defined may affect the achieved
pattern of results (Geraci, McCabe, \& Guillory, 2009; Williams \&
Moulin, 2014).

A large body of literature also reports that the RK procedure produces
reliable estimations of recollection and familiarity in clinical
populations (Lombardi et al., 2016); for example, those with Mild
Cognitive Impairment (MCI) typically show recollection impairments but
intact familiarity compared to healthy older adults (Belleville et al.,
2011; Hudon, Belleville, \& Gauthier, 2009; Lombardi et al., 2016; Serra
et al., 2010; L. Wang et al., 2013).

A second method of measurement is to ask participants to make confidence
judgements or ratings and interpret high confidence as indicating
recollection and low confidence as indicating familiarity. Instead of
confidence, some researchers ask participants to make specific ratings
of the amount of recollection and familiarity they have for each item
they recognise on the memory test; here, rather than a binary
Remember-Know judgement which means that the processes of recollection
and familiarity are seen as mutually exclusive, in this method
recollection and familiarity are viewed as processes that can occur
conjointly.

The objective of my research is to better understand what these
different methodologies can tell us about the underlying processes of
recollection and familiarity. In order to achieve this objective my
proposed research will compare different methodologies against each
other in different ways:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  How to define the response options to participants: The way the `Know'
  response is defined to participants can differ across researchers --
  some emphasise a feeling of `just knowing' or `certainty', whereas
  other labs use definitions that emphasise a `feeling of familiarity'.
  I want to know whether how we are defining `Knowing' to participants
  when we use Remember-Know recognition tests changes how they use the
  response options.
\item
  Are ratings tasks better than judgement tasks: Recollection and
  familiarity or confidence ratings allow for a more fine-grained
  examination of memory processes but perhaps they are more complicated
  for participants to use and perhaps they are no more `accurate' than
  more standard RK judgement tasks? I want to examine how patterns of
  responding differ across these methodologies.
\end{enumerate}

In addition to the availability of different response options, there is
evidence to suggest that the format of to-be-remembered stimuli

The picture superiority effect (PSE) -- stimuli presented as pictures
are markedly better remembered on tests of recall or recognition than
stimuli presented as words (Shepard, 1967).

The magnitude of the PSE is greater in aMCI and AD patients when
compared to healthy older (Embree, Budson, \& Ally, 2012). Understanding
this phenomenon helps to conceptualise how memory breaks down in AD.

Studies agree that pictures enhance recollection compared to words in
healthy younger and older adults: Ally \& Budson (2007); Ally et
al.~(2008); Curran \& Doyle (2011); Rajaram (1996). However, it has been
demonstrated that certain methodological factors can mediate the PSE, at
least in certain populations; findings generally show intact familiarity
for individuals with aMCI when \emph{pictures} are shown during
recognition memory paradigm, but impaired familiarity when word stimuli
are utilised (Algarabel et al., 2009; Ally et al., 2009a, 2009b;
Anderson et al., 2008; Embree, Budson, \& Ally, 2012; Hudon et al.,
2009; O'Connor \& Ally, 2010; Serra et al., 2010; Westerberg et al.,
2006; Wolk, Signoff, \& DeKosky, 2008).

The objective of Experiment 1 was to establish baseline PSE response
patterns in younger adults, and examine how PSE magnitudes differ across
the three response option conditions (RF-judgements / RFB-judgements /
RF-Ratings). A 2x3 mixed factorial design was utilised, consisting of a
within-subjects variable of stimulus type (words / greyscale
line-drawings) and a between-subjects variable of response option
(RF-judgements / RFBG-judgements / RF-Ratings).

To determine whether a PSE is evident in the current paradigm, \emph{d'}
(d-prime) scores will be calculated for each participant. \emph{d'} is a
signal detection statistic, calculated by taking the standardised
difference between the signal (i.e.~correct hits) and signal+noise
(i.e.~false alarms); in other words, \emph{d'} offers a representation
of participants' ability to distinguish target items from lures (Wixted,
2014). A \emph{d'} score of

{[}see Appendix A for \emph{d'} formula{]}.

Within the currently proposed paradigm, the following results are
hypothesised:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A PSE will be evident, manifesting as higher overall \emph{d'} scores
  for pictures compared to words.

  \begin{itemize}
  \tightlist
  \item
    A PSE is also expected to manifest as i) a higher proportion of
    correct hits, ii) lower proportion of false alarms, and iii) better
    overall recognition.
  \end{itemize}
\item
  Similar PSEs will be evident regardless of the response-options
  available at test (RFG, RFBG, RF-Ratings).

  \begin{itemize}
  \tightlist
  \item
    There will be a higher proportion of hits assigned Recollection for
    pictures, compared to words.
  \item
    There will be a higher proportion of hits assigned Familiarity for
    words, compared to pictures.
  \end{itemize}
\item
  XXXXXX condition may over or under-estimate recollection in comparison
  to XXXXXX condition.
\end{enumerate}

\hypertarget{experiment-proof-of-concept}{%
\subsection{Experiment: Proof of
concept}\label{experiment-proof-of-concept}}

\hypertarget{method}{%
\subsubsection{Method}\label{method}}

\hypertarget{participants}{%
\paragraph{Participants}\label{participants}}

A total of 186 subjects completed the online experiment (\emph{M} = 26.7
years (\emph{SD} = 10.36 years; see Table 1 for a comprehensive
breakdown of the sample). The current sample was primarily comprised of
participants sourced from voluntary participation websites such as
Prolific Academic\footnote{\url{https://www.prolific.co/}} (52.15\%)
(where they received payment at the rate of £5/hr) and via the in-school
research participation system\footnote{\url{https://keelepsychology.sona-systems.com/}}
(where they received course participation credits; 41.4\%). A small
number of participants were also recruited from social media and other
online sources (Facebook: 3.76\%; Call For Participants: 1.61\%; Reddit:
0.54\%; unspecified: 0.54\%). To meet our YA requirements, all
participants were required to be between 18-59 years of age (actual
range: 18-59). As our experiment involved English word stimuli, we also
asked subjects whether English was their first language; the vast
majority (93.01\%) reported that English was indeed their first
language.

Table 1: Gender and age (\emph{SD}) of the current sample.

\begin{table}[!h]
\centering
\begin{tabular}{l>{}rr>{}l}
\toprule
Gender & N & Age & \\
\midrule
Female & \em{122} & 26.02 & \em{(10.04)}\\
Male & \em{60} & 28.10 & \em{(10.98)}\\
Non-binary & \em{2} & 19.50 & \em{(2.12)}\\
Unspecified & \em{2} & 39.00 & \em{(0)}\\
\textbf{Total} & \textbf{\em{186}} & \textbf{26.70} & \textbf{\em{(10.36)}}\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{materials}{%
\paragraph{Materials}\label{materials}}

Pictures of innocuous, everyday objects (e.g.~clock, rabbit, shoe) and
their written-word names were sourced from Rossion \& Pourtois (2004).
The picture stimuli consisted of greyscale line-drawn illustrations
(containing shaded surface details), while word stimuli were simply the
written-word names of each object presented in a clear Sans-serif
typeface. A total of 136 unique items were randomly selected for use in
the current experiment, from a pool consisting of: i) items with a
written name between 4 and 7 letters; ii) items that would conjure the
same intended concept in our UK-based sample (e.g.~``ladder'' should be
universally understood across English-speaking cultures, whereas
``wagon'' or ``pants'' can be interpreted differently); iii) items that
were not unknown, or uncommon, for our sample (e.g.~Americanisms such as
``wrench''); and iv) non-specific concepts such as ``bird'' (since the
pool of items already contained specific exemplars of birds, such as
``peacock'' and ``penguin''). As the current experiment involved
memorising word stimuli, a single item (``glass'') was also removed as
it shared too many letters with another item (``glasses''). Selected
items were split into four separate lists for counterbalancing purposes;
using the normative data provided by Rossion \& Pourtois (2004), each
list was balanced based on the length of the written name, as well as
scores of naming accuracy, familiarity, visual complexity, and mental
imagery agreement. A series of independent samples t-tests confirmed
that no list was significantly different from another on any of the
aforementioned criteria.

The picture stimuli utilised in the current study were created in
Photoshop CC (20.0.04 Release), by importing the greyscale,
surface-shaded, line-drawings onto a plain 250x250px white canvas.
Written word stimuli were created using the Calibri sans-serif typeface
on the same size canvas (see Figure 1 for example stimuli). All items
were exported as .pngs files for presentation by the online survey
platform.

~ ~

\includegraphics[width=1\linewidth]{./resources/images/exp1__stim_examples}
~ ~ Figure 1: Example word and picture stimuli from the current study. ~
~

\hypertarget{design}{%
\paragraph{Design}\label{design}}

The current study utilised a mixed design, with a 2-level
within-subjects factor of stimuli format (words, drawings), and a
3-level between-subjects factor of response option (RFG, RFBG,
RF-Ratings). Subjects completed two study blocks - one consisting only
of word stimuli, the other consisting only of picture stimuli - before
completing a single mixed format recognition test, where previously
studied word and picture items were randomly shown among new, unseen
items. Subjects passed through 2 levels of blocked randomization during
the experiment (equally sized, predetermined blocks). First, subjects
were randomly allocated into one of two study block orders, which
determined the order in which they were presented with the picture and
word blocks at study. Second, subjects were assigned into one of three
possible recognition tests (identical aside from the response options
available when categorising recognition experiences): 1) RFG:
``Recollection'', ``Familiarity'',``Guessing''; 2) RFBG:
``Recollection'', ``Familiarity'', ``Guessing'', ``Both'', or 3)
RF-Ratings: two independent 0-5 rating scales to separately report the
contribution of Recollection and Familiarity. These randomisation
processes were completed automatically by the experiment software using
balanced methods.

\hypertarget{procedure}{%
\paragraph{Procedure}\label{procedure}}

Data collection was conducted via the online survey platform
Qualtrics\footnote{\url{https://www.qualtrics.com/uk/}}. Subjects
initially completed an encoding block, where target words and pictures
were randomly presented one-at-a-time on-screen. To ensure attention was
directed to the presented stimuli, participants were required to respond
to a simple encoding question toward each item at study: ``Is this a
picture or a word?''. This question allowed for the assessment of
performance during the study block (to determine whether participants
were concentrating at study), whilst also avoiding potential
levels-of-processing effects that can accompany deeper encoding
judgements (e.g.~pleasantness ratings). The encoding phase was followed
by a short distractor task comprised of 20 multiplication sums. Finally,
subjects completed the recognition task, where they were again randomly
presented with word and picture items one-at-a-time on-screen, and were
required to respond ``Old''/``New'' depending on whether they recognised
the item or not. ``Old'' responses were succeeded by a follow-up screen
whereby participants were asked to report their recognition experience
for the current item; the response options available during this
follow-up response page differed between participants, with random
allocation into either the RFG, RFBG, or RF-Ratings response option
conditions. Recollection and Familiarity were defined identically across
conditions, and the only deviations in instructions were: i) to define
the additional ``Both'' response option in the RFBG condition; and ii)
explain how certain responses should be reported in the RF-Ratings
condition (i.e.~subjects could still report a ``Guess'' in this
condition by providing a 0-rating on both of the scales).

\hypertarget{data-processing}{%
\paragraph{Data processing}\label{data-processing}}

Measured variables included the total number of hits and FAs, and the
total number of hits and FAs assigned to each of the available response
options (RFG, RFBG, and RF Ratings). In order to create a common
dependant variable, proportions were calculated from these variables in
slightly different ways depending on the response option group. In the
RFG-judgement group, simple proportions were created from the total
number of R responses and the total number of F responses. In the RFBG
condition, similar proportions were calculated by separately adding the
proportion of Both responses to the proportion of R and proportion of F
responses. In the RF-Ratings group, proportions of R and F were
calculated based on the number of responses scoring +\textgreater3; a
response was classified R when subjects rated between 3-5 on the
``Recollection'' scale (regardless of the Familiarity rating), and a
response was classified F when subjects rated between 3-5 on the
``Familiarity'' scale (regardless of the Recollection rating). The
scales therefore allowed for pure R responses (R=3-5 + F=0-2), pure F
responses (F=3-5 + R=0-2), both responses (R=3-5 + F=3-5) and Guessing
responses (R=0 + F=0). Additional DVs included: i) d' (d-prime, a signal
detection measure of sensitivity); ii) c-value (a measure of response
bias); iii) overall accuracy (hits / (hits + FAs)); iv) reaction times
for all responses.

All analyses were conducted using R (R Core Team, 2020). \emph{d'}
(sensitivity) and \emph{c} (bias) scores were calculated using the
`psycho' package (v0.5.0; Makowski, 2018). \emph{d'} scores were
calculated via: z-scores for correct hits minus z-scores for false
alarms (Hautus, 1995 adjustments for extreme values were applied).
\emph{c} scores were calculated

A series of exclusion criteria were defined before analysis. First,
subjects were to be excluded from analysis if they showed poor
performance during the encoding task; the relative ease of reporting
whether each item was shown as a word or picture prompted a performance
cut off of 90\% accuracy. This would allow for some accidental clicks,
though subjects scoring less than 90\% were to be excluded on the
assumption they did not dedicate their full attention to the task.
Second, subjects would be considered outliers (and thus excluded from
analysis) if they presented extreme z-scores of +/- 3 for total hits,
total FAs, or overall recognition (hits minus FAs). However, no subjects
were found to meet any of these criteria.

\hypertarget{results}{%
\subsubsection{Results}\label{results}}

\hypertarget{picture-superiority}{%
\paragraph{Picture superiority}\label{picture-superiority}}

To establish baseline picture superiority effects in the current
paradigm, and assess whether there were any interactions with the
availability of different response options at test, a series of 2
(stimuli format: words, pictures) x 3 (response option condition:
RFG-judgements, RFBG-judgements, RF-ratings) mixed ANOVAs were conducted
on a number of outcome variables. Namely, the proportion of overall
hits, false alarms (FAs), and overall recognition (hits - FAs) {[}see
Table 2{]}. To further examine response patterns between pictures and
words, ANOVAs were also run on the signal detection measures of
\emph{d'} (measure of sensitivity) and \emph{c} (decision criterion).
Significant main effects and interaction effects were followed-up with
Bonferroni-adjusted pairwise comparisons.

Table 2: Mean proportion of hits and FAs by stimuli-format and
response-option condition.

\begin{table}[!h]
\centering
\begin{tabular}{>{\raggedright\arraybackslash}p{3.6cm}>{\raggedright\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{2cm}}
\toprule
  & Hits & FAs & Overall recognition\\
\midrule
\addlinespace[0.3em]
\multicolumn{4}{l}{\textbf{Stimuli-format}}\\
\hspace{1em}Words & 0.47 & 0.21 & 0.27\\
\hspace{1em}Pictures & 0.62 & 0.12 & 0.50\\
\addlinespace[0.3em]
\multicolumn{4}{l}{\textbf{Response-option}}\\
\hspace{1em}RFG & 0.62 & 0.19 & 0.43\\
\hspace{1em}RFBG & 0.54 & 0.16 & 0.38\\
\hspace{1em}RF Ratings & 0.48 & 0.14 & 0.34\\
\bottomrule
\end{tabular}
\end{table}

The ANOVA on the proportion of hits demonstrated a significant main
effect of stimuli-format, \(F(1, 183) = 131.77\),
\(\mathit{MSE} = 0.01\), \(p < .001\), \(\hat{\eta}^2_G = .092\); a PSE
was evident, with pictures (\(M = 0.62\)) showing a higher number of
overall hits compared to words (\(M = 0.47\)), \(t(183) = -11.48\),
\(p < .001\). Similarly, the ANOVA on the proportion of FAs also
supported a PSE; a significant main effect of stimuli-format
\(F(1, 183) = 61.18\), \(\mathit{MSE} = 0.01\), \(p < .001\),
\(\hat{\eta}^2_G = .084\) showed that words (\(M = 0.21\)) produced more
FAs than pictures (\(M = 0.12\)), \(t(183) = 7.82\), \(p < .001\).
Overall recognition performance (a measure that takes into account both
hits and FAs) offered further support for a PSE in the current paradigm;
a significant main effect of stimuli-format \(F(1, 183) = 409.20\),
\(\mathit{MSE} = 0.01\), \(p < .001\), \(\hat{\eta}^2_G = .236\) showed
pictures (\(M = 0.50\)) produced better overall recognition on the task
compared to words (\(M = 0.27\)), \(t(183) = -20.23\), \(p < .001\). No
interaction effects were found between stimuli format and response
option for any of these variables. Taken together, the findings
demonstrate a replication of the PSE in the current memory paradigm, and
suggest stimuli format plays a key role in memorability that is
independent of response option.

~ ~

The ANOVA on \emph{d'} scores produced findings consistent with those
found for hits, FAs, and overall recognition; there was a significant
main effect of stimuli-format, \(F(1, 183) = 295.80\),
\(\mathit{MSE} = 0.18\), \(p < .001\), \(\hat{\eta}^2_G = .223\),
whereby pictures (\(M = 1.62\)) facilitated better discrimination
between hits and FAs than words (\(M = 0.86\)), \(t(183) = -17.20\),
\(p < .001\). \emph{C} scores, however, showed no significant main
effect of stimuli-format, \(F(1, 183) = 2.31\), \(\mathit{MSE} = 0.11\),
\(p = .130\), \(\hat{\eta}^2_G = .002\), suggesting response biases were
similarly conservative between pictures and words. Neither the ANOVA on
\emph{d'} or \emph{C} scores showed any significant interaction effects.

\hypertarget{response-option-availability}{%
\paragraph{Response option
availability}\label{response-option-availability}}

In the ANOVAs on the proportion of hits, FAs, and overall recognition,
the main effects of response option were also examined to determine
whether the availability of different response option had an impact on
task performance. There was a significant main effect of response option
only in the ANOVA for the proportion of hits, \(F(2, 183) = 6.46\),
\(\mathit{MSE} = 0.09\), \(p = .002\), \(\hat{\eta}^2_G = .057\), with
the RFG group (\(M = 0.62\)) showing more hits than the RF-Ratings group
(\(M = 0.48\)), \(t(183) = 3.60\), \(p = .001\). The ANOVAs on the
proportion of FAs and overall recognition showed no significant main
effect of response option. This finding might indicate fewer available
response options facilitate accurate recognition compared to more
response options - however, the absence of a main effect for overall
recognition (a measure that takes into account both hits and FAs)
suggests this interpretation should be treated with caution.

Discriminability (\emph{d'}) between hits and FAs showed no significant
main effect of response option, however, scores of response bias
(\emph{C}) did, \(F(2, 183) = 6.44\), \(\mathit{MSE} = 0.51\),
\(p = .002\), \(\hat{\eta}^2_G = .054\); those in the RF-Ratings
condition (\(M = 0.67\)) showed higher c-scores (and thus a more
conservative response bias) than those in the RFG condition
(\(M = 0.34\)), \(t(183) = -3.59\), \(p = .001\). This indicates
subjects were less likely to respond ``Old'' when they were required to
provide more detailed follow-up recognition judgements (i.e., using
separate 0-5 scales for R and F), compared to simply selecting one of
three options (R,F, or G).

\hypertarget{recollection-and-familiarity}{%
\paragraph{Recollection and
Familiarity}\label{recollection-and-familiarity}}

To determine whether stimuli format, or the availability of different
response options, had an impact on rates of R and F, additional a series
of 2 (words, pictures) x 3 (RFG-judgements, RFBG-judgements, RF-ratings)
mixed ANOVAs were conducted on the mean proportion of hits and FAs
assigned R, F, and G.

\includegraphics{R--Thesis_files/figure-latex/unnamed-chunk-13-1.pdf}
Figure 2: Proportion of hits assigned Recollection, Familiarity, and
Guessing, by stimuli-format and response-option condition.

\textbf{\emph{Recollection:}} For R hits, there was a significant main
effect of stimuli-format, \(F(1, 178) = 158.42\),
\(\mathit{MSE} = 0.03\), \(p < .001\), \(\hat{\eta}^2_G = .167\), with
pictures (\(M = 0.67\)) showing a higher proportion of Recollected hits
than words (\(M = 0.45\)), . There was also a significant main effect of
response-option, \(F(2, 178) = 8.55\), \(\mathit{MSE} = 0.09\),
\(p < .001\), \(\hat{\eta}^2_G = .069\); the RF-Ratings group
(\(M = 0.65\)) showed significantly more Recollected hits compared to
both the RFG-group (\(M = 0.49\)), , and the RFBG-group (\(M = 0.54\)),
. There were no significant interaction effects, \(F(2, 178) = 1.91\),
\(\mathit{MSE} = 0.03\), \(p = .151\), \(\hat{\eta}^2_G = .005\). In the
ANOVA on Recollection FAs, there was no significant main effect of
stimuli-format, \(F(1, 136) = 2.78\), \(\mathit{MSE} = 0.04\),
\(p = .098\), \(\hat{\eta}^2_G = .005\), but there was for
response-option, \(F(2, 136) = 10.70\), \(\mathit{MSE} = 0.12\),
\(p < .001\), \(\hat{\eta}^2_G = .106\), with those in the RF-ratings
group (\(M = 0.38\)) showing more Recollection FAs than both the
RFG-group (\(M = 0.14\)), , and RFBG-group (\(M = 0.24\)), ). This could
indicate that when subjects were required to individually report
Recollection and Familiarity on two 0-5 rating scales, they were more
likely to experience (or report) false recognition (accompanied by
non-existent contextual details) than when only three (RFG) or four
(RFBG) response-options were provided. There were no significant
interaction effects, \(F(2, 136) = 2.08\), \(\mathit{MSE} = 0.04\),
\(p = .129\), \(\hat{\eta}^2_G = .008\).

\textbf{\emph{Familiarity:}} F hits demonstrated a significant
interaction between stimuli format and response option,
\(F(2, 178) = 34.42\), \(\mathit{MSE} = 0.03\), \(p < .001\),
\(\hat{\eta}^2_G = .083\) (see Figure 3). Within response-option
conditions, words resulted in more Familiarity hits than pictures in
both the RFG group (words: \(M = 0.48\); pictures: \(M = 0.29\),
\(t(178) = 6.07\), \(p < .001\)) and RFBG group (words: \(M = 0.57\);
pictures: \(M = 0.48\), \(t(178) = 2.87\), \(p = .005\)). Conversely,
the RF-Ratings group showed the opposite pattern, with more Familiarity
hits produced for pictures (\(M = 0.79\)) than words (\(M = 0.63\)),
\(t(178) = -5.29\), \(p < .001\). The ANOVA on Familiarity FAs did not
yield any significant results; with no significant main effect of
stimuli-format, \(F(1, 136) = 1.12\), \(\mathit{MSE} = 0.04\),
\(p = .292\), \(\hat{\eta}^2_G = .002\), no significant main effect of
response-option, \(F(2, 136) = 0.62\), \(\mathit{MSE} = 0.15\),
\(p = .539\), \(\hat{\eta}^2_G = .007\), and no significant interaction
effects, \(F(2, 136) = 1.12\), \(\mathit{MSE} = 0.04\), \(p = .331\),
\(\hat{\eta}^2_G = .004\).

Between response-option conditions, word stimuli produced significantly
more Familiarity hits in the RF-Ratings group (\(M = 0.63\)) compared to
the RFG group (\(M = 0.48\)), \(t(276.78) = -3.37\), \(p = .002\). For
pictures, a higher number of Familiarity hits was evident in the
RF-Ratings group (\(M = 0.79\)) compared to both the RFG group
(\(M = 0.29\)), \(t(276.78) = -11.13\), \(p < .001\) and RFBG group
(\(M = 0.48\)), \(t(276.78) = -6.94\), \(p < .001\). The RFBG group
(\(M = 0.48\)) also showed a significantly higher number of Familiarity
hits compared to the RFG group (\(M = 0.29\)), \(t(276.78) = -4.24\),
\(p < .001\).

\includegraphics{R--Thesis_files/figure-latex/unnamed-chunk-15-1.pdf}
Figure 3: Interaction plot between stimuli-format and response-option
condition for the mean proportion of hits assigned `Familiarity'.

\textbf{\emph{Guessing:}} The ANOVA on Guessing hits also showed a
significant interaction between stimuli format and response
option,\(F(2, 178) = 4.17\), \(\mathit{MSE} = 0.01\), \(p = .017\),
\(\hat{\eta}^2_G = .011\), (see Figure 4). Within response-option
conditions, words resulted in more Guessing hits than pictures in both
the RFG group (words: \(M = 0.17\); pictures: \(M = 0.08\)),
\(t(178) = 5.38\), \(p < .001\); and RFBG group (words: \(M = 0.16\);
pictures: \(M = 0.09\)), \(t(178) = 4.42\), \(p < .001\).

Between response-option conditions, word stimuli produced significantly
fewer Guessing hits in the RF-Ratings group (\(M = 0.04\)) compared to
both the RFG group (\(M = 0.17\)), \(t(281.42) = 5.44\), \(p < .001\),
and the RFBG group (\(M = 0.16\)), \(t(281.42) = 5.18\), \(p < .001\). A
similar pattern was also evident for pictures, with significantly fewer
of Guessing hits in the RF-Ratings group (\(M = 0.01\)) compared to both
the RFG group (\(M = 0.08\)), \(t(281.42) = 2.70\), \(p = .020\) and
RFBG group (\(M = 0.09\)), \(t(281.42) = 3.15\), \(p = .005\).

\includegraphics{R--Thesis_files/figure-latex/unnamed-chunk-17-1.pdf}
Figure 4: Interaction plot between stimuli-format and response-option
condition for the mean proportion of hits assigned `Guessing'.

Finally, the ANOVA on Guessing FAs also showed no significant main
effect of stimuli-format, \(F(1, 136) = 0.51\), \(\mathit{MSE} = 0.04\),
\(p = .476\), \(\hat{\eta}^2_G = .001\), but there was a significant
main effect of response-option, \(F(2, 136) = 15.69\),
\(\mathit{MSE} = 0.11\), \(p < .001\), \(\hat{\eta}^2_G = .144\), with
the with the RF-ratings group (\(M = 0.08\)) showing significantly fewer
Guessing FAs than both the RFG (\(M = 0.35\)), , and RFBG groups
(\(M = 0.30\)), . This again aligns with previous results, suggesting
that those in the RF-Ratings group were less likely to report guesses
than the other groups, whether accurate or not. There were no
significant interaction effects, \(F(2, 136) = 0.07\),
\(\mathit{MSE} = 0.04\), \(p = .935\), \(\hat{\eta}^2_G = .000\).

\includegraphics{R--Thesis_files/figure-latex/unnamed-chunk-19-1.pdf}
Figure 5: Proportion of FAs assigned Recollection, Familiarity, and
Guessing, by stimuli-format and response-option condition.

\hypertarget{discussion}{%
\subsubsection{Discussion}\label{discussion}}

How do colour (vs.~greyscale), and illustrations (vs.~photographs)
differentially affect responses across RFG, RFBG, and RF Ratings?

``perhaps the current study stimulus set of high-resolution colour
images may have helped patients overcome visual processing deficits, and
use distinctive information to improve memory for pictures over words''
- (Ally, Gold, \& Budson, 2009) -- expected visual processing deficits
to manifest as reduced PSE in MCI, but as the results did not support
this, suggest the colour images may have helped to bypass this. ``Future
studies can perhaps examine whether increasing the amount of detail
present in a picture enhances discrimination''

Suzuki \& Takahashi (1997): recognition performance was highest when
colour pictures were used in both the study and test phases (compared
with black and white).

Taken together, these findings with expected PSE are consistent with the
notion that pictures offer an enhanced memorability in comparison to
words. When they were correctly recognised, words were not recognised in
the the same context-rich nature as pictures, evidenced by a higher
proportion of F responses. Despite `Guessing' responses being
permissable in any of the response-option groups, it seems when two
independent rating scales were required participants were less likely to
report a ``Guess''. This could be because those in the RF-Ratings
condition selected ``New'' more often than ``Old'' when they were having
a complete guess, or instead, subjects might have opted to report lower
levels of Recollection and Familiarity ratings (i.e., 1-3), rather than
responding 0 on both scales.

\#\#\#\#\#\#----------------------------------------

\newpage

\hypertarget{chapter-3}{%
\section{Chapter 3}\label{chapter-3}}

The Picture Superiority Effect (PSE) is a highly robust and replicable
phenomenon. In recognition memory paradigms, the PSE has been shown to
manifest as both increased recollection and familiarity (Dewhurst \&
Conway, 1994; Rajaram, 1993, 1996; Wagner, Gabrieli, \& Verfaellie,
1997; Yonelinas, 2002). The effect is present in children, adolescents
and healthy older adults (Whitehouse, Maybery, \& Durkin, 2006), though
perhaps more striking is the fact that patients with Alzheimer's disease
or those presenting early isolated memory impairments, known as amnestic
mild cognitive impairment (aMCI), also show memorial benefits toward
pictures (Ally, 2012). This is supported by ERP studies demonstrating
comparable enhancements to recollection-based ERP components between
healthy older and aMCI groups when pictures, rather than words, are
utilised (Ally et al., 2009a). There is debate within the literature
attempting to characterise the nature of memory deficits in aMCI,
whereby despite general agreement that recollection processes are
impaired in such individuals, findings show great inconsistency with
regard to familiarity (Algarabel et al., 2012; Belleville et al., 2011;
Pitarque, 2016; Wolk, Dunfee, Dickerson, Aizenstein, \& DeKosky, 2011;
Wolk, Mancuso, Kliot, Arnold, \& Dickerson, 2013). The PSE may have been
largely overlooked as an area for further research in an effort to help
settle this debate, despite recent reviews highlighting methodological
differences across studies as the potential source of inconsistent
findings (Koen \& Yonelinas, 2014; Migo, Mayes, \& Montaldi, 2012;
Schoemaker et al., 2014). The level at which stimuli distinctiveness
impacts successful recognition is currently unclear, and there is little
consistency across studies with regard to what is considered a
`picture'.

Many experiments utilise illustrations for their picture stimuli (van
der Meulen et al., 2012; Westerberg et al., 2013; Wolk et al., 2011),
with a standardised set of items published by Snodgrass \& Vanderwart
(1980) among the most-used illustrated picture stimuli within the domain
of memory research (Bermúdez-Margaretto, Beltrán, Cuetos, \& Domínguez,
2018; Deason, Hussey, Flannery, \& Ally, 2015; Hockley, 2008; Martins \&
Lloyd-Jones, 2006; McBride \& Anne Dosher, 2002; Meade, Ahmad, \&
Fernandes, 2019; Schmitter-Edgecombe, Woo, \& Greeley, 2009; van der
Meulen et al., 2012; Wagner et al., 1997; Wammes, Meade, \& Fernandes,
2016; Weldon, Iii, \& Challis, 1989; Weldon \& Roediger, 1987;
Whitehouse et al., 2006). The set consists of 260 line drawings of
common, everyday objects (in black ink), along with their written word
counterpart (e.g.~``shoe''). Items were selected on the basis of
exemplifying a number of semantic categories, including animals,
furniture, fruit, etc., and a range of normative data was collected for
each item; indices of naming agreement, mental imagery agreement, visual
complexity, and familiarity were all recorded for each drawing. The
normative data for the Snodgrass \& Vanderwart (1980) items has been
continually revisited, with a number of studies gathering
culturally-appropriate norms (e.g.~in Spanish (Sanfeliu \& Fernandez,
1996), Chinese (Yoon et al., 2004), and Russian (Tsaparina, Bonin, \&
Méot, 2011), and additional testing of the relationship between reaction
time and naming agreement (Székely et al., 2003). There are multiple
theories of object recognition; the recognition-by-components theory
proposed by Biederman (1987) identifies shape as the most crucial factor
for successful recognition, in which case, the object outlines found in
the set by Snodgrass \& Vanderwart (1980) should be more than sufficient
for experimental cognitive research. Other theories, however, posit that
surface details such as colour and texture are just as crucial in
forming object representations (Tanaka, Weiskopf, \& Williams, 2001;
Tarr \& Bülthoff, 1998). The wide-ranging applicability of the Snodgrass
\& Vanderwart (1980) items throughout a number of cognitive disciplines
has led to a more recent revision of the items by Rossion \& Pourtois
(2004). This revision consists of the exact same objects, digitally
re-drawn to include surface textures and shading. Additionally, this set
provides greyscale and colour versions for all items, as opposed to the
greyscale-only items found in the Snodgrass \& Vanderwart (1980) set
(see Figure 6 for example items contained in the Snodgrass \& Vanderwart
(1980) and Rossion \& Pourtois (2004) stimuli sets). The Rossion \&
Pourtois (2004) revision now appears to be favoured over the original
Snodgrass \& Vanderwart (1980) set among many cognitive researchers
(Rollins \& Riggins, 2018, p. @ensor2019b; Stenberg, 2006; Wolk et al.,
2008), almost certainly attributable to the increased detail and ability
to choose whether colour is a necessary condition.

Despite their widespread use, line drawings have been criticised for
their relative simplicity and lack of realism (Viggiano, Vannucci, \&
Righi (2004)), with many researchers favouring the use of photographs as
experimental stimuli (Embree et al., 2012; Pitarque, 2016; Troyer et
al., 2012; Troyer, Vandermorris, \& Murphy, 2016; P. Wang et al., 2013).
Photographs of faces are especially useful in research examining emotion
and face recognition (Barba, 1997; Bowen, Fields, \& Kensinger, 2019;
Cui et al., 2016; Herzmann, Minor, \& Curran, 2018), though a number of
common-object photograph sets have also emerged as ecological
alternatives to line-drawn items (Adlington, Laws, \& Gale, 2009;
Moreno-Martínez \& Montoro, 2012; Viggiano et al., 2004). While the
published sets of photographs are undoubtedly useful in a range of
cognitive domains, they do not allow us to specifically examine stimuli
format as a factor on its own, as the concepts depicted are unique to
the set they derive from. In order to make such comparisons, and ensure
any differences in performance (e.g.~recognition memory ability) are
indeed attributable to stimuli format, the objects depicted must be
consistent across stimuli formats. The current study presents a new set
of photographic stimuli that extend the set of words and drawings
provided by Rossion \& Pourtois (2004), wherein each of the concepts
depicted has been carefully matched across formats. These new stimuli
will be utilised throughout a number of planned recognition experiments
that aim to systematically compare measures of recognition against
different `levels' of stimuli. The curation of a new set of photographs
- carefully matched to other formats - allows investigation into whether
picture superiority magnitudes are mediated by the format pictures are
presented in. The inconsistent use of different formats across studies
has previously made it difficult to reconcile effects obtained in
response to drawings with those obtained in response to photographs - an
inherent problem when concepts are not matched across format. Normative
data for the new set of photographs is also presented, allowing others
who also wish to use our photograph stimuli to filter items by measures
of naming agreement, mental imagery agreement, familiarity, visual
complexity, and colour diagnosticity.

~ ~

\includegraphics[width=1\linewidth]{./resources/images/exp2__stim_examples}
~ ~ Figure 7: Examples of matching pictures across Snodgrass \&
Vanderwart (1980), Rossion \& Pourtois (2004), and photographs from the
current study. Greyscale versions of the drawings and photographs are
not presented in this example. ~ ~

\hypertarget{experiment-development-of-a-new-set-of-standardised-photographic-stimuli}{%
\subsection{Experiment: Development of a new set of standardised
photographic
stimuli}\label{experiment-development-of-a-new-set-of-standardised-photographic-stimuli}}

\newpage

\hypertarget{method-1}{%
\subsubsection{Method}\label{method-1}}

\hypertarget{participants-1}{%
\paragraph{Participants}\label{participants-1}}

A total of 377 subjects completed the online experiment (see Table 3 for
a breakdown of the gender and age of the sample). This sample size
provided 20 data points for each of the five response types, while also
ensuring the experiment did not last too long for participants (approx
25-mins). Subjects were recruited from both voluntary participation
websites such as
Prolific Academic\footnote{\url{https://www.prolific.co/}} (where they
received payment at the rate of £5/hr), and via the in-school
research participation system\footnote{\url{https://keelepsychology.sona-systems.com/}}
(where they received course participation credits).

Table 3: Gender and age (\emph{SD}) of the current sample.

\begin{table}[!h]
\centering
\begin{tabular}{l>{}rr>{}l}
\toprule
Gender & N & Age & \\
\midrule
Female & \em{196} & 33.22 & \em{(11.28)}\\
Male & \em{171} & 33.15 & \em{(10.3)}\\
Non-binary & \em{2} & 23.50 & \em{(-)}\\
Unspecified & \em{5} & 29.40 & \em{(6.11)}\\
\textbf{Total} & \textbf{\em{377}} & \textbf{NA} & \textbf{\em{NA}}\\
\bottomrule
\end{tabular}
\end{table}

To meet our YA requirements, all participants were required to be aged
between 18-59 years (actual obtained range: 18-59 years). As our
experiment involved typing the English labels for a range of image
stimuli, subjects were also asked whether English was their first
language; all but one participant indicated that English was indeed
their first language (99.2\%).

\hypertarget{materials-1}{%
\paragraph{Materials}\label{materials-1}}

A pool of 136 line drawings (Rossion \& Pourtois, 2004) - depicting
common, everyday objects - were brought forward from the previous
experiment. These items (along with their written-word labels) would
form two of the unique stimuli formats that would be used in future
recognition experiments (words and drawings). In this study, the
drawings from Rossion \& Pourtois (2004) were simply used as a reference
in the photograph matching process. Corresponding photographs were
obtained online with the aim of depicting the everyday objects in a
similar manner to the drawings. The inherent subjectivity involved in
this process may have led to images that were not a reliable `match' to
the concepts they were selected to depict (for example, the photograph
chosen to depict the concept ``bottle'' may inadvertently provoke the
majority of participants to give the label ``wine'', thus indicating
that this particular photograph fails to accurately depict the intended
concept). To address this issue, and ensure all photographs more
objectively depict the same concepts as the line drawings, three
different photograph variations were found for each everyday object,
with the aim of taking the best `match' forward. An emphasis was placed
on variety across these variations, with the aim of obtaining at least
one photograph that very closely resembled the line-drawn depiction, and
another offering a more modern depiction. Some items were substituted
due to unique restrictions that meant they could not easily be
translated into photographic format (for example, the shapes ``arrow''
and ``star'' can not be represented similarly as photographs). Photo
stimuli were obtained by searching open-source, copyright-free image
websites (e.g.~Unsplash\footnote{\url{https://unsplash.com/}};
Pexels\footnote{\url{https://www.pexels.com/}}) for photographs that
depicted the same everyday objects as the line drawings (see Appendix C
for the full list of image references).

The matching process produced a total of 408 unique photographs. All
were imported into Adobe Photoshop (20.0.04 Release), where the
background was removed to isolate the object of interest from other
potentially distracting visual details. This was completed manually
using the magnetic lasso and polygonal lasso tools (edges were either
feathered by 1px or left un-feathered). The orientation of isolated
objects was adjusted to ensure they matched as closely as possible with
their line-drawn counterpart (e.g.~all photograph variations of the item
`boot' were adjusted so the toe was facing left and the heel facing
right, as in the line drawing); this was often achieved by flipping or
mirroring the object to `correct' the direction.

Despite isolating objects from their background, a small number of
photographs still contained irrelevant and potentially distracting
details. For example, in one photograph variation of the item `piano',
there was a sign on the object that may have impacted how the item was
named or rated. Such details were removed as best as possible using the
clone stamp and content-aware fill tools. Any obvious text (e.g.~brand
names) and numbers were also removed from photographs using the same
method (see Figure 8). The primary aim of the current study was to
obtain photographs that could be clearly distinguished as a unique
stimuli format among words and line drawings; it is conceivable that
combining these formats (i.e.~inadvertently including photographs that
also contain written words) might affect recognition performance in ways
that are not directly comparable to items defined only by a single
category. Any text in our photographs was therefore removed, apart from
a couple of exceptions whereby such details happened to be integral to
the depiction of the object (e.g.~the numbers found on a ruler or
clock).

All photographs were exported from Photoshop in ``.png'' format in both
their original colour and in greyscale (by setting saturation levels to
0). Final edits were completed in Adobe Lightroom (Classic, 8.2
Release): exposure (brightness) adjustments were made on images that
appeared too light or too dark; highlights were decreased if some areas
were too bright compared to the rest of the photograph; shadows were
raised if some areas were too dark compared to the rest of the
photograph; noise reduction was applied to some items after isolating
the subject had inadvertently made unwanted noise/grain more visible.
The changes made to each image were systematically applied to both the
colour and greyscale versions (e.g.~if one variation of ``shoe'' had an
exposure increase of .010 for the colour version, the greyscale version
also received an exposure increase of .010). Some colour-specific
adjustments were made to the colour photographs only, however; common
photo artefacts such as chromatic aberration (purple fringing) were
corrected, along with white balance normalisation. Finally, all
photographs were placed on a 600x600 pixel white background, and made to
fill this frame as much as possible (i.e.~some items were restrained by
height, whilst others were restrained by width).

~ ~

\includegraphics[width=1\linewidth]{./resources/images/photo-manipulation-examples}
~ ~ Figure 8: Examples of background and text removal in photograph
items. ~ ~

\hypertarget{design-1}{%
\paragraph{Design}\label{design-1}}

This was a descriptive study; a mix of qualitative and quantitative data
were gathered. Across three blocks, all participants provided five types
of response toward photograph stimuli: i) Naming; ii) Familiarity; iii)
Visual Complexity, iv) Colour Diagnosticity; and v) Mental Imagery
Agreement. Excluding the Naming task (consisting of a typed single-word
answer), all responses were provided on a 5-point ordinal scale. Within
participants, the maximum number of response type provided for any one
item was two; Naming and Familiarity responses were paired in one block,
Visual Complexity and Colour Diagnosticity responses were paired in
another, and Mental Imagery Agreement responses were always presented in
a separate block. The order of these three blocks was counterbalanced
across participants. Toward each individual photograph, participants
made only one or two types of response before moving on to the next
item, and the same items were not repeated to participants. For each
photograph, the five types of required data were obtained by
counterbalancing between participants (e.g.~for the first variation of
the ``cat'' photograph, the Naming and Familiarity data was obtained
from one participant, the Visual Complexity and Colour Diagnosticity
data was obtained from another, and the Mental Imagery Agreement data
was obtained from another).

\hypertarget{procedure-1}{%
\paragraph{Procedure}\label{procedure-1}}

Data collection was conducted via two online platforms; i)
Qualtrics\footnote{\url{https://www.qualtrics.com/uk/}} - a survey
platform that allowed for straightforward collection of consent,
demographics, and computer compatibility data, and ii)
Pavlovia\footnote{\url{https://pavlovia.org/}} - an open-source
experiment hosting platform for studies programmed in Javascript (Peirce
et al., 2019).

In the Naming and Familiarity block, participants were first asked
``What is the name of the item depicted?''. Subjects were instructed to
name each photograph as briefly and unambiguously as possible, with one
name only, and respond by typing their answer into the response box. If
they did not know the name of an item, or had a tip-of-the-tongue
experience, participants were instructed to type ``no'' for their answer
(the term ``don't know'' was avoided so as not to encourage subjects to
deviate from single-word responses, as instructed).Following the naming
judgement, with the same photograph still present on-screen,
participants were next asked ``How familiar is the item depicted?''.
Subjects were instructed to judge each photo according to how usual or
unusual the item was in their realm of experience; specifically,
familiarity was defined as ``the degree to which you come in contact
with, or think about, the concept'', and encouraged participants to rate
the concept itself rather than the particular way it was currently
shown. Participants selected one value from the 5-point scale, ranging
from very unfamiliar (1) to very familiar (5), and were encouraged to
use the full range of the scale throughout the set of photographs.

In the Visual Complexity and Colour Diagnosticity block, participants
were first instructed to respond to the question ``How visually complex
is this picture?'' using a 5-point scale that ranged from ``very
simple'' (1) to ``very complex'' (5). Complexity was defined to subjects
as ``the amount of detail in the picture''; in contrast to the
familiarity ratings, participants were encouraged here to rate the
complexity of the picture itself, rather than the real-life item. If the
photograph shown was greyscale, subjects would simply move on to the
next item. If the item shown was in colour, however, participants were
also required to make a colour diagnosticity judgement. This concept was
defined as ``how typical / normal the colour of the item is'',
instructing subjects to rate on a 5-point scale ranging from ``Not at
all diagnostic (i.e.~this item could be in any other colour equally
well)'' (1) to "Highly diagnostic (i.e.~this item appears only in this
colour in real life). Participants were instructed to utilise the full
range of options on the scale when making visual complexity and colour
diagnosticity judgements. After making these ratings, a fixation cross
was presented during a 1s interstimulus interval.

Due to the slight change in procedure and increased task complexity,
Mental Imagery Agreement ratings were always acquired in an individual
block (i.e.~not alongside any other response types). First, participants
were presented with a written label for 3s (e.g.~``cat'') and told to
focus their attention on the word. Once the written word disappeared, a
beep tone was played alongside the instruction ``close your eyes and
imagine this item'' (subjects were encouraged to close their eyes and
begin imagining the item as soon as they heard the tone, but the written
instruction were included as a further prompt). After 3s a second beep
tone sounded to alert subjects to open their eyes, where they were
presented with a photograph of the item they had been instructed to
imagine. On a 5-point scale, participants were asked to ``rate the
agreement between your mental image and the picture'', from ``low
agreement'' (1) to ``high agreement'' (5). The degree of agreement was
defined as ``how similar your mental image of the item is to the picture
shown''. A fixation cross was displayed for 1s before the next word item
was shown.

All responses were self-paced; the timing was only controlled during the
study/imagine section of the Mental Imagery Agreement block.

~ ~

\includegraphics[width=1\linewidth]{./resources/images/procedure} ~ ~
Figure 9: Data collection procedure for Mental Imagery Agreement
responses. ~ ~

\hypertarget{data-processing-1}{%
\paragraph{Data processing}\label{data-processing-1}}

The naming responses for each photograph item were manually assessed for
spelling and typing errors. Automatic spell checking software was
avoided in an effort to avoid inadvertently introducing unique names
that were not actually given by participants. The vast majority of
errors were unambiguous and easy to correct (e.g.~``anker'' =
``anchor'', ``peguin'' = ``penguin'', ``ssnowman'' = ``snowman''), or
consisted of transforming plural words to singular (or vice versa,
depending on the form of the intended label - e.g.~``sock'' to
``socks''). Some responses were a little more ambiguous, and
necessitated comparison to the photographs they were in response to for
additional clarity (e.g.~a photograph depicting a plug that would fit
into North American electrical sockets was labelled as ``usplug'' -
given the nature of our UK-based sample, it's likely the subject was
responding: ``U.S. (i.e.~United States) plug''.

There were instances where subjects provided a sensible and correctly
spelled English word, but that were clearly typos when examined against
the photograph they were in response to (e.g.~``dock'' for a photograph
depicting a duck, ``frock'' for a frog, and ``beer'' for a ``bear'',
etc). The most ambiguous spelling error to correct was ``bittle'', which
was provided by more than one participant and to more than one item;
separate inspections of the photographs participants were responding to
made this easy to correct though, with one participant clearly meaning
to respond ``bottle'', whilst the other meant to respond ``beetle''.
Though participants were instructed to only give a single label for each
item, some multiple word responses were found (without spaces) during
the spell checking process. On such occasions, a judgement was made
regarding whether multiple words were retained, or whether the response
could be shortened into a single word. A general rule was applied
whereby if the other words provided additional information, they were
retained (e.g.``maledear'' - presumably ``male deer'' - was kept as a
two-word answer). Multiple word responses were generally shortened into
a single word when the intended label for the item was clearly present,
and no information was lost in the process (e.g.~``haircomb'' was
shortened to the intended answer ``comb''). It is noted that there was
some inherent subjectivity in this process, though as such items were
not common among straightforward responses, their overall effects are
estimated to be negligible.

Finally, there were some responses that were changed to ``no'' as they
were clearly intended to signify that the responder did not know the
name of the item shown; the experiment instructed participants to type
``no'' in these instances, though the labels ``none'' and ``idk''
(common abbreviation for ``I don't know) were provided instead. There
was also a single response that was manually changed to''no``, as the
provided label was a single letter and thus entirely unclear what the
intended answer should be (see Appendix B for full list of manipulations
to naming responses). This process yielded data that could be used to
determine which photograph variation best matched the intended concepts
(e.g.~100\% of participants labelled the object ``bottle'', indicating a
perfect match), and which did not (e.g.~only 50\% of participants
labelled the item ``bottle'', whilst the other 50\% gave the label
``wine'', indicating a poor match). Photographs showing poor agreement
across participant-generated labels, or those where the majority of
labels differed from the intended concept, could be replaced with the
variation demonstrating the most accurate depiction.

\hypertarget{analysis-preperation}{%
\paragraph{Analysis preperation}\label{analysis-preperation}}

A number of variables were calculated prior to analysis. For
familiarity, visual complexity, colour diagnosticity, and mental imagery
agreement, mean ratings were calculated for each (see Appendix C). Mean
reaction times (RTs) were also calculated for each photograph / response
variable, including naming responses. For naming responses, accuracy was
defined as the proportion of subjects reporting the correct/intended
label for any given item (e.g.~80\% of subjects correctly labelled a
photograph of the moon as ``moon''). Percentage agreement was also
calculated (i.e.~the proportion of subjects providing the most frequent
name, regardless of whether it matched the correct/intended label) in
order to compute \emph{H} values for each item. The \emph{H} statistic
also reflects naming agreement, but it takes into account the total
number of unique labels given for an item. This is especially useful for
comparing similar items, as it captures information not provided by
simple agreement proportions. For instance, if the first variation of
the photo moon (`moon-1') demonstrated 90\% naming agreement among
subjects, and the second variation (`moon-2') also demonstrated 90\%
naming agreement, it would appear as if both versions offer the same
level of agreement among participants. However, `moon-1' may have
received a total of 2 unique names (e.g.~moon, planet), while `moon-2'
received a total of 4 unique names (e.g.~moon, planet, earth, comet).
\emph{H} values utilise this useful information to determine which item
shows the best naming agreement (in other words, the item with the least
number of unique names). The original formula by Snodgrass \& Vanderwart
(1980) was used to calculate \emph{H} values:

\includegraphics[width=0.5\linewidth]{./resources/images/h_calculation}

A \emph{H} value of 0 indicates perfect naming agreement (all subjects
responded with the same label for that item). Items showing a \emph{H}
value of 1 signify two unique names were provided, with identical
proportions (e.g.~10 subjects responded ``moon'' and 10 subjects
responded ``planet''). As the \emph{H} value increases, overall naming
agreement decreases.

\hypertarget{results-1}{%
\subsubsection{Results}\label{results-1}}

Summary statistics (mean and \emph{SD}) for each of the measured
variables are shown in Table 4. Data for the grey and colour photographs
are presented alongside previously obtained normative values for a
number of other stimuli formats (all obtained from Rossion \& Pourtois
(2004), who published revised norms for Snodgrass \& Vanderwart (1980)'s
(S\&V) original line drawings, as well as their own re-drawn versions
that contained shading and texture detail). The data from previous
studies were not used in any statistical analyses. To examine whether
the grey and colour photographs from the current study demonstrated any
differences, a series of independent samples t-tests were run on each
variable, as well as their corresponding reaction times (excluding
scores of colour diagnosticity, which were obtained only in response to
the colour items and thus cannot be compared). Mean (and \emph{SD})
values for all x816 unique photograph items are presented in Appendix C.

\hypertarget{naming}{%
\paragraph{\texorpdfstring{\emph{Naming}}{Naming}}\label{naming}}

Naming accuracy was very high for all photographs (\emph{M} = 0.95),
indicating that overall, the selected items closely depicted the
intended concepts. Compared with the other stimuli formats, there
appears to be a steady increase in accuracy as items become more
distinctive (see Table 4). Accuracy rates did not differ between the
grey (\emph{M} = 0.94) and colour (\emph{M} = 0.95) versions of the
photographs {[}\(t(745.64) = -0.56\), \(p = .576\){]}.

\emph{H} values were also low across all items (\emph{M} = 0.23),
showing that subjects generally agreed on how the items should be named.
Similar to naming accuracy, naming agreement also appears to steadily
increase as items become more distinctive (as indicated by decreasing H
values - see Table 4. While Rossion \& Pourtois (2004) observed
significantly better naming agreement for their colour - rather than
greyscale - items, this pattern did not reach significance with the
current set of photographs; \emph{H} values did not differ between the
grey (\emph{M} = 0.24) and colour (\emph{M} = 0.22) photographs
{[}\(t(743.66) = 0.62\), \(p = .537\){]}.

A mean reaction time (RT) of (3.9s) was observed for naming responses.
While this was of little interest on its own, and could not be compared
to those obtained in response to the other stimuli formats as our
methodology was slightly different (RTs were only recorded when subjects
had typed their response \emph{and} clicked the mouse to signify they
had finished), they were useful for marking comparisons between the grey
and colour items (though no difference was observed {[}\emph{M} grey =
4s, \emph{M} colour = 3.8s, \(t(651.86) = 1.57\), \(p = .117\){]}).
Overall, these analyses suggest that the current photographs closely
resemble the drawings they were designed to match, with high levels of
naming accuracy and agreement among subjects. The absence of any colour
differences indicates there were no naming advantages when photographs
were made even more distinctive through the addition of colour.

Table 4: Summary statistics for each of the measured variables. Mean
values are presented in bold (SDs are shown in parentheses).

\begin{table}[!h]
\centering
\begin{tabular}{>{\raggedright\arraybackslash}p{13em}>{\centering\arraybackslash}p{3.8em}>{\centering\arraybackslash}p{3.8em}>{\centering\arraybackslash}p{3.8em}>{\centering\arraybackslash}p{2em}>{\centering\arraybackslash}p{3.8em}>{\centering\arraybackslash}p{3.8em}}
\toprule
\multicolumn{1}{c}{ } & \multicolumn{3}{c}{Rossion \& Pourtois (2004)} & \multicolumn{1}{c}{ } & \multicolumn{2}{c}{Current study} \\
\cmidrule(l{3pt}r{3pt}){2-4} \cmidrule(l{3pt}r{3pt}){6-7}
  & S\&V lines & Grey shaded & Colour shaded &    & Grey photos & Colour photos\\
\midrule
\textbf{Naming accuracy} & \textbf{88.2} & \textbf{89.2} & \textbf{90.3} & \textbf{} & \textbf{0.94} & \textbf{0.95}\\
\em{} & \em{(17.1)} & \em{(17.2)} & \em{(16.9)} & \em{} & \em{(0.08)} & \em{(0.08)}\\
\textbf{Naming agreement (H)} & \textbf{0.44} & \textbf{0.38} & \textbf{0.32} & \textbf{} & \textbf{0.24} & \textbf{0.22}\\
\em{} & \em{(0.56)} & \em{(0.52)} & \em{(0.46)} & \em{} & \em{(0.33)} & \em{(0.31)}\\
 &  &  &  &  &  \vphantom{2} & \\
\addlinespace
\textbf{Mental imagery agreement} & \textbf{3.73} & \textbf{3.76} & \textbf{3.74} & \textbf{} & \textbf{3.46} & \textbf{3.74}\\
\em{} & \em{(0.48)} & \em{(0.55)} & \em{(0.63)} & \em{} & \em{(0.56)} & \em{(0.65)}\\
 &  &  &  &  &  \vphantom{1} & \\
\textbf{Familiarity} & \textbf{3.59} & \textbf{3.52} & \textbf{3.44} & \textbf{} & \textbf{4.13} & \textbf{4.19}\\
\em{} & \em{(0.94)} & \em{(1.01)} & \em{(1.01)} & \em{} & \em{(0.56)} & \em{(0.54)}\\
\addlinespace
 &  &  &  &  &  & \\
\textbf{Visual complexity} & \textbf{2.76} & \textbf{2.88} & \textbf{2.7} & \textbf{} & \textbf{2.87} & \textbf{3.16}\\
\em{} & \em{(1.03)} & \em{(1.03)} & \em{(0.94)} & \em{} & \em{(0.62)} & \em{(0.63)}\\
 & - & - & - &  & - & -\\
\textbf{Colour diagnosticity} & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{} & \textbf{-} & \textbf{3.22}\\
\addlinespace
\em{} & \em{-} & \em{-} & \em{-} & \em{} & \em{-} & \em{(0.84)}\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{mental-imagery-agreement}{%
\paragraph{\texorpdfstring{\emph{Mental imagery
agreement}}{Mental imagery agreement}}\label{mental-imagery-agreement}}

Scores of mental imagery agreement were moderate across all items
(\emph{M} = 3.6). While no colour differences were previously observed
between stimuli formats, the grey (\emph{M} = 3.46) photographs in the
current study showed significantly lower mental imagery agreement scores
than the colour (\emph{M} = 3.74) items {[}\(t(800.06) = -6.54\),
\(p < .001\){]}. Comparisons with previous normative data also highlight
how the grey photographs exhibited uniquely poorer mental imagery
agreement scores than any of the other stimuli formats (see Table 4).
RTs between the grey (\emph{M} = 3.04) and colour (\emph{M} = 2.81)
items did not significantly differ {[}\(t(571.37) = 2.14\),
\(p = .033\){]}.

\hypertarget{familiarity}{%
\paragraph{\texorpdfstring{\emph{Familiarity}}{Familiarity}}\label{familiarity}}

Familiarity scores were high overall (\emph{M} = 4.16), and like
previous findings, there was no difference between the grey (\emph{M} =
4.13) and colour (\emph{M} = 4.19) items {[}\(t(813.19) = -1.63\),
\(p = .103\){]}. However, familiarity scores for the current set of
photographs were higher than those obtained for any of the other stimuli
formats, and while there previously appeared to be a decline in
familiarity as stimuli become more distinctive (from line drawings, to
grey shaded, to colour shaded), such a pattern was not evident with the
current photographs (see Table 4). RTs between the grey (\emph{M} =
0.97) and colour (\emph{M} = 0.98) items did not significantly differ
{[}\(t(783.66) = -0.30\), \(p = .762\){]}.

\hypertarget{visual-complexity}{%
\paragraph{\texorpdfstring{\emph{Visual
complexity}}{Visual complexity}}\label{visual-complexity}}

Visual complexity ratings were moderate across all of the items
(\emph{M} = 3.3). Colour (\emph{M} = 3.16) photographs showed
significantly higher scores of visual complexity than grey (\emph{M} =
2.87) photographs {[}\(t(813.51) = -6.65\), \(p < .001\){]}. This
finding is further demonstrated when compared to the scores from the
other stimuli formats (see Table 4); where grey photographs show
comparable levels of visual complexity, the colour photographs show
higher scores than all of the other formats. There was no significant
difference between the RTs of grey (\emph{M} = 3.26) and colour
(\emph{M} = 3.35) items {[}\(t(754.08) = -1.21\), \(p = .228\){]}.

\hypertarget{selection-of-final-items}{%
\paragraph{\texorpdfstring{\emph{Selection of final
items}}{Selection of final items}}\label{selection-of-final-items}}

For each concept represented in the photographs, one variation
(e.g.~shoe-1, shoe-2, or shoe-3) was selected for inclusion in a final
list of stimuli that would be taken forward into subsequent recognition
experiments. The normative naming data was assessed to establish which
version best matched the existing line-drawn depictions of the concepts
(Rossion \& Pourtois, 2004). Naming was favoured over all of the other
variables as, if an item was found to primarily convey a different
concept than was intended during the naming task (e.g.~if a photograph
of the fruit `orange' was labelled `grapefruit' by the majority of
subjects), then it could not be sufficiently compared to its line-drawn
(and written-word) counterpart during recognition studies.

At least 20 unique naming responses were collected for each of the 816
photographs (408 grey items and 408 colour items). The proportion of
`correct' responses (i.e.~names that were congruent with the intended
concept) and the proportion of `don't know' responses were calculated
for each item. Photographs were excluded if they:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  received a high proportion of ``don't know'' responses (20\%; all of
  the photographs depicted common, everyday objects, and so if a number
  of subjects were unable to name the item, that particular photograph
  was considered to be a poor representation of the item);
\item
  were incorrectly named by the majority of subjects (i.e.~if the
  proportion of correct responses equalled ≤ 50\%, since it was
  essential for the photographs to depict the same concepts as those
  found in the line drawings and word stimuli);
\item
  had particularly poor naming agreement (≤ 20\% subjects named the
  object similarly). Items may not have been flagged by the second
  criteria (e.g.~if it received 4 different names, each with a 25\%
  ratio), but could still be considered poor representations of the
  intended concepts.
\end{enumerate}

54 photographs were found to meet at least one of the above criteria,
and therefore excluded. Regardless of whether these items were grey or
colour, it was also necessary to remove its grey or colour partner
(since both versions were needed to make comparisons across recognition
experiments). Thus, a total of 64 items (32 grey / 32 colour) were
excluded at this stage (many items already had both grey and colour
versions flagged by the original criteria).

Next, the proportion of correct responses were compared between grey and
colour photographs in order to identify items showing the lowest
difference. In order to manipulate colour in later recognition
experiments, it was important to select items where naming was congruent
across colour/grey items; in other words, it would be difficult to
attribute particular recognition response patterns to the addition of
colour (if a difference were found) when the grey version could not be
identified (or encoded) similarly. Variations exhibiting the least
difference between colour and grey items (for the proportion of correct
responses) were taken forward, while the rest were excluded. In a number
of instances, multiple variations for the same object had the same
`difference' score. For example, all three variations of the item
``balloon'' exhibited perfect naming agreement, irrespective of whether
they were presented in colour or grey (and thus ``balloon1'',
``balloon2'', and ``balloon3'' had a difference score of 0). For items
where more than 1 variation remained, manual rankings were obtained from
two of the researchers to determine which variation best depicted the
intended concept. For each item, the researchers independently studied
the remaining variations and provided a rank of which they thought was
best (1) to worst (2 or 3, depending on the number of variations that
remained). The ratings from both researchers were collated; items where
there was agreement as to which variation best depicted the intended
concept were selected for inclusion in the final stimuli list. For all
the items where there was disagreement between the researchers rankings,
one of the variations was simply selected at random.

\hypertarget{discussion-1}{%
\subsubsection{Discussion}\label{discussion-1}}

\hypertarget{the-role-of-colour}{%
\paragraph{\texorpdfstring{\emph{The role of
colour}}{The role of colour}}\label{the-role-of-colour}}

For naming responses (accuracy, agreement {[}\emph{H}{]}, and RTs), no
differences were observed between the grey and colour photographs. Such
a result was expected for accuracy and agreement scores; the
addition/absence of colour should not alter how participants identify
(and thus label) items, except in rare instances whereby a lack of
colour may lead to the misidentification of an object (e.g.~incorrectly
labelling a greyscale photograph of an orange as `grapefruit'). The data
indicates, however, that this was not common, with the grey set of
photographs exhibiting equally high levels of naming accuracy as the
colour photographs. The absence of RT differences between the colour and
greyscale sets was not expected for naming responses. It is reasonable
to assume that colour photographs - with an additional layer of
contextual information compared to grey items - would be identified (and
therefore named) quicker than grey photographs (e.g.~a colour photograph
of an orange should avoid the potential ambiguity that might accompany a
greyscale depiction, which could initially be confused for another type
of fruit). Indeed, Rossion \& Pourtois (2004) demonstrated RTs
consistent with this hypotheses, with colour drawings showing
significantly quicker RTs than grey items. The lack of difference in the
current data could be attributable to ceiling effects, whereby all
photographs were sufficiently unambiguous, and were quickly identified
irrespective of whether they were presented in greyscale or colour.
Examination of the other naming data, showing similarly high levels of
accuracy and agreement across grey and colour, supports this notion.

Scores of mental imagery agreement produced particularly interesting
results between the grey and colour items. Grey photographs exhibited a
significantly poorer match with subjects imagined presentation of the
objects than the colour items. Colour differences were not observed
previously between drawings (Rossion \& Pourtois, 2004), and comparing
the current data with that obtained in other studies (see Table 4)
demonstrates how the greyscale photographs show uniquely lower mental
imagery agreement scores compared with any of the other stimuli formats.
To imagine the objects, it seems likely that subjects would conjure an
image of how they naturally see the item in their everyday lives - which
for the majority of subjects, would presumably be a colour
representation. Therefore, when presented with greyscale depictions,
subjects may have been more inclined to report that that item did not
align quite as well as those presented in colour. However, it is unclear
why a similar pattern is not also evident when comparing grey and colour
drawings (Rossion \& Pourtois, 2004). It may be that photographs promote
stricter internal criteria when subjects must decide whether an item is
a good match to their mental image. With line-drawn / illustrated items,
subjects may simply accept that the items are baseline depictions, and
that they will only able to match their real-world mental images to a
certain degree - thus leading to a generally more liberal response bias
throughout. The addition of colour may therefore do very little to
further reconcile the match between the drawing and real-world mental
representation. When subjects are responding only to photographs, the
ecological nature of the items may facilitate deeper critical evaluation
of whether they offer a good match to mental images, and thus promote a
more conservative response bias. Colour may therefore be a far more
important factor in photographs than it is in line drawings for allowing
participants to decide whether an item matches well with their mental
image.

There were no colour differences in familiarity scores. This result was
expected - participants were asked to rate the degree to which they came
in contact with, or think about, the concept itself rather than the
particular depiction shown, and there is no apparent reason why colour
should influence such ratings. Visual complexity, on the other hand,
where participants were required to directly rate the amount of detail
in the picture, did show an expected difference. Colour photographs were
rated as significantly more visually complex than grey items, presumably
due to their additional layer of contextual information. When compared
to the previous data obtained for drawings, the greyscale photographs
showed comparable levels of visual complexity, while the colour
photographs showed higher levels than any of the other formats. It is
unclear why the photographs of the current study showed colour
differences, when grey and colour drawings did not differ, though it may
tie in with the hypotheses proposed to explain the mental imagery
agreement data. Subjects may apply stricter internal criteria when
rating stimuli that are perceived as being closer to how they would be
experienced in real life - when viewing a colour photograph of a rabbit,
it is difficult to see how we could make the item any more visually
complex than it already is (at least in a 2D medium). It's probable that
subjects notice the absence of colour when viewing the greyscale items,
since they depict the items in a way that they are not usually seen, and
thus determine that these items could be made more complex if they were
shown in colour (and so give lower visual complexity ratings as a
result).

\hypertarget{establishing-a-new-set-of-stimuli}{%
\paragraph{\texorpdfstring{\emph{Establishing a new set of
stimuli}}{Establishing a new set of stimuli}}\label{establishing-a-new-set-of-stimuli}}

The objective of the current study was to establish a new set of
ecological photograph stimuli to be taken forward into subsequent
recognition memory experiments. Matching items with previously
established drawings (and words) would allow for the effects of
stimuli-format on recognition response patterns to be directly examined.
A range of normative data was collected for 816 unique photograph items.
These items may prove useful for a range of cognitive researchers that
wish to utilise a set of high quality and realistic object stimuli,
especially given the flexibility of items that can be filtered based on
colour, naming agreement, familiarity, etc. For the needs of the current
body of research, the naming data was used to determine which
photographs best matched the intended concepts among a number of
possible variations. This allowed for the systematic comparison of
recognition memory performance toward three distinct stimuli formats
(words, drawings, and photographs) in the following study, in an effort
to establish how stimuli of varying perceptual distinctiveness may
affect recognition response patterns. Such comparisons might help to
reconcile the inconsistencies present across recognition memory
research, such as those attempted to determine whether familiarity
processes are preserved in those with amnestic Mild Cognitive Impairment
(aMCI).

\hypertarget{experiment-effect-of-stimuli-format-greyscale-and-response-option-on-recognition-memory-judgements.}{%
\subsection{Experiment: Effect of stimuli format (greyscale) and
response option on recognition memory
judgements.}\label{experiment-effect-of-stimuli-format-greyscale-and-response-option-on-recognition-memory-judgements.}}

For the recognition memory experiment, everyday objects were presented
in three stimuli formats: i) words (written in simple, black ink); ii)
drawings (shaded line-drawn illustrations); and iii) photographs (detail
rich exemplars of the real world object). Rossion \& Pourtois (2004)
demonstrated that naming agreement could be improved by adding surface
texture and shading to the original Snodgrass \& Vanderwart (1980)
items; however, it is unclear how manipulations to distinctiveness
actually impact performance in recognition memory paradigms. As well as
general inconsistencies regarding the type of stimuli used in
recognition memory experiments, there is also much variability in the
response options available to participants when reporting their
recognition, for example: Remember/Know (Lombardi et al. (2016)),
Recollection/Familiarity (???), or Low/Med/High confidence (???). In the
current experiment, the availability of different response options when
reporting recognition will also be examined by randomly assigning
participants into a paradigm with three response options (Recollection /
Familiarity / Guessing) or four response options (RFG + Both).

Based on the results of Experiment 1, which compared recognition to for
words and drawings only, a number of hypotheses are proposed as to the
potential effects of adding a third stimuli format (highly distinctive
photograph stimuli). As stimuli become increasingly distinctive (from
words, to drawings, to photographs), it seems likely that the number of
hits (correctly recognised items) will increase, and the number of false
alarms (FAs) will decrease. RFG responses are expected to show a similar
pattern, with the most detailed stimuli showing the highest number of
hits assigned ``Recollection'', while the less detailed formats show
increasing levels of ``Familiarity'' and ``Guessing'' hits. Whilst we
expect the overall number of FAs to increase as stimuli become less
distinctive (i.e.~words will show the highest rate of FAs), there is no
reason to believe that these FAs will be biased toward any particular
RFG judgement across formats. It is also hypothesised that the rates of
reported Recollection and Familiarity will differ across response option
conditions (RFG / RFBG), though the direction of this difference is
currently unclear.

\hypertarget{method-2}{%
\subsubsection{Method}\label{method-2}}

\hypertarget{participants-2}{%
\paragraph{Participants}\label{participants-2}}

A total of 158 subjects completed the online experiment (see Table 5 for
a breakdown of the gender and age of the sample). To meet our YA
requirements, all participants were required to be between 18-59 years
of age (actual range: 18-58). As our experiment involved English word
stimuli, we also asked subjects whether English was their first
language; the vast majority (95.57\%) reported that English was indeed
their first language. Subjects were recruited from voluntary
participation websites such as
Prolific Academic\footnote{\url{https://www.prolific.co/}} (72.78\%),
where payment at the rate of £5/hr was given, and via the in-school
research participation system\footnote{\url{https://keelepsychology.sona-systems.com/}}
(15.19\%), where they received course participation credits. A small
number of participants were also recruited from
Psychological Research on the Net\footnote{\url{https://psych.hanover.edu/research/exponnet.html}}
(12.03\%). In order to detect a medium effect size of Cohen's \emph{f} =
0.25 with 80\% power (\emph{α} = .05, two-tailed), G\emph{Power
indicated that we would need 79 participants per group (}N* = 158) in a
3x2 mixed ANOVA.

Table 5: Gender and age (\emph{SD}) of the current sample.

\begin{table}[!h]
\centering
\begin{tabular}{l>{}rr>{}l}
\toprule
Gender & N & Age &  \\
\midrule
Female & \em{96} & 29.53 & \em{(10.18)}\\
Male & \em{58} & 31.36 & \em{(11.19)}\\
Questioning & \em{1} & 21.00 & \em{(0)}\\
Unspecified & \em{3} & 50.33 & \em{(4.93)}\\
\textbf{Total} & \textbf{\em{158}} & \textbf{30.54} & \textbf{\em{(10.84)}}\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{materials-2}{%
\paragraph{Materials}\label{materials-2}}

A total of 126 innocuous, everyday objects (e.g.~clock, rabbit, shoe)
were presented across three individual stimuli formats: written words,
line drawings, and photographs. The line drawings were obtained from
Rossion \& Pourtois (2004), and consisted of greyscale shaded
illustrations that contained some surface details. The word stimuli were
simply the written word names of the line-drawn objects, presented in a
clear Sans-serif typeface. The photograph stimuli were curated in the
previous study; high quality photographs were sourced to similarly
depict the same everyday objects as the line drawings. All objects in
the photographs were isolated from their original background, converted
to greyscale, and rotated to match the orientations shown in the
line-drawn items.

\hypertarget{design-2}{%
\paragraph{Design}\label{design-2}}

The current study utilised a mixed design, with a 3-level
within-subjects factor of stimuli format (words, drawings, photographs),
and a 2-level between-subjects factor of response option (RFG, RFBG).
Subjects passed through 2 levels of blocked randomization (equally
sized, predetermined blocks); first, participants were randomly assigned
one of six possible study lists (of equal length, and containing an even
number of word, drawing, and photograph items) for counterbalancing
purposes. Subjects were then either assigned into a recognition test
with three possible response options (RFG: ``Recollection'',
``Familiarity'',``Guessing''), or four possible response options (RFBG:
``Recollection'', ``Familiarity'', ``Guessing'', ``Both''). These
randomisation processes were completed automatically by the experiment
software using balanced methods.

~ ~

\includegraphics[width=1\linewidth]{./resources/images/exp3__stim_examples}
~ ~ Figure 10: Example stimuli from the three formats. ~ ~

\hypertarget{procedure-2}{%
\paragraph{Procedure}\label{procedure-2}}

Data was collected online using
Gorilla\footnote{\url{https://gorilla.sc/}} - a platform for the
building and hosting of online experiments. The experiment consisted of
three self-paced phases: i) study phase, ii) distractor task, and iii)
recognition test. In the study phase, an even mix of word, drawing, and
photograph stimuli were presented one-at-a-time on the computer screen.
Subjects were instructed to learn the items in preparation for a later
memory test. To ensure attention was directed to the presented stimuli,
subjects were required to report whether each item was shown as a word,
drawing, or photograph using the computer mouse. Following the study
phase, participants completed some simple multiple choice mathematical
questions (e.g.~6 x 4 = ?) as a distractor. Finally, participants memory
of the previously studied items was testing in the recognition task. An
even mix of word, drawing, and photograph stimuli were again presented
one-at-a-time on the screen; half of the test items had been shown
previously in the study phase, while the other half were new (and were
not on the study list). For each item, subjects were instructed to press
``Old'' if they believed it was an item they had studied earlier, and
``New'' if they had not. ``Old'' responses led to a follow-up judgement,
where participants reported whether they had experienced recognition
through ``Recollection'', ``Familiarity'', or were simply taking an
uninformed ``Guess''. Participants that had been randomised into the
RFBG test condition had a fourth option here, whereby they could report
that they had experienced Recollection and Familiarity simultaneously
(``Both''). Stimuli format was congruent across the study and test
blocks (e.g.~items presented as photos at study were also presented as
photos at test). For each concept depicted across the three stimuli
formats, subjects were only presented with one variation (in other
words, if a subject saw a photograph for the item ``shoe'', they did not
see the word or line-drawn version of ``shoe'').

\hypertarget{data-processing-2}{%
\paragraph{Data processing}\label{data-processing-2}}

Measured variables included the total number of hits and FAs, and the
total number of hits and FAs assigned to each of the available response
options (R/F/G and R/F/B/G). In order to create a common dependant
variable, proportions were calculated from these variables slightly
differently depending on the response option group. In the RFG-judgement
group, simple proportions were created from the total number of R
responses and the total number of F responses. In the RFBG condition,
however, the proportion of Both responses was separately added to R
proportions and F proportions. Additional DVs included: i) d' (d-prime,
a signal detection measure of sensitivity); ii) c-value (a measure of
response bias); iii) overall accuracy (hits / (hits + FAs)); iv)
reaction times for all responses.

Participants were excluded from analysis if they showed poor performance
during the encoding task; the relative ease of reporting whether each
item was shown as a word, drawing, or photograph prompted a performance
cut off of 90\% accuracy. This allowed for some accidental clicks /
incorrect responses toward potentially ambiguous items, though subjects
scoring less than 90\% were excluded on the assumption they did not
dedicate their full attention to the task. Subjects with extreme
z-scores were also excluded from analysis; those presenting z-scores of
+/- 3 (for total hits, total FAs, or overall recognition {[}hits minus
FAs{]}) were considered outliers. These criteria resulted in the
exclusion of 11 datasets.

\hypertarget{results-2}{%
\subsubsection{Results}\label{results-2}}

A series of 3x2 repeated measures ANOVAs were conducted on each of the
DVs using a within-subjects factor of stimuli format (photographs /
drawings / words) and a between-subjects factor of response option (RFG
/ RFBG). Significant main effects and interaction effects were
followed-up with Bonferroni-adjusted pairwise comparisons.

\hypertarget{overall-hits-false-alarms-fas-and-recognition}{%
\paragraph{Overall hits, false alarms (FAs), and
recognition}\label{overall-hits-false-alarms-fas-and-recognition}}

Separate 3 (stimuli format: words, drawings, photographs) x 2 (response
option condition: RFG-judgements, RFBG-judgements) mixed ANOVAs were
conducted on the mean proportion of hits and false alarms (FAs; see
Table 6).

\newpage

Table 6: Mean proportion of hits and FAs by stimuli format and response
option condition.

\begin{table}[!h]
\centering
\begin{tabular}{>{\raggedright\arraybackslash}p{4cm}rr}
\toprule
  & Hits & FAs\\
\midrule
\addlinespace[0.3em]
\multicolumn{3}{l}{\textbf{Stimuli format}}\\
\hspace{1em}Words & 0.55 & 0.21\\
\hspace{1em}Drawings & 0.76 & 0.09\\
\hspace{1em}Photographs & 0.86 & 0.05\\
\addlinespace[0.3em]
\multicolumn{3}{l}{\textbf{Response option}}\\
\hspace{1em}RFG & 0.78 & 0.13\\
\hspace{1em}RFBG & 0.74 & 0.11\\
\bottomrule
\end{tabular}
\end{table}

~

For the proportion of total hits, there was a significant main effect of
stimuli format {[}\(F(1.75, 273.58) = 229.89\), \(\mathit{MSE} = 0.02\),
\(p < .001\), \(\hat{\eta}^2_G = .346\){]}. The interaction effect was
not significant {[}\(F(1.75, 273.58) = 0.74\), \(\mathit{MSE} = 0.02\),
\(p = .461\), \(\hat{\eta}^2_G = .002\){]}. Post-hoc comparisons for the
main effect of stimuli format showed that photographs (\(M = 0.86\))
produced a significantly higher proportion of hits than both words
(\(M = 0.55\)) {[}{]} and drawings (\(M = 0.76\)) {[}{]}. Drawings
(\(M = 0.76\)) also produced a significantly higher proportion of hits
compared to words (\(M = 0.55\)) {[}{]}.

There was also a significant main effect of stimuli format for the
proportion of total FAs {[}\(F(1.46, 227.29) = 106.64\),
\(\mathit{MSE} = 0.01\), \(p < .001\), \(\hat{\eta}^2_G = .243\){]};
photographs (\(M = 0.05\)) produced a significantly lower proportion of
FAs than both words
(\texttt{rexp3\_\ apa\_\_grey\_\_anova\_\_PROP.FA\_\_words.mean}) {[}{]}
and drawings (\(M = 0.09\)) {[}{]}; drawings (\(M = 0.09\)) produced a
significantly lower proportion of FAs compared to words (\(M = 0.21\))
{[}{]}. The interaction effect was not significant
{[}\(F(1.46, 227.29) = 1.22\), \(\mathit{MSE} = 0.01\), \(p = .287\),
\(\hat{\eta}^2_G = .004\){]}.

For overall performance accuracy, there was a significant main effect of
stimuli format {[}\(F(1.93, 300.97) = 586.13\), \(\mathit{MSE} = 0.02\),
\(p < .001\), \(\hat{\eta}^2_G = .549\){]}. The interaction effect was
not significant {[}\(F(1.93, 300.97) = 2.02\), \(\mathit{MSE} = 0.02\),
\(p = .136\), \(\hat{\eta}^2_G = .004\){]}. Post-hoc comparisons for the
main effect of stimuli format showed that photographs (\(M = 0.81\))
produced significantly better performance accuracy than both words
(\(M = 0.34\)) {[}{]} and drawings (\(M = 0.67\)) {[}{]}. Drawings
(\(M = 0.67\)) also produced significantly better performance accuracy
compared to words (\(M = 0.34\)) {[}{]}.

\hypertarget{discrimination-d-and-response-bias-c}{%
\paragraph{Discrimination (d') and response bias
(c)}\label{discrimination-d-and-response-bias-c}}

To assess the roles of discrimination and response bias, separate 3
(stimuli format: words, drawings, photographs) x 2 (response option
condition: RFG-judgements, RFBG-judgements) mixed ANOVAs were conducted
on the values of d' (d-prime; measure of sensitivity) and c (decision
criterion; see Table 7).

Table 7: d' and c values by stimuli format and response option
condition.

\begin{table}[!h]
\centering
\begin{tabular}{>{\raggedright\arraybackslash}p{4cm}rr}
\toprule
  & d' & c\\
\midrule
\addlinespace[0.3em]
\multicolumn{3}{l}{\textbf{Stimuli format}}\\
\hspace{1em}Words & 1.06 & 0.39\\
\hspace{1em}Drawings & 2.18 & 0.32\\
\hspace{1em}Photographs & 2.78 & 0.22\\
\addlinespace[0.3em]
\multicolumn{3}{l}{\textbf{Response option}}\\
\hspace{1em}RFG & 0.10 & 0.01\\
\hspace{1em}RFBG & 0.10 & 0.01\\
\bottomrule
\end{tabular}
\end{table}

~

For d' scores, there was a significant interaction between stimuli
format and response option {[}\(F(2.00, 311.73) = 3.60\),
\(\mathit{MSE} = 0.26\), \(p = .029\), \(\hat{\eta}^2_G = .008\){]} (see
Figure 11). Photographs (\(M = 2.86\)) facilitated better discrimination
between hits / FAs than both words (\(M = 1.13\))
{[}\(t(312.00) = -21.66\), \(p < .001\){]} and drawings (\(M = 2.13\))
{[}\(t(312) = -9.13\), \(p < .001\){]} in the RFG group. Drawings
(\(M = 2.13\)) also showed significantly higher d' scores compared to
words (\(M = 1.13\)) {[}\(t(312) = -12.53\), \(p < .001\){]}. In the
RFBG group, the same pattern was evident; photographs (\(M = 2.69\))
facilitated better discrimination than both words (\(M = 0.98\))
{[}\(t(312) = -20.79\), \(p < .001\){]} and drawings (\(M = 2.24\))
{[}\(t(312) = -5.53\), \(p < .001\){]}. Again, drawings (\(M = 2.24\))
also showed significantly higher d' scores than words (\(M = 0.98\))
{[}\(t(319.09) = -10.22\), \(p < .001\){]}.

Comparisons of stimuli format across the response option groups showed
that d' scores for photographs did not significantly differ between the
RFG (\(M = 2.86\)) and RFBG (\(M = 2.69\)) conditions
{[}\(t(319.09) = 1.43\), \(p > .999\){]}, nor for drawings (RFG:
\(M = 2.13\), RFBG: \(M = 2.24\), {[}\(t(319.09) = -0.96\),
\(p > .999\){]}, nor for words (RFG: \(M = 1.13\), RFBG: \(M = 0.98\),
{[}\(t(319.09) = 1.39\), \(p > .999\){]}).

~

\includegraphics{R--Thesis_files/figure-latex/unnamed-chunk-35-1.pdf}
Figure 12: Interaction plot between stimuli format and response option
for d' scores.

c-scores showed a significant main effect of stimuli format
{[}\(F(1.74, 272.11) = 10.25\), \(\mathit{MSE} = 0.13\), \(p < .001\),
\(\hat{\eta}^2_G = .025\){]}, with photographs (\(M = 0.22\))
demonstrating significantly lower c-scores (and thus a less conservative
response bias) than words (\(M = 0.39\)) {[}{]} and drawings
(\(M = 0.32\)) {[}{]}. Photographs may have uniquely provided subjects
with additional confidence that their old/new response was correct in
comparison to the other stimuli formats; there was no difference in
c-scores between drawings (\(M = 0.32\)) and words (\(M = 0.39\))
{[}{]}. There were no significant interaction effects
{[}\(F(1.74, 272.11) = 0.62\), \(\mathit{MSE} = 0.13\), \(p = .518\),
\(\hat{\eta}^2_G = .002\){]}.

\hypertarget{hits-assigned-recollection-familiarity-and-guessing}{%
\paragraph{Hits assigned Recollection, Familiarity, and
Guessing}\label{hits-assigned-recollection-familiarity-and-guessing}}

To determine the effects of stimuli format and response option on
accurate recognition memory judgements, separate 3 (stimuli format:
words, drawings, photographs) x 2 (response option condition:
RFG-judgements, RFBG-judgements) mixed ANOVAs were conducted on the mean
proportion of hits assigned Recollection, Familiarity, and Guessing (see
Figure 13).

\includegraphics{R--Thesis_files/figure-latex/unnamed-chunk-38-1.pdf}
Figure 13: Proportion of hits assigned Recollection, Familiarity, and
Guessing, by stimuli format and response option condition.

\hypertarget{recollection-hits}{%
\subparagraph{Recollection (hits)}\label{recollection-hits}}

For hits assigned Recollection, there was a significant interaction
effect {[}\(F(1.77, 273.98) = 5.32\), \(\mathit{MSE} = 0.03\),
\(p = .007\), \(\hat{\eta}^2_G = .010\){]} (see Figure 14). Photographs
(\(M = 0.79\)) resulted in more Recollection hits than both words
(\(M = 0.34\)) {[}\(t(310) = -17.90\), \(p < .001\){]} and drawings
(\(M = 0.63\)) {[}\(t(310) = -6.38\), \(p < .001\){]} in the RFG group.
Drawings (\(M = 0.63\)) also resulted in more Recollection hits than
words (\(M = 0.34\)) {[}\(t(310) = -11.52\), \(p < .001\){]} in the RFG
group. In the RFBG group, there was an identical pattern; photographs
(\(M = 0.79\)) resulted in more Recollection hits than both words
(\(M = 0.46\)) {[}\(t(310) = -12.62\), \(p < .001\){]} and drawings
(\(M = 0.69\)) {[}\(t(310) = -3.59\), \(p = .006\){]}. Drawings
(\(M = 0.69\)) also resulted in more Recollection hits than words
(\(M = 0.46\)) {[}\(t(310) = -9.03\), \(p < .001\){]} in the RFBG group.
Comparisons of stimuli format across the response option groups showed
no difference in the number of Recollection hits for photograph stimuli
between the RFG (\(M = 0.79\)) and RFBG (\(M = 0.79\)) conditions
{[}\(t(278.97) = 0.05\), \(p > .999\){]}. The same pattern was evident
for drawings (RFG: \(M = 0.63\), RFBG: \(M = 0.69\)
{[}\(t(278.97) = -1.62\), \(p > .999\){]}). Word stimuli, however,
produced significantly more Recollection hits in the RFBG group
(\(M = 0.46\)) compared to the RFG (\(M = 0.34\)) group
{[}\(t(278.97) = -2.94\), \(p = .053\){]}.

~

\includegraphics{R--Thesis_files/figure-latex/unnamed-chunk-39-1.pdf}
Figure 14: Interaction plot between stimuli format and response option
for the mean proportion of hits assigned Recollection.

\hypertarget{familiarity-hits}{%
\subparagraph{Familiarity (hits)}\label{familiarity-hits}}

For hits assigned Familiarity, there was a significant interaction
between stimuli format and response option
{[}\(F(1.52, 236.21) = 8.68\), \(\mathit{MSE} = 0.04\), \(p = .001\),
\(\hat{\eta}^2_G = .016\){]} (see Figure 15). Within the RFG condition,
words (\(M = 0.45\)) resulted in more Familiarity hits than both
drawings (\(M = 0.28\)) {[}\(t(310) = 5.84\), \(p < .001\){]} and
photographs (\(M = 0.17\)) {[}\(t(310) = 9.80\), \(p < .001\){]}.
Drawings (\(M = 0.28\)) also produced more Familiarity hits compared to
photographs (\(M = 0.17\)) {[}\(t(310) = 3.96\), \(p = .001\){]}.

Within the RFBG condition, words (\(M = 0.54\)) still produced more
Familiarity hits than photographs (\(M = 0.43\)) {[}\(t(310) = 3.61\),
\(p = .005\){]}. However, there was no difference in the number of
Familiarity hits when comparing words (\(M = 0.54\)) to drawings
(\(M = 0.46\)) {[}\(t(310) = 2.53\), \(p = .178\){]}. Another difference
from the within-RFG findings is the number of Familiarity hits for
drawings (\(M = 0.46\)) did not differ from photographs (\(M = 0.43\))
in the RFBG condition {[}\(t(310) = 1.08\), \(p > .999\){]}.

Comparisons across response option conditions showed that drawings
produced significantly more Familiarity hits in the RFBG (\(M = 0.46\))
condition compared to RFG (\(M = 0.28\)) {[}\(t(289.15) = -4.14\),
\(p = .001\){]}. A similar pattern was also evident for photographs
(RFG: \(M = 0.17\), RFBG: \(M = 0.43\) {[}\(t(289.15) = -6.00\),
\(p < .001\){]}). Words, however, showed no difference in the number of
Familiarity hits between the RFG (\(M = 0.45\)) and RFBG (\(M = 0.54\))
conditions {[}\(t(289.15) = -2.06\), \(p = .611\){]}.

~

\includegraphics{R--Thesis_files/figure-latex/unnamed-chunk-40-1.pdf}
Figure 15: Interaction plot between stimuli format and response option
for the mean proportion of hits assigned `Familiarity'.

\hypertarget{guessing-hits}{%
\subparagraph{Guessing (hits)}\label{guessing-hits}}

For hits assigned Guessing, there was a significant main effect of
stimuli format {[}\(F(1.32, 204.20) = 71.22\), \(\mathit{MSE} = 0.02\),
\(p < .001\), \(\hat{\eta}^2_G = .142\){]}. The interaction effect was
not significant {[}\(F(1.32, 204.20) = 1.12\), \(\mathit{MSE} = 0.02\),
\(p = .308\), \(\hat{\eta}^2_G = .003\){]}. Post-hoc comparisons for the
main effect of stimuli format showed that words (\(M = 0.18\)) produced
significantly more Guessing hits than both drawings (\(M = 0.08\))
{[}{]} and photographs (\(M = 0.03\)) {[}{]}. Drawings (\(M = 0.08\))
also produced significantly more Guessing hits compared to photographs
(\(M = 0.03\)) {[}{]}.

\hypertarget{fas-assigned-recollection-familiarity-and-guessing}{%
\paragraph{FAs assigned Recollection, Familiarity, and
Guessing}\label{fas-assigned-recollection-familiarity-and-guessing}}

To determine the effects of stimuli format and response option on false
alarms, separate 3 (stimuli format: words, drawings, photographs) x 2
(response option condition: RFG-judgements, RFBG-judgements) mixed
ANOVAs were conducted on the mean proportion of FAs assigned
Recollection, Familiarity, and Guessing (see Figure 16).

\includegraphics{R--Thesis_files/figure-latex/unnamed-chunk-42-1.pdf}
Figure 16: Proportion of FAs assigned Recollection, Familiarity, and
Guessing, by stimuli format and response option condition.

\hypertarget{recollection-fas}{%
\subparagraph{Recollection (FAs)}\label{recollection-fas}}

For FAs assigned Recollection, there was no significant main effect of
stimuli format {[}\(F(1.94, 301.96) = 1.11\), \(\mathit{MSE} = 0.07\),
\(p = .328\), \(\hat{\eta}^2_G = .003\){]} or interaction
{[}\(F(1.94, 301.96) = 2.02\), \(\mathit{MSE} = 0.07\), \(p = .136\),
\(\hat{\eta}^2_G = .006\){]}.

\hypertarget{familiarity-fas}{%
\subparagraph{Familiarity (FAs)}\label{familiarity-fas}}

For FAs assigned Familiarity, there was a significant interaction
between stimuli format and response option
{[}\(F(1.98, 309.33) = 3.33\), \(\mathit{MSE} = 0.11\), \(p = .038\),
\(\hat{\eta}^2_G = .010\){]} (see Figure 17). Within the RFG condition,
words (\(M = 0.41\)) resulted in more Familiarity FAs than photographs
(\(M = 0.26\)) {[}\(t(312) = 2.96\), \(p = .050\){]}, but not drawings
(\(M = 0.40\)) {[}\(t(312) = 0.20\), \(p > .999\){]}. The number of
Familiarity FAs did not differ between drawings (\(M = 0.40\)) and
photographs (\(M = 0.26\)) {[}\(t(312) = 2.76\), \(p = .091\){]} in the
RFG condition.

Within the RFBG condition, words (\(M = 0.47\)) again produced more
Familiarity FAs than photographs (\(M = 0.30\)) {[}\(t(312) = 3.06\),
\(p = .036\){]}. However, words (\(M = 0.47\)) also produced more
Familiarity FAs than drawings(\(M = 0.28\)) {[}\(t(312) = 3.39\),
\(p = .012\){]}. As before, the number of Familiarity FAs did not differ
between drawings (\(M = 0.28\)) and photographs (\(M = 0.30\)) in the
RFBG condition {[}\(t(312) = -0.33\), \(p > .999\){]}.

Comparisons across response option conditions showed no differences in
the number of Familiarity FAs, for any stimuli format: words (RFG:
\(M = 0.41\), RFBG: \(M = 0.47\) {[}\(t(404.98) = -0.86\),
\(p > .999\){]}); drawings (RFG: \(M = 0.40\), RFBG: \(M = 0.28\)
{[}\(t(404.98) = 1.91\), \(p = .859\){]}; photographs (RFG:
\(M = 0.26\), RFBG: \(M = 0.30\) {[}\(t(404.98) = -0.68\),
\(p > .999\){]}).

~

\includegraphics{R--Thesis_files/figure-latex/unnamed-chunk-43-1.pdf}
Figure 17: Interaction plot between stimuli format and response option
for the mean proportion of FAs assigned `Familiarity'.

\hypertarget{guessing-fas}{%
\subparagraph{Guessing (FAs)}\label{guessing-fas}}

For FAs assigned Guessing, there was a significant main effect of
stimuli format {[}\(F(1.93, 300.68) = 9.44\), \(\mathit{MSE} = 0.09\),
\(p < .001\), \(\hat{\eta}^2_G = .033\){]}. The interaction effect was
not significant {[}\(F(1.93, 300.68) = 0.35\), \(\mathit{MSE} = 0.09\),
\(p = .699\), \(\hat{\eta}^2_G = .001\){]}. Post-hoc comparisons for the
main effect of stimuli format showed that words (\(M = 0.27\)) produced
significantly more Guessing FAs than both drawings (\(M = 0.18\)) {[}{]}
and photographs (\(M = 0.13\)) {[}{]}. There was no difference in the
proportion of FAs assigned Guessing between drawings (\(M = 0.18\)) and
photographs (\(M = 0.13\)) {[}{]}.

\hypertarget{discussion-2}{%
\subsubsection{Discussion}\label{discussion-2}}

Across a range of performance variables, the results show a clear effect
of stimuli distinctiveness. As distinctiveness increased (from words, to
drawings, to photographs), this produced more hits, less FAs, better
overall recognition, and better discrimination between hits / FAs. The
absence of any interaction effects across these variables demonstrates
that the availability of different response options (i.e.~the addition
of a Both option) had little impact on overall performance. RF(B)G
responses for accurate recognition displayed a similar pattern; as
distinctiveness increased, the number of Recollected hits also
increased, while the number of Familiarity and Guessing hits decreased.
The rate of both Familiarity FAs and Guessing FAs was also highest for
the least distinctive stimuli (words).

\#\#\#\#\#\#----------------------------------------

\newpage

\hypertarget{chapter-4-the-role-of-colour}{%
\section{Chapter 4 (The role of
colour)}\label{chapter-4-the-role-of-colour}}

\hypertarget{experiment-effect-of-stimuli-format-colour-and-response-option-on-recognition-memory-judgements.}{%
\subsection{Experiment: Effect of stimuli format (colour) and response
option on recognition memory
judgements.}\label{experiment-effect-of-stimuli-format-colour-and-response-option-on-recognition-memory-judgements.}}

\hypertarget{method-3}{%
\subsubsection{Method}\label{method-3}}

\hypertarget{participants-3}{%
\paragraph{Participants}\label{participants-3}}

161 participants completed the experiment online (see Table 8 for a
breakdown of the age/gender of the current sample). All participants
were required to be between the age of 18-59 years in order to meet our
YA criteria (actual range: 18-57). As our experiment involved written
words as to-be-remembered stimuli, we also asked that subjects first
language be English; the vast majority (96.89\%) reported that English
was indeed their first language. Subjects were recruited from the
voluntary participation website
*Prolific Academic*\footnote{\url{https://www.prolific.co/}} (86.34\%),
where payment at the rate of £5/hr was given, and via the in-school
research participation system\footnote{\url{https://keelepsychology.sona-systems.com/}}
(13.66\%), where they received course participation credits.
\emph{G*Power} software was used to calculate an appropriate sample
size; to detect a medium effect size of Cohen's \emph{f} = 0.25 with
80\% power (\emph{α} = .05, two-tailed), 79 subjects were necessary per
group (\emph{N} = 158) in a 3x2 mixed ANOVA.

Table 8: Gender and age (\emph{SD}) of the current sample.

\begin{table}[!h]
\centering
\begin{tabular}{l>{}rr>{}l}
\toprule
Gender & N & Age &  \\
\midrule
Female & \em{97} & 31.78 & \em{(11.18)}\\
Male & \em{60} & 31.77 & \em{(10.3)}\\
Transgender & \em{1} & 32.00 & \em{(0)}\\
Non-binary & \em{1} & 19.00 & \em{(0)}\\
Unspecified & \em{2} & 38.50 & \em{(3.54)}\\
\addlinespace
\textbf{Total} & \textbf{\em{161}} & \textbf{31.78} & \textbf{\em{(10.76)}}\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{materials-3}{%
\paragraph{Materials}\label{materials-3}}

Stimuli were the same as those utilised in \emph{Experiment 3}, only
with the greyscale drawings and photographs substituted for their colour
versions. Items consisted of 126 innocuous, everyday objects
(e.g.~clock, rabbit, shoe), presented across three individual stimuli
formats: written words, line drawings, and photographs. Words and line
drawings were sourced from Rossion \& Pourtois (2004); the drawings
consisted of shaded, colour illustrations, and the words were simply the
written names of the depicted objects (these were presented in a clear
Sans-serif typeface in the current experiment). A matching set of
photograph stimuli were curated in \emph{Experiment 2}; high quality
photographs were sourced to similarly depict the same everyday objects
as those found in the Rossion \& Pourtois (2004) line drawings. In each
photograph, the object of interest was isolated from its' original
background and rotated to match the orientations shown in the line-drawn
items. See Figure 18 for examples of each stimuli format.

\hypertarget{design-3}{%
\paragraph{Design}\label{design-3}}

A mixed 3x2 design was utilised, consisting of a within-subjects factor
of stimuli format (words, drawings, photographs) and a between-subjects
factor of response option (RFG, RFBG). Blocked randomisation presented
participants with: 1) one of six possible study lists (equal length,
with the same number of words, drawings, and photographs); 2) one of two
possible recognition tests (either RFG: ``Recollection'',
``Familiarity'', ``Guessing''), or RFBG: ``Recollection'',
``Familiarity'', ``Guessing'', ``Both''). All routes were of equal
length, and subjects were randomly assigned into blocks according to
balanced methods.

~ ~

\includegraphics[width=1\linewidth]{./resources/images/exp4__stim_examples}
~ ~ Figure 18: Example word, drawing, and photograph stimuli. ~ ~

\hypertarget{procedure-3}{%
\paragraph{Procedure}\label{procedure-3}}

The procedure was identical to that of \emph{Experiment 3}; data
collection was conducted online using the experiment platform
Gorilla\footnote{\url{https://gorilla.sc/}}. All subjects completed
three self-paced phases: i) study phase, ii) distractor task, and iii)
recognition test. At study, subjects were instructed to learn each of
the word, drawing, and photograph items (shown at random, one-at-a-time)
in preparation for a later memory test. For each item, participants were
required to report whether the current format was a word, drawing, or
photograph - an encoding judgement that ensured attention was directed
to the to-be-remembered stimuli. Next, subjects completed some simple
multiple choice mathematical questions (e.g.~6 x 4 = ?) as a distractor
task. Finally, participants were presented with the recognition test;
word, drawing, and photograph items were once again shown one-at-a-time
at random. Half of the test items had been shown previously in the study
phase, while the other half were new (not shown at study). Subjects were
fist required to make an ``Old'' / ``New'' judgement, based on whether
they believed they had studied the item earlier or not. While ``New''
judgements simply led to the next item, ``Old'' judgements led to a
follow-up screen where participants were asked whether they had
recognised the item via ``Recollection'', ``Familiarity'', or were
simply taking a ``Guess'' that it was old. Those in the RFBG response
option condition had an additional ``Both'' option at this stage, where
they could report that they had experienced Recollection and Familiarity
simultaneously. Stimuli format stayed the same across study and test
(e.g.~if they item ``penguin'' was shown as a word at study, it was also
shown as a word at test), and same concepts were not repeated across the
other formats within-subjects (e.g.~if the item ``penguin'' was shown as
a word, that subject would not view the drawing or photo version).

\hypertarget{data-processing-3}{%
\paragraph{Data processing}\label{data-processing-3}}

The primary DVs consisted of the proportion of total hits, false alarms
(FAs), and the total number of hits and FAs assigned to each of the
available response options (R/F/G and R/F/B/G). Proportions of
Recollection and Familiarity were calculated slightly differently
depending on the response option condition; in the RFG-judgement group,
simple proportions were created from the total number of R responses and
the total number of F responses. In the RFBG condition, Both responses
was separately added to R proportions and F proportions. Additional DVs
included: i) d' (d-prime, a signal detection measure of sensitivity);
ii) c-value (a measure of response bias); iii) overall accuracy (hits /
(hits + FAs)); iv) reaction times for all responses.

Subjects were excluded according to a two key criteria; 1) less than
90\% accuracy during the encoding task (``Is this a word, drawing, or
photograph?''); 2) extreme z-scores (those presenting z-scores of +/- 3
for total hits, total FAs, or overall recognition {[}hits minus FAs{]}).
A total of 3 participants were found to meet (at least) one of such
criteria, and were thus considered outliers and excluded from analysis.

\newpage

\hypertarget{results-3}{%
\subsubsection{Results}\label{results-3}}

\hypertarget{distinctiveness}{%
\paragraph{Distinctiveness}\label{distinctiveness}}

To determine whether colour photographs were more distinctive than
colour drawings, and examine any potential interactions with
response-option condition, a series of 2 (stimuli format: words,
pictures) x 3 (response option condition: RFG-judgements,
RFBG-judgements, RF-ratings) mixed ANOVAs were conducted on the
proportion of overall hits, false alarms (FAs), and overall recognition
(hits - FAs) {[}see Table 9{]}. To further examine response patterns
between the stimuli formats, 2x3 mixed ANOVAs were also run on the
signal detection measures of \emph{d'} (sensitivity) and \emph{c}
(decision criterion). Significant main effects were followed up with
single pairwise comparisons (drawings vs.~photographs).

~ ~ Table 9: Mean proportion of hits, FAs, and overall recognition, by
stimuli format and response option condition.

\begin{table}[!h]
\centering
\begin{tabular}{>{\raggedright\arraybackslash}p{3.6cm}>{\raggedright\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{2cm}}
\toprule
  & Hits & FAs & Overall recognition\\
\midrule
\addlinespace[0.3em]
\multicolumn{4}{l}{\textbf{Stimuli format}}\\
\hspace{1em}Words & 0.56 & 0.23 & 0.33\\
\hspace{1em}Drawings & 0.73 & 0.08 & 0.65\\
\hspace{1em}Photographs & 0.87 & 0.04 & 0.83\\
\addlinespace[0.3em]
\multicolumn{4}{l}{\textbf{Response option}}\\
\hspace{1em}RFG & 0.74 & 0.13 & 0.60\\
\hspace{1em}RFBG & 0.70 & 0.10 & 0.60\\
\bottomrule
\end{tabular}
\end{table}

~

Visual inspection of the data (Table 9) shows some expected patterns
with regard to stimuli distinctiveness. As the intended distinctiveness
increases across the formats (from words, to drawings, to photographs),
the mean proportion of hits increases, the mean proportion of FAs
decreases, and overall scores of recognition (hits - FAs) also
increases. These patterns support the notion that distinctiveness plays
a key role in the memorability of stimuli, and also that the current
stimuli indeed appear to capture different `levels' of stimuli
distinctiveness. The ANOVA on the proportion of hits demonstrated a
significant main effect of stimuli-format, \(F(1.70, 271.03) = 187.25\),
\(\mathit{MSE} = 0.02\), \(p < .001\), \(\hat{\eta}^2_G = .311\); a
distinctiveness effect was apparent, with colour photographs
(\(M = 0.87\)) showing a higher number of overall hits compared to
colour drawings (\(M = 0.73\)), \(t(318) = -8.53\), \(p < .001\).
Similarly, the ANOVA on the proportion of FAs also supported a
distinctiveness effect; a significant main effect of stimuli-format
\(F(1.26, 200.79) = 123.14\), \(\mathit{MSE} = 0.02\), \(p < .001\),
\(\hat{\eta}^2_G = .279\) showed that drawings (\(M = 0.08\)) produced
more FAs than photographs (\(M = 0.04\)), \(t(318) = 3.07\),
\(p = .002\). Overall recognition performance (taking into account hits
and FAs) offered further support for a distinctiveness effect; a
significant main effect of stimuli-format \(F(1.79, 284.84) = 527.35\),
\(\mathit{MSE} = 0.02\), \(p < .001\), \(\hat{\eta}^2_G = .550\) showed
photographs (\(M = 0.83\)) produced better overall task performance
compared to drawings (\(M = 0.65\)), \(t(318) = -11.38\), \(p < .001\).
Taken together, the findings support the distinctiveness hypothesis, in
that colour photographs were recognised better than colour drawings.

The ANOVA on \emph{d'}-scores produced findings consistent with those
found for hits, FAs, and overall recognition; there was a significant
main effect of stimuli-format, \(F(1.92, 305.18) = 497.69\),
\(\mathit{MSE} = 0.30\), \(p < .001\), \(\hat{\eta}^2_G = .543\),
whereby photographs (\(M = 2.87\)) facilitated better discrimination
between hits and FAs than drawings (\(M = 2.13\)), \(t(318) = -12.41\),
\(p < .001\). \emph{c}-scores also showed a significant main effect of
stimuli-format, \(F(1.61, 256.18) = 7.21\), \(\mathit{MSE} = 0.17\),
\(p = .002\), \(\hat{\eta}^2_G = .018\), with drawings (\(M = 0.37\))
showing higher \emph{c}-scores (and thus a more conservative response
bias) than photographs (\(M = 0.22\)), \(t(318) = 3.57\), \(p < .001\).

\hypertarget{response-option}{%
\paragraph{Response option}\label{response-option}}

In each of the previously discussed ANOVAs, the role of response option
was also assessed. However, there were no significant interaction
effects between stimuli format and response option for any of the
examined DVs: i) proportion of hits; ii) proportion of FAs; iii) overall
recognition; iv) \emph{d'}-scores; v) \emph{c}-scores. There was only a
significant main effect of response option in the ANOVA on the mean
proportion of FAs, \(F(1, 159) = 5.25\), \(\mathit{MSE} = 0.02\),
\(p = .023\), \(\hat{\eta}^2_G = .016\) (with the RFG group,
\(M = 0.13\), showing more FAs than the RFBG group, \(M = 0.10\),
\(t(159) = 2.29\), \(p = .023\)), and the ANOVA on \emph{c}-scores,
\(F(1, 159) = 4.85\), \(\mathit{MSE} = 0.39\), \(p = .029\),
\(\hat{\eta}^2_G = .018\) (with the RFBG group, \(M = 0.38\), showing a
more conservative response bias than the RFG group, \(M = 0.25\),
\(t(159) = -2.20\), \(p = .029\))

\hypertarget{role-of-colour}{%
\paragraph{Role of colour}\label{role-of-colour}}

Visual inspection of the data from \emph{Experiment 3}, which used
greyscale drawings and photographs, alongside that obtained in the
current study (Figure 19) suggests the effects of colour on
distinctiveness are negligible. Performance, in terms of the proportion
of hits, FAs, and overall recognition accuracy, appears the same
irrespective of whether greyscale or colour pictures were used.

\includegraphics{R--Thesis_files/figure-latex/unnamed-chunk-57-1.pdf}
Figure 19: Grey vs.~colour

In turn, this further implicates the stimuli format as the

\includegraphics{R--Thesis_files/figure-latex/unnamed-chunk-59-1.pdf}

\hypertarget{discussion-3}{%
\subsubsection{Discussion}\label{discussion-3}}

\#\#\#\#\#\#----------------------------------------

\newpage

\hypertarget{chapter-5-distinctiveness-of-word-stimuli}{%
\section{Chapter 5 (Distinctiveness of word
stimuli)}\label{chapter-5-distinctiveness-of-word-stimuli}}

\hypertarget{experiment-manipulating-word-distinctiveness}{%
\subsection{Experiment: Manipulating word
distinctiveness}\label{experiment-manipulating-word-distinctiveness}}

\hypertarget{method-4}{%
\subsubsection{Method}\label{method-4}}

All stimuli were presented as 500x500px image files at their actual size
(i.e.~without scaling) to ensure consistency across participants. Adobe
Photoshop 2021 (22.0.0 Release) was used to create the image files, all
on a plain white canvas. The Rossion and Pourtois (2004) line-drawings
were sourced directly from the authors, and were trimmed of any
preexisting background before being resized to fit the 500x500px canvas
(for some items this was determined by a maximum width of 500px, whilst
for others it was determined by a maximum height of 500px).

word stimuli were created in Roboto (light, 54pt)

Planned comparisons:

Distinctive words vs.~grey words (are they actually more distinctive?)

\begin{verbatim}
                  vs. grey drawings       (are they as distinctive as grey drawings?)
                  vs. grey photos         (are they as distinctive as grey photos?)
                  
                  vs. colour drawings     (are they as distinctive as colour drawings?)
                  vs. colour photos       (are they as distinctive as colour photos?)
\end{verbatim}

\hypertarget{results-4}{%
\subsubsection{Results}\label{results-4}}

\hypertarget{proportion-of-total-hits}{%
\paragraph{Proportion of total hits}\label{proportion-of-total-hits}}

\begin{table}[!h]
\centering
\begin{tabular}{>{\raggedright\arraybackslash}p{2cm}>{\raggedright\arraybackslash}p{2cm}>{\raggedright\arraybackslash}p{2cm}>{\raggedleft\arraybackslash}p{2cm}>{\raggedleft\arraybackslash}p{2cm}>{\raggedleft\arraybackslash}p{2cm}}
\toprule
stim\_format & distinctiveness & variable & n & mean & sd\\
\midrule
Words & Low & hit & 158 & 0.579 & 0.243\\
Words & High & hit & 158 & 0.606 & 0.233\\
Drawings & Low & hit & 158 & 0.754 & 0.191\\
Drawings & High & hit & 158 & 0.775 & 0.189\\
Photos & Low & hit & 158 & 0.908 & 0.124\\
\addlinespace
Photos & High & hit & 158 & 0.915 & 0.113\\
\bottomrule
\end{tabular}
\end{table}

\begin{tabular}{l|l|l|l|l|l}
\hline
Effect & df & MSE & F & ges & p.value\\
\hline
stim\_format & 1.84, 289.13 & 0.03 & 282.85 *** & .323 & <.001\\
\hline
distinctiveness & 1, 157 & 0.02 & 3.46 + & .002 & .065\\
\hline
stim\_format:distinctiveness & 1.71, 268.93 & 0.02 & 0.46 & <.001 & .604\\
\hline
\end{tabular}

Significant main effect of stimuli format: \(F(1.84, 289.13) = 282.85\),
\(\mathit{MSE} = 0.03\), \(p < .001\), \(\hat{\eta}^2_G = .323\).

No main effect of distinctiveness: \(F(1, 157) = 3.46\),
\(\mathit{MSE} = 0.02\), \(p = .065\), \(\hat{\eta}^2_G = .002\).

No interaction effects: \(F(1.71, 268.93) = 0.46\),
\(\mathit{MSE} = 0.02\), \(p = .604\), \(\hat{\eta}^2_G = .001\).

\newpage

\hypertarget{proportion-of-total-fa}{%
\paragraph{Proportion of total FA}\label{proportion-of-total-fa}}

\begin{table}[!h]
\centering
\begin{tabular}{lllrrr}
\toprule
stim\_format & distinctiveness & variable & n & mean & sd\\
\midrule
Words & Low & FA & 158 & 0.175 & 0.187\\
Words & High & FA & 158 & 0.051 & 0.079\\
Drawings & Low & FA & 158 & 0.075 & 0.114\\
Drawings & High & FA & 158 & 0.053 & 0.092\\
Photos & Low & FA & 158 & 0.039 & 0.067\\
\addlinespace
Photos & High & FA & 158 & 0.020 & 0.052\\
\bottomrule
\end{tabular}
\end{table}

\begin{tabular}{l|l|l|l|l|l}
\hline
Effect & df & MSE & F & ges & p.value\\
\hline
stim\_format & 1.74, 273.37 & 0.01 & 53.57 *** & .093 & <.001\\
\hline
distinctiveness & 1, 157 & 0.01 & 86.43 *** & .062 & <.001\\
\hline
stim\_format:distinctiveness & 1.63, 255.48 & 0.01 & 34.16 *** & .048 & <.001\\
\hline
\end{tabular}

\newpage

\hypertarget{overall-recognition}{%
\paragraph{Overall recognition:}\label{overall-recognition}}

\begin{table}[!h]
\centering
\begin{tabular}{lllrrr}
\toprule
stim\_format & distinctiveness & variable & n & mean & sd\\
\midrule
Words & Low & recog & 158 & 0.404 & 0.245\\
Words & High & recog & 158 & 0.555 & 0.230\\
Drawings & Low & recog & 158 & 0.679 & 0.208\\
Drawings & High & recog & 158 & 0.723 & 0.208\\
Photos & Low & recog & 158 & 0.868 & 0.142\\
\addlinespace
Photos & High & recog & 158 & 0.895 & 0.125\\
\bottomrule
\end{tabular}
\end{table}

\begin{tabular}{l|l|l|l|l|l}
\hline
Effect & df & MSE & F & ges & p.value\\
\hline
stim\_format & 1.97, 310.07 & 0.03 & 425.75 *** & .410 & <.001\\
\hline
distinctiveness & 1, 157 & 0.03 & 47.83 *** & .034 & <.001\\
\hline
stim\_format:distinctiveness & 1.68, 263.84 & 0.03 & 16.23 *** & .019 & <.001\\
\hline
\end{tabular}

\newpage

\hypertarget{d-scores}{%
\paragraph{d' scores}\label{d-scores}}

\begin{table}[!h]
\centering
\begin{tabular}{lllrrr}
\toprule
stim\_format & distinctiveness & variable & n & mean & sd\\
\midrule
Words & Low & d.prime & 158 & 1.183 & 0.742\\
Words & High & d.prime & 158 & 1.714 & 0.688\\
Drawings & Low & d.prime & 158 & 2.059 & 0.698\\
Drawings & High & d.prime & 158 & 2.223 & 0.729\\
Photos & Low & d.prime & 158 & 2.746 & 0.584\\
\addlinespace
Photos & High & d.prime & 158 & 2.871 & 0.541\\
\bottomrule
\end{tabular}
\end{table}

\begin{tabular}{l|l|l|l|l|l}
\hline
Effect & df & MSE & F & ges & p.value\\
\hline
stim\_format & 2.00, 313.36 & 0.35 & 424.00 *** & .410 & <.001\\
\hline
distinctiveness & 1, 157 & 0.33 & 54.02 *** & .041 & <.001\\
\hline
stim\_format:distinctiveness & 1.81, 284.95 & 0.28 & 15.85 *** & .018 & <.001\\
\hline
\end{tabular}

\newpage

\hypertarget{c-scores}{%
\paragraph{C scores:}\label{c-scores}}

\begin{table}[!h]
\centering
\begin{tabular}{lllrrr}
\toprule
stim\_format & distinctiveness & variable & n & mean & sd\\
\midrule
Words & Low & c & 158 & 0.386 & 0.553\\
Words & High & c & 158 & 0.566 & 0.412\\
Drawings & Low & c & 158 & 0.302 & 0.409\\
Drawings & High & c & 158 & 0.318 & 0.361\\
Photos & Low & c & 158 & 0.105 & 0.304\\
\addlinespace
Photos & High & c & 158 & 0.151 & 0.263\\
\bottomrule
\end{tabular}
\end{table}

\begin{tabular}{l|l|l|l|l|l}
\hline
Effect & df & MSE & F & ges & p.value\\
\hline
stim\_format & 1.79, 280.46 & 0.14 & 74.32 *** & .115 & <.001\\
\hline
distinctiveness & 1, 157 & 0.10 & 14.90 *** & .010 & <.001\\
\hline
stim\_format:distinctiveness & 1.84, 288.51 & 0.10 & 6.70 ** & .008 & .002\\
\hline
\end{tabular}

\newpage

\hypertarget{prop-rec-hit}{%
\paragraph{Prop Rec hit:}\label{prop-rec-hit}}

\begin{table}[!h]
\centering
\begin{tabular}{lllrrr}
\toprule
stim\_format & distinctiveness & variable & n & mean & sd\\
\midrule
Words & Low & rec\_hit & 158 & 0.357 & 0.286\\
Words & High & rec\_hit & 158 & 0.480 & 0.304\\
Drawings & Low & rec\_hit & 158 & 0.563 & 0.306\\
Drawings & High & rec\_hit & 158 & 0.590 & 0.295\\
Photos & Low & rec\_hit & 158 & 0.713 & 0.322\\
\addlinespace
Photos & High & rec\_hit & 158 & 0.733 & 0.325\\
\bottomrule
\end{tabular}
\end{table}

\begin{tabular}{l|l|l|l|l|l}
\hline
Effect & df & MSE & F & ges & p.value\\
\hline
stim\_format & 1.42, 223.31 & 0.09 & 118.98 *** & .142 & <.001\\
\hline
distinctiveness & 1, 157 & 0.03 & 24.81 *** & .008 & <.001\\
\hline
stim\_format:distinctiveness & 1.70, 266.57 & 0.04 & 8.59 *** & .006 & <.001\\
\hline
\end{tabular}

\newpage

\hypertarget{prop-fam-hit}{%
\paragraph{Prop FAM hit:}\label{prop-fam-hit}}

\begin{table}[!h]
\centering
\begin{tabular}{lllrrr}
\toprule
stim\_format & distinctiveness & variable & n & mean & sd\\
\midrule
Words & Low & fam\_hit & 158 & 0.480 & 0.289\\
Words & High & fam\_hit & 158 & 0.407 & 0.288\\
Drawings & Low & fam\_hit & 158 & 0.385 & 0.285\\
Drawings & High & fam\_hit & 158 & 0.358 & 0.270\\
Photos & Low & fam\_hit & 158 & 0.270 & 0.311\\
\addlinespace
Photos & High & fam\_hit & 158 & 0.245 & 0.315\\
\bottomrule
\end{tabular}
\end{table}

\begin{tabular}{l|l|l|l|l|l}
\hline
Effect & df & MSE & F & ges & p.value\\
\hline
stim\_format & 1.40, 220.37 & 0.10 & 40.99 *** & .064 & <.001\\
\hline
distinctiveness & 1, 157 & 0.03 & 12.00 *** & .005 & <.001\\
\hline
stim\_format:distinctiveness & 1.62, 254.40 & 0.04 & 1.69 & .001 & .191\\
\hline
\end{tabular}

\newpage

\hypertarget{prop-guess-hit}{%
\paragraph{Prop GUESS hit:}\label{prop-guess-hit}}

\begin{table}[!h]
\centering
\begin{tabular}{lllrrr}
\toprule
stim\_format & distinctiveness & variable & n & mean & sd\\
\midrule
Words & Low & guess\_hit & 158 & 0.131 & 0.185\\
Words & High & guess\_hit & 158 & 0.100 & 0.192\\
Drawings & Low & guess\_hit & 158 & 0.052 & 0.102\\
Drawings & High & guess\_hit & 158 & 0.052 & 0.105\\
Photos & Low & guess\_hit & 158 & 0.017 & 0.053\\
\addlinespace
Photos & High & guess\_hit & 158 & 0.023 & 0.058\\
\bottomrule
\end{tabular}
\end{table}

\begin{tabular}{l|l|l|l|l|l}
\hline
Effect & df & MSE & F & ges & p.value\\
\hline
stim\_format & 1.47, 230.35 & 0.02 & 46.07 *** & .089 & <.001\\
\hline
distinctiveness & 1, 157 & 0.01 & 1.52 & .001 & .219\\
\hline
stim\_format:distinctiveness & 1.31, 205.90 & 0.02 & 2.97 + & .004 & .075\\
\hline
\end{tabular}

\newpage

\hypertarget{prop-rec-fa}{%
\paragraph{Prop REC FA:}\label{prop-rec-fa}}

\begin{table}[!h]
\centering
\begin{tabular}{lllrrr}
\toprule
stim\_format & distinctiveness & variable & n & mean & sd\\
\midrule
Words & Low & rec\_FA & 158 & 0.101 & 0.252\\
Words & High & rec\_FA & 158 & 0.041 & 0.178\\
Drawings & Low & rec\_FA & 158 & 0.109 & 0.300\\
Drawings & High & rec\_FA & 158 & 0.057 & 0.217\\
Photos & Low & rec\_FA & 158 & 0.066 & 0.247\\
\addlinespace
Photos & High & rec\_FA & 158 & 0.027 & 0.149\\
\bottomrule
\end{tabular}
\end{table}

\begin{tabular}{l|l|l|l|l|l}
\hline
Effect & df & MSE & F & ges & p.value\\
\hline
stim\_format & 1.96, 308.15 & 0.04 & 2.45 + & .004 & .089\\
\hline
distinctiveness & 1, 157 & 0.04 & 13.91 *** & .012 & <.001\\
\hline
stim\_format:distinctiveness & 1.89, 297.40 & 0.04 & 0.21 & <.001 & .800\\
\hline
\end{tabular}

\newpage

\hypertarget{prop-fam-fa}{%
\paragraph{Prop FAM FA:}\label{prop-fam-fa}}

\begin{table}[!h]
\centering
\begin{tabular}{lllrrr}
\toprule
stim\_format & distinctiveness & variable & n & mean & sd\\
\midrule
Words & Low & fam\_FA & 158 & 0.378 & 0.428\\
Words & High & fam\_FA & 158 & 0.185 & 0.376\\
Drawings & Low & fam\_FA & 158 & 0.234 & 0.396\\
Drawings & High & fam\_FA & 158 & 0.210 & 0.397\\
Photos & Low & fam\_FA & 158 & 0.139 & 0.333\\
\addlinespace
Photos & High & fam\_FA & 158 & 0.061 & 0.231\\
\bottomrule
\end{tabular}
\end{table}

\begin{tabular}{l|l|l|l|l|l}
\hline
Effect & df & MSE & F & ges & p.value\\
\hline
stim\_format & 1.97, 309.05 & 0.12 & 22.29 *** & .041 & <.001\\
\hline
distinctiveness & 1, 157 & 0.12 & 19.14 *** & .018 & <.001\\
\hline
stim\_format:distinctiveness & 1.81, 283.95 & 0.11 & 5.73 ** & .009 & .005\\
\hline
\end{tabular}

\newpage

\hypertarget{prop-guess-fa}{%
\paragraph{Prop GUESS FA:}\label{prop-guess-fa}}

\begin{table}[!h]
\centering
\begin{tabular}{lllrrr}
\toprule
stim\_format & distinctiveness & variable & n & mean & sd\\
\midrule
Words & Low & guess\_FA & 158 & 0.185 & 0.323\\
Words & High & guess\_FA & 158 & 0.147 & 0.342\\
Drawings & Low & guess\_FA & 158 & 0.101 & 0.271\\
Drawings & High & guess\_FA & 158 & 0.074 & 0.242\\
Photos & Low & guess\_FA & 158 & 0.111 & 0.302\\
\addlinespace
Photos & High & guess\_FA & 158 & 0.057 & 0.226\\
\bottomrule
\end{tabular}
\end{table}

\begin{tabular}{l|l|l|l|l|l}
\hline
Effect & df & MSE & F & ges & p.value\\
\hline
stim\_format & 1.91, 300.51 & 0.08 & 9.45 *** & .017 & <.001\\
\hline
distinctiveness & 1, 157 & 0.08 & 4.83 * & .005 & .029\\
\hline
stim\_format:distinctiveness & 2.00, 313.38 & 0.08 & 0.19 & <.001 & .826\\
\hline
\end{tabular}

\newpage

\hypertarget{results-5}{%
\subsection{Results}\label{results-5}}

\hypertarget{manipulation-check}{%
\subsubsection{Manipulation check}\label{manipulation-check}}

To examine whether the distinctiveness manipulation for word stimuli was
effective, a series of two-way repeated measures ANOVAs
(Greenhouse-Geisser corrected) were run on the mean proportion of hits,
mean proportion of false alarms (FAs), and overall recognition scores
(hits - FAs).

While there was no significant main effect of distinctiveness in the
ANOVA on the mean proportion of hits {[}\(F(1, 157) = 3.46\),
\(\mathit{MSE} = 0.02\), \(p = .065\), \(\hat{\eta}^2_G = .002\){]},
significant effects were demonstrated in the ANOVA on the mean
proportion of FAs {[}\(F(1, 157) = 86.43\), \(\mathit{MSE} = 0.01\),
\(p < .001\), \(\hat{\eta}^2_G = .062\){]} and overall recognition
scores {[}\(F(1, 157) = 47.83\), \(\mathit{MSE} = 0.03\), \(p < .001\),
\(\hat{\eta}^2_G = .034\){]}.

\newpage

\#\#\#\#\#\#----------------------------------------

\newpage

\hypertarget{references}{%
\section{References}\label{references}}

\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}

\noindent

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-adlington2009}{}%
Adlington, R. L., Laws, K. R., \& Gale, T. M. (2009). The Hatfield Image
Test (HIT): A new picture test and norms for experimental and clinical
use. \emph{Journal of Clinical and Experimental Neuropsychology},
\emph{31}(6), 731--753. \url{https://doi.org/10.1080/13803390802488103}

\leavevmode\hypertarget{ref-algarabel2009}{}%
Algarabel, S., Escudero, J., Mazón, J. F., Pitarque, A., Fuentes, M.,
Peset, V., \& Lacruz, L. (2009). Familiarity-based recognition in the
young, healthy elderly, mild cognitive impaired and Alzheimer's
patients73. \emph{Neuropsychologia}, \emph{47}(10), 2056--2064.
\url{https://doi.org/10.1016/j.neuropsychologia.2009.03.016}

\leavevmode\hypertarget{ref-algarabel2012}{}%
Algarabel, S., Fuentes, M., Escudero, J., Pitarque, A., Peset, V.,
Mazón, J.-F., \& Meléndez, J.-C. (2012). Recognition memory deficits in
mild cognitive impairment. \emph{Aging, Neuropsychology, and Cognition},
\emph{19}(5), 608--619.
\url{https://doi.org/10.1080/13825585.2011.640657}

\leavevmode\hypertarget{ref-ally2012}{}%
Ally, B. A. (2012). Using Pictures and Words To Understand Recognition
Memory Deterioration in Amnestic Mild Cognitive Impairment and
Alzheimer's Disease: A Review. \emph{Current Neurology and Neuroscience
Reports}, \emph{12}(6), 687--694.
\url{https://doi.org/10.1007/s11910-012-0310-7}

\leavevmode\hypertarget{ref-ally2009}{}%
Ally, B. A., Gold, C. A., \& Budson, A. E. (2009a). The picture
superiority effect in patients with Alzheimer's disease and mild
cognitive impairment. \emph{Neuropsychologia}, \emph{47}(2), 595--598.
\url{https://doi.org/10.1016/j.neuropsychologia.2008.10.010}

\leavevmode\hypertarget{ref-ally2009a}{}%
Ally, B. A., McKeever, J. D., Waring, J. D., \& Budson, A. E. (2009b).
Preserved frontal memorial processing for pictures in patients with mild
cognitive impairment. \emph{Neuropsychologia}, \emph{47}(10),
2044--2055. \url{https://doi.org/10.1016/j.neuropsychologia.2009.03.015}

\leavevmode\hypertarget{ref-anderson2008}{}%
Anderson, N. D., Ebert, P. L., Jennings, J. M., Grady, C. L., Cabeza,
R., \& Graham, S. J. (2008). Recollection- and familiarity-based memory
in healthy aging and amnestic mild cognitive impairment.
\emph{Neuropsychology}, \emph{22}(2), 177--187.
\url{https://doi.org/10.1037/0894-4105.22.2.177}

\leavevmode\hypertarget{ref-barba1997}{}%
Barba, G. D. (1997). Recognition Memory and Recollective Experience in
Alzheimer's Disease. \emph{Memory}, \emph{5}(6), 657--672.
\url{https://doi.org/10.1080/741941546}

\leavevmode\hypertarget{ref-belleville2011}{}%
Belleville, S., Ménard, M.-C., \& Lepage, É. (2011). Impact of novelty
and type of material on recognition in healthy older adults and persons
with mild cognitive impairment. \emph{Neuropsychologia},
\emph{49}(2011), 2856--2865.

\leavevmode\hypertarget{ref-bermudez-margaretto2018}{}%
Bermúdez-Margaretto, B., Beltrán, D., Cuetos, F., \& Domínguez, A.
(2018). Brain Signatures of New (Pseudo-) Words: Visual Repetition in
Associative and Non-associative Contexts. \emph{Frontiers in Human
Neuroscience}, \emph{12}, 354.
\url{https://doi.org/10.3389/fnhum.2018.00354}

\leavevmode\hypertarget{ref-biederman1987}{}%
Biederman, I. (1987). \emph{Recognition-by-Components: A Theory of Human
Image Understanding}. 33.

\leavevmode\hypertarget{ref-bowen2019}{}%
Bowen, H. J., Fields, E. C., \& Kensinger, E. A. (2019). Prior Emotional
Context Modulates Early Event-Related Potentials to Neutral Retrieval
Cues. \emph{Journal of Cognitive Neuroscience}, \emph{31}(11),
1755--1767. \url{https://doi.org/10.1162/jocn_a_01451}

\leavevmode\hypertarget{ref-cui2016}{}%
Cui, L., Shi, G., He, F., Zhang, Q., Oei, T. P. S., \& Guo, C. (2016).
Electrophysiological Correlates of Emotional Source Memory in
High-Trait-Anxiety Individuals. \emph{Frontiers in Psychology},
\emph{7}. \url{https://doi.org/10.3389/fpsyg.2016.01039}

\leavevmode\hypertarget{ref-curran2011}{}%
Curran, T., \& Doyle, J. (2011). Picture Superiority Doubly Dissociates
the ERP Correlates of Recollection and Familiarity. \emph{Journal of
Cognitive Neuroscience}, \emph{23}(5), 1247--1262.
\url{https://doi.org/10.1162/jocn.2010.21464}

\leavevmode\hypertarget{ref-deason2015}{}%
Deason, R. G., Hussey, E. P., Flannery, S., \& Ally, B. A. (2015).
Preserved conceptual implicit memory for pictures in patients with
Alzheimer's disease. \emph{Brain and Cognition}, \emph{99}, 112--117.
\url{https://doi.org/10.1016/j.bandc.2015.07.008}

\leavevmode\hypertarget{ref-dewhurst1994}{}%
Dewhurst, S. A., \& Conway, M. A. (1994). \emph{Pictures, Images, and
Recollective Experience}. 11.

\leavevmode\hypertarget{ref-dunn2008}{}%
Dunn, J. C. (2008). The Dimensionality of the RememberKnow Task: A
State-Trace Analysis. \emph{Psychological Review}, \emph{115}(2),
426--446.

\leavevmode\hypertarget{ref-eldridge2002}{}%
Eldridge, L. L., Sarfatti, S., \& Knowlton, B. J. (2002). The effect of
testing procedure on remember-know judgments. \emph{Psychonomic Bulletin
\& Review}, \emph{9}(1), 139--145.
\url{https://doi.org/10.3758/BF03196270}

\leavevmode\hypertarget{ref-embree2012}{}%
Embree, L. M., Budson, A. E., \& Ally, B. A. (2012). Memorial
familiarity remains intact for pictures but not for words in patients
with amnestic mild cognitive impairment. \emph{Neuropsychologia},
\emph{50}(9), 2333--2340.
\url{https://doi.org/10.1016/j.neuropsychologia.2012.06.001}

\leavevmode\hypertarget{ref-ensor2019b}{}%
Ensor, T. M., Surprenant, A. M., \& Neath, I. (2019). Increasing word
distinctiveness eliminates the picture superiority effect in
recognition: Evidence for the physical-distinctiveness account.
\emph{Memory \& Cognition}, \emph{47}(1), 182--193.
\url{https://doi.org/10.3758/s13421-018-0858-9}

\leavevmode\hypertarget{ref-gardiner2000}{}%
Gardiner, J. M. (2000). On the objectivity of subjective experiences of
autonoetic and noetic consciousness. In E. Tulving (Ed.), \emph{Memory,
consciousness, and the brain: The Tallinn Conference} (pp. 159--172).
Psychology Press.

\leavevmode\hypertarget{ref-gardiner1998}{}%
Gardiner, J. M., \& Ramponi, C. (1998). Experiences of Remembering,
Knowing, and Guessing. \emph{CONSCIOUSNESS AND COGNITION}, \emph{7},
1--26.

\leavevmode\hypertarget{ref-gardiner2002}{}%
Gardiner, J. M., Ramponi, C., \& Richardson-Klavehn, A. (2002).
Recognition memory and decision processes: A meta-analysis of remember,
know, and guess responses. \emph{Memory}, \emph{10}(2), 83--98.
\url{https://doi.org/10.1080/09658210143000281}

\leavevmode\hypertarget{ref-geraci2009}{}%
Geraci, L., McCabe, D. P., \& Guillory, J. J. (2009). On interpreting
the relationship between rememberKnow judgments and confidence: The role
of instructions. \emph{Consciousness and Cognition}, \emph{18}(3),
701--709. \url{https://doi.org/10.1016/j.concog.2009.04.010}

\leavevmode\hypertarget{ref-hautus1995}{}%
Hautus, M. J. (1995). Corrections for extreme proportions and their
biasing effects on estimated values ofd\({'}\). \emph{Behavior Research
Methods, Instruments, \& Computers}, \emph{27}(1), 46--51.
\url{https://doi.org/10.3758/BF03203619}

\leavevmode\hypertarget{ref-herzmann2018}{}%
Herzmann, G., Minor, G., \& Curran, T. (2018). Neural evidence for the
contribution of holistic processing but not attention allocation to the
other-race effect on face memory. \emph{Cognitive, Affective, \&
Behavioral Neuroscience}, \emph{18}(5), 1015--1033.
\url{https://doi.org/10.3758/s13415-018-0619-z}

\leavevmode\hypertarget{ref-hockley2008}{}%
Hockley, W. E. (2008). The picture superiority effect in associative
recognition. \emph{Memory \& Cognition}, \emph{36}(7), 1351--1359.
\url{https://doi.org/10.3758/MC.36.7.1351}

\leavevmode\hypertarget{ref-hudon2009}{}%
Hudon, C., Belleville, S., \& Gauthier, S. (2009). The assessment of
recognition memory using the Remember/Know procedure in amnestic mild
cognitive impairment and probable Alzheimer's disease. \emph{Brain and
Cognition}, 9.

\leavevmode\hypertarget{ref-jacoby1991}{}%
Jacoby, L. L. (1991). A process dissociation framework: Separating
automatic from intentional uses of memory. \emph{Journal of Memory and
Language}, \emph{30}(5), 513--541.
\url{https://doi.org/10.1016/0749-596X(91)90025-F}

\leavevmode\hypertarget{ref-jacoby1997}{}%
Jacoby, L. L., Yonelinas, A. P., \& Jennings, J. M. (1997). The relation
between conscious and unconscious (automatic) influences: A declaration
of independence. In J. D. Cohen \& J. W. Schooler (Eds.),
\emph{Scientific approaches to consciousness} (pp. 13--47). Mahwah, NJ:
Erlbaum.

\leavevmode\hypertarget{ref-koen2014}{}%
Koen, J. D., \& Yonelinas, A. P. (2014). \emph{The Effects of Healthy
Aging, Amnestic Mild Cognitive Impairment, and Alzheimer's Disease on
Recollection and Familiarity: A Meta-Analytic Review}. 41.

\leavevmode\hypertarget{ref-lombardi2016}{}%
Lombardi, M. G., Perri, R., Fadda, L., Caltagirone, C., \& Carlesimo, G.
A. (2016). Forgetting of the recollection and familiarity components of
recognition in patients with amnestic mild cognitive impairment.
\emph{Journal of Neuropsychology}, \emph{12}(2), 231--247.
\url{https://doi.org/10.1111/jnp.12114}

\leavevmode\hypertarget{ref-psycho}{}%
Makowski, D. (2018). The psycho package: An efficient and
publishing-oriented workflow for psychological science. \emph{Journal of
Open Source Software}, \emph{3}(22), 470.
\url{https://doi.org/10.21105/joss.00470}

\leavevmode\hypertarget{ref-martins2006}{}%
Martins, C. A. R., \& Lloyd-Jones, T. J. (2006). Preserved Conceptual
Priming in Alzheimer's Disease. \emph{Cortex}, \emph{42}(7), 995--1004.
\url{https://doi.org/10.1016/S0010-9452(08)70205-3}

\leavevmode\hypertarget{ref-mcbride2002}{}%
McBride, D. M., \& Anne Dosher, B. (2002). A comparison of conscious and
automatic memory processes for picture and word stimuli: A process
dissociation analysis. \emph{Consciousness and Cognition}, \emph{11}(3),
423--460. \url{https://doi.org/10.1016/S1053-8100(02)00007-7}

\leavevmode\hypertarget{ref-meade2019}{}%
Meade, M. E., Ahmad, M., \& Fernandes, M. A. (2019). Drawing pictures at
encoding enhances memory in healthy older adults and in individuals with
probable dementia. \emph{Aging, Neuropsychology, and Cognition},
\emph{27}(6), 880--901.
\url{https://doi.org/10.1080/13825585.2019.1700899}

\leavevmode\hypertarget{ref-migo2012}{}%
Migo, E. M., Mayes, A. R., \& Montaldi, D. (2012). Measuring
recollection and familiarity: Improving the remember/know procedure.
\emph{Consciousness and Cognition}, \emph{21}(3), 1435--1455.
\url{https://doi.org/10.1016/j.concog.2012.04.014}

\leavevmode\hypertarget{ref-moreno-martinez2012}{}%
Moreno-Martínez, F. J., \& Montoro, P. R. (2012). An Ecological
Alternative to Snodgrass \& Vanderwart: 360 High Quality Colour Images
with Norms for Seven Psycholinguistic Variables. \emph{PLoS ONE},
\emph{7}(5), e37527. \url{https://doi.org/10.1371/journal.pone.0037527}

\leavevmode\hypertarget{ref-oconnor2010}{}%
O'Connor, M. K., \& Ally, B. A. (2010). Using stimulus form change to
understand memorial familiarity for pictures and words in patients with
mild cognitive impairment and Alzheimer's disease.
\emph{Neuropsychologia}, \emph{48}(7), 2068--2074.
\url{https://doi.org/10.1016/j.neuropsychologia.2010.03.027}

\leavevmode\hypertarget{ref-paivio1971}{}%
Paivio, A. (1971). \emph{Imagery and verbal processes.} New York: Holt,
Rinehart and Winston.

\leavevmode\hypertarget{ref-paivio1972}{}%
Paivio, A. (1972). Symbolic and sensory modalities of memory. In M. E.
Meyer (Ed.), \emph{The third Western symposium on learning: Cognitive
Learning.} Western Washington State College.

\leavevmode\hypertarget{ref-peirce2019}{}%
Peirce, J., Gray, J. R., Simpson, S., MacAskill, M., Höchenberger, R.,
Sogo, H., \ldots{} Lindeløv, J. K. (2019). PsychoPy2: Experiments in
behavior made easy. \emph{Behavior Research Methods}, \emph{51}(1),
195--203. \url{https://doi.org/10.3758/s13428-018-01193-y}

\leavevmode\hypertarget{ref-pitarque2016}{}%
Pitarque, A. (2016). \emph{The effects of healthy aging, amnestic mild
cognitive impairment, and Alzheimer's disease on recollection,
familiarity and false recognition, estimated by an associative
process-dissociation recognition procedure}. 7.

\leavevmode\hypertarget{ref-rajaram1993}{}%
Rajaram, S. (1993). Remembering and knowing: Two means of access to the
personal past. \emph{Memory \& Cognition}, \emph{21}(1), 89--102.
\url{https://doi.org/10.3758/BF03211168}

\leavevmode\hypertarget{ref-rajaram1996}{}%
Rajaram, S. (1996). \emph{Perceptual Effects on Remembering:
Recollective Processes in Picture Recognition Memory}. 13.

\leavevmode\hypertarget{ref-rcoreteam2020}{}%
R Core Team. (2020). \emph{R: A language and environment for statistical
computing} {[}Manual{]}. Vienna, Austria: R Foundation for Statistical
Computing.

\leavevmode\hypertarget{ref-rollins2018}{}%
Rollins, L., \& Riggins, T. (2018). Age-related differences in
subjective recollection: ERP studies of encoding and retrieval.
\emph{Developmental Science}, \emph{21}(3), e12583.
\url{https://doi.org/10.1111/desc.12583}

\leavevmode\hypertarget{ref-rossion2004}{}%
Rossion, B., \& Pourtois, G. (2004). Revisiting Snodgrass and
Vanderwart's Object Pictorial Set: The Role of Surface Detail in
Basic-Level Object Recognition. \emph{Perception}, \emph{33}(2),
217--236. \url{https://doi.org/10.1068/p5117}

\leavevmode\hypertarget{ref-sanfeliu1996}{}%
Sanfeliu, M. C., \& Fernandez, A. (1996). A set of 254
Snodgrass-Vanderwart pictures standardized for Spanish: Norms for name
agreement, image agreement, familiarity, and visual complexity.
\emph{Behavior Research Methods, Instruments, \& Computers},
\emph{28}(4), 537--555. \url{https://doi.org/10.3758/BF03200541}

\leavevmode\hypertarget{ref-scalici2017}{}%
Scalici, F., Caltagirone, C., \& Carlesimo, G. A. (2017). The
contribution of different prefrontal cortex regions to recollection and
familiarity: A review of fMRI data. \emph{Neuroscience \& Biobehavioral
Reviews}, \emph{83}, 240--251.
\url{https://doi.org/10.1016/j.neubiorev.2017.10.017}

\leavevmode\hypertarget{ref-schmitter-edgecombe2009}{}%
Schmitter-Edgecombe, M., Woo, E., \& Greeley, D. R. (2009).
Characterizing multiple memory deficits and their relation to everyday
functioning in individuals with mild cognitive impairment.
\emph{Neuropsychology}, \emph{23}(2), 168--177.
\url{https://doi.org/10.1037/a0014186}

\leavevmode\hypertarget{ref-schoemaker2014}{}%
Schoemaker, D., Gauthier, S., \& Pruessner, J. C. (2014). Recollection
and Familiarity in Aging Individuals with Mild Cognitive Impairment and
Alzheimer's Disease: A Literature Review. \emph{Neuropsychol Rev}, 19.

\leavevmode\hypertarget{ref-serra2010}{}%
Serra, L., Bozzali, M., Cercignani, M., Perri, R., Fadda, L.,
Caltagirone, C., \& Carlesimo, G. A. (2010). Recollection and
familiarity in amnesic mild cognitive impairment.
\emph{Neuropsychology}, \emph{24}(3), 316--326.
\url{https://doi.org/10.1037/a0017654}

\leavevmode\hypertarget{ref-snodgrass1980}{}%
Snodgrass, J. G., \& Vanderwart, M. (1980). A Standardized Set of 260
Pictures: Norms for Name Agreement, Image Agreement, Familiarity, and
Visual Complexity. \emph{Journal of Experimental Psychology: Human
Learning and Memory}, \emph{6}(2), 174--215.

\leavevmode\hypertarget{ref-squire2007}{}%
Squire, L. R., Wixted, J. T., \& Clark, R. E. (2007). Recognition memory
and the medial temporal lobe: A new perspective. \emph{Nature Reviews.
Neuroscience}, \emph{8}(11), 872--883.
\url{https://doi.org/10.1038/nrn2154}

\leavevmode\hypertarget{ref-stenberg2006}{}%
Stenberg, G. (2006). Conceptual and perceptual factors in the picture
superiority effect. \emph{European Journal of Cognitive Psychology},
\emph{18}(6), 813--847. \url{https://doi.org/10.1080/09541440500412361}

\leavevmode\hypertarget{ref-szekely2003}{}%
Székely, A., D'Amico, S., Devescovi, A., Federmeier, K., Herron, D.,
Iyer, G., \ldots{} Bates, E. (2003). Timed picture naming: Extended
norms and validation against previous studies. \emph{Behavior Research
Methods, Instruments, \& Computers}, \emph{35}(4), 621--633.
\url{https://doi.org/10.3758/BF03195542}

\leavevmode\hypertarget{ref-tanaka2001}{}%
Tanaka, J., Weiskopf, D., \& Williams, P. (2001). The role of color in
high-level vision. \emph{TRENDS in Cognitive Sciences}, \emph{5}(5),
211--215.

\leavevmode\hypertarget{ref-tarr1998}{}%
Tarr, M. J., \& Bülthoff, H. H. (1998). Image-based object recognition
in man, monkey and machine. \emph{Cognition}, \emph{67}(1-20).

\leavevmode\hypertarget{ref-troyer2012}{}%
Troyer, A. K., Murphy, K. J., Anderson, N. D., Craik, F. I. M.,
Moscovitch, M., Maione, A., \& Gao, F. (2012). Associative recognition
in mild cognitive impairment: Relationship to hippocampal volume and
apolipoprotein E. \emph{Neuropsychologia}, \emph{50}(14), 3721--3728.
\url{https://doi.org/10.1016/j.neuropsychologia.2012.10.018}

\leavevmode\hypertarget{ref-troyer2016}{}%
Troyer, A. K., Vandermorris, S., \& Murphy, K. J. (2016).
Intraindividual variability in performance on associative memory tasks
is elevated in amnestic mild cognitive impairment.
\emph{Neuropsychologia}, \emph{90}, 110--116.
\url{https://doi.org/10.1016/j.neuropsychologia.2016.06.011}

\leavevmode\hypertarget{ref-tsaparina2011}{}%
Tsaparina, D., Bonin, P., \& Méot, A. (2011). Russian norms for name
agreement, image agreement for the colorized version of the Snodgrass
and Vanderwart pictures and age of acquisition, conceptual familiarity,
and imageability scores for modal object names. \emph{Behavior Research
Methods}, \emph{43}(4), 1085--1099.
\url{https://doi.org/10.3758/s13428-011-0121-9}

\leavevmode\hypertarget{ref-tulving1985}{}%
Tulving, E. (1985). Memory and consciousness. \emph{Canadian
Psychology/Psychologie Canadienne}, \emph{26}(1), 1--12.
\url{https://doi.org/10.1037/h0080017}

\leavevmode\hypertarget{ref-tunney2007}{}%
Tunney, R. J., \& Fernie, G. (2007). Repetition priming affects guessing
not familiarity. \emph{Behavioral and Brain Functions}, \emph{3}(1), 40.
\url{https://doi.org/10.1186/1744-9081-3-40}

\leavevmode\hypertarget{ref-vandermeulen2012}{}%
van der Meulen, M., Lederrey, C., Rieger, S. W., van Assche, M.,
Schwartz, S., Vuilleumier, P., \& Assal, F. (2012). Associative and
Semantic Memory Deficits in Amnestic Mild Cognitive Impairment as
Revealed by Functional Magnetic Resonance Imaging: \emph{Cognitive and
Behavioral Neurology}, \emph{25}(4), 195--215.
\url{https://doi.org/10.1097/WNN.0b013e31827de67f}

\leavevmode\hypertarget{ref-viggiano2004}{}%
Viggiano, M. P., Vannucci, M., \& Righi, S. (2004). A New Standardized
Set of Ecological Pictures for Experimental and Clinical Research on
Visual Object Processing. \emph{Cortex}, \emph{40}(3), 491--509.
\url{https://doi.org/10.1016/S0010-9452(08)70142-4}

\leavevmode\hypertarget{ref-wagner1997}{}%
Wagner, A. D., Gabrieli, J. D. E., \& Verfaellie, M. (1997).
\emph{Dissociations Between Familiarity Processes in Explicit
Recognition and Implicit Perceptual Memory}. 19.

\leavevmode\hypertarget{ref-wammes2016}{}%
Wammes, J. D., Meade, M. E., \& Fernandes, M. A. (2016). The drawing
effect: Evidence for reliable and robust memory benefits in free recall.
\emph{Quarterly Journal of Experimental Psychology}, \emph{69}(9),
1752--1776. \url{https://doi.org/10.1080/17470218.2015.1094494}

\leavevmode\hypertarget{ref-wang2013}{}%
Wang, L., Li, H., Liang, Y., Zhang, J., Li, X., Shu, N., \ldots{} Zhang,
Z. (2013). Amnestic Mild Cognitive Impairment: Topological
Reorganization of the Default-Mode Network. \emph{Radiology},
\emph{268}(2), 501--514. \url{https://doi.org/10.1148/radiol.13121573}

\leavevmode\hypertarget{ref-wang2013a}{}%
Wang, P., Li, J., Li, H., Li, B., Yang Jiang, Bao, F., \& Zhang, S.
(2013). Is emotional memory enhancement preserved in amnestic mild
cognitive impairment? Evidence from separating recollection and
familiarity. \emph{Neuropsychology}, \emph{27}(6), 691--701.
\url{https://doi.org/10.1037/a0033973}

\leavevmode\hypertarget{ref-weldon1989}{}%
Weldon, M. S., Iii, H. L. R., \& Challis, B. H. (1989). \emph{The
properties of retrieval cues constrain the picture superiority effect}.
11.

\leavevmode\hypertarget{ref-weldon1987}{}%
Weldon, M. S., \& Roediger, H. L. (1987). \emph{Altering retrieval
demands reverses the picture superiority effect}. 12.

\leavevmode\hypertarget{ref-westerberg2006}{}%
Westerberg, C. E., Paller, K. A., Weintraub, S., Mesulam, M.-M.,
Holdstock, J. S., Mayes, A. R., \& Reber, P. J. (2006). When memory does
not fail: Familiarity-based recognition in mild cognitive impairment and
Alzheimer's disease. \emph{Neuropsychology}, \emph{20}(2), 193--205.
\url{https://doi.org/10.1037/0894-4105.20.2.193}

\leavevmode\hypertarget{ref-westerberg2013}{}%
Westerberg, C., Mayes, A., Florczak, S. M., Chen, Y., Creery, J.,
Parrish, T., \ldots{} Paller, K. A. (2013). Distinct medial temporal
contributions to different forms of recognition in amnestic mild
cognitive impairment and Alzheimer's disease. \emph{Neuropsychologia},
\emph{51}(12), 2450--2461.
\url{https://doi.org/10.1016/j.neuropsychologia.2013.06.025}

\leavevmode\hypertarget{ref-whitehouse2006}{}%
Whitehouse, A. J. O., Maybery, M. T., \& Durkin, K. (2006). The
development of the picture-superiority effect. \emph{British Journal of
Developmental Psychology}, \emph{24}(4), 767--773.
\url{https://doi.org/10.1348/026151005X74153}

\leavevmode\hypertarget{ref-williams2013}{}%
Williams, H. L., Conway, M. A., \& Moulin, C. J. A. (2013). Remembering
and Knowing: Using another's subjective report to make inferences about
memory strength and subjective experience. \emph{Consciousness and
Cognition}, \emph{22}(2), 572--588.
\url{https://doi.org/10.1016/j.concog.2013.03.009}

\leavevmode\hypertarget{ref-williams2014}{}%
Williams, H. L., \& Moulin, C. J. A. (2014). Know versus Familiar:
Differentiating states of awareness in others' subjective reports of
recognition. \emph{Memory}, \emph{23}(7), 981--990.
\url{https://doi.org/10.1080/09658211.2014.945460}

\leavevmode\hypertarget{ref-doi:https:ux2fux2fdoi.orgux2f10.1002ux2f9781118445112.stat06743}{}%
Wixted, J. T. (2014). Signal detection theory. In \emph{Wiley StatsRef:
Statistics reference online}. American Cancer Society.
\url{https://doi.org/10.1002/9781118445112.stat06743}

\leavevmode\hypertarget{ref-wolk2011}{}%
Wolk, D. A., Dunfee, K. L., Dickerson, B. C., Aizenstein, H. J., \&
DeKosky, S. T. (2011). A medial temporal lobe division of labor:
Insights from memory in aging and early Alzheimer disease.
\emph{Hippocampus}, \emph{21}(5), 461--466.
\url{https://doi.org/10.1002/hipo.20779}

\leavevmode\hypertarget{ref-wolk2013}{}%
Wolk, D. A., Mancuso, L., Kliot, D., Arnold, S. E., \& Dickerson, B. C.
(2013). Familiarity-based memory as an early cognitive marker of
preclinical and prodromal AD. \emph{Neuropsychologia}, \emph{51}(6),
1094--1102. \url{https://doi.org/10.1016/j.neuropsychologia.2013.02.014}

\leavevmode\hypertarget{ref-wolk2008}{}%
Wolk, D. A., Signoff, E. D., \& DeKosky, S. T. (2008). Recollection and
familiarity in amnestic mild cognitive impairment: A global decline in
recognition memory. \emph{Neuropsychologia}, \emph{46}(7), 1965--1978.
\url{https://doi.org/10.1016/j.neuropsychologia.2008.01.017}

\leavevmode\hypertarget{ref-yonelinas2002}{}%
Yonelinas, A. P. (2002). The Nature of Recollection and Familiarity: A
Review of 30 Years of Research. \emph{Journal of Memory and Language},
\emph{46}(3), 441--517. \url{https://doi.org/10.1006/jmla.2002.2864}

\leavevmode\hypertarget{ref-yonelinas1995}{}%
Yonelinas, A. P., \& Jacoby, L. L. (1995). The relation between
remembering and knowing as bases for recognition: Effects of size
congruency. \emph{Journal of Memory and Language}, \emph{34}(5),
622--643.

\leavevmode\hypertarget{ref-yonelinas1995a}{}%
Yonelinas, A. P., \& Jacoby, L. L. (1995). The Relation between
Remembering and Knowing as Bases for Recognition: Effects of Size
Congruency. \emph{Journal of Memory and Language}, \emph{Volume 34}(5),
622--643. \url{https://doi.org/10.1006/jmla.1995.1028}

\leavevmode\hypertarget{ref-yoon2004}{}%
Yoon, C., Feinberg, F., Luo, T., Hedden, T., Gutchess, A. H., Chen,
H.-Y. M., \ldots{} Park, D. C. (2004). A cross-culturally standardized
set of pictures for younger and older adults: American and Chinese norms
for name agreement, concept agreement, and familiarity. \emph{Behavior
Research Methods, Instruments, \& Computers}, \emph{36}(4), 639--649.
\url{https://doi.org/10.3758/BF03206545}

\newpage
\begin{landscape}

\hypertarget{appendices}{%
\section{Appendices}\label{appendices}}

\hypertarget{appendix-a-d-calculations}{%
\subsection{\texorpdfstring{Appendix A: \emph{d'}
calculations}{Appendix A: d' calculations}}\label{appendix-a-d-calculations}}

\newpage

\hypertarget{appendix-b-spelling-corrections-manipulations-to-naming-responses.}{%
\subsection{Appendix B: Spelling corrections / manipulations to naming
responses.}\label{appendix-b-spelling-corrections-manipulations-to-naming-responses.}}

\begingroup\fontsize{7}{9}\selectfont

\begin{longtable}{>{\raggedright\arraybackslash}p{2.6cm}>{\raggedright\arraybackslash}p{2.3cm}|>{\raggedright\arraybackslash}p{2.6cm}>{\raggedright\arraybackslash}p{2.3cm}|>{\raggedright\arraybackslash}p{2.6cm}>{\raggedright\arraybackslash}p{2.6cm}}
\toprule
Response & Correction & Response  & Correction  & Response   & Correction  \\
\midrule
\endfirsthead
\multicolumn{6}{@{}l}{\textit{(continued)}}\\
\toprule
Response & Correction & Response  & Correction  & Response   & Correction  \\
\midrule
\endhead

\endfoot
\bottomrule
\endlastfoot
;ashtray & ashtray & draw & drawers & olobster & lobster\\
a & no & drawer & drawers & onions & onion\\
acoop & scoop & draws & drawers & onions & onion\\
ancher & anchor & drums & drum & osterich & ostrich\\
anchore & anchor & eagal & eagle & ostrage & ostrich\\
\addlinespace
ancor & anchor & eclipes & eclipse & ostridge & ostrich\\
anker & anchor & eclipses & eclipse & ostrige & ostrich\\
aparagus & asparagus & eclipsse & eclipse & ostrisge & ostrich\\
apricorte & apricot & eeagle & eagle & ostritch & ostrich\\
ashtry & ashtray & eele & seal & pair & pear\\
\addlinespace
ballon & balloon & eyeglass & eyeglasses & paper & pepper\\
ballone & balloon & falg & flag & peacck & peacock\\
balloone & balloon & feet & foot & pecock & peacock\\
ballun & balloon & fencing & fence & peguin & penguin\\
baloon & balloon & footstall & footstool & peneut & peanut\\
\addlinespace
bamnna & banana & fott & foot & pengiuin & penguin\\
bananaa & banana & frock & frog & pengiun & penguin\\
bananna & banana & frog/ & frog & penguine & penguin\\
bannan & banana & geese & goose & penquin & penguin\\
bannana & banana & giaffee & giraffe & peper & pepper\\
\addlinespace
barel & barrel & giaraffe & giraffe & pestleandmorter & pestleandmortar\\
barrell & barrel & girafe & giraffe & piccalo & piccolo\\
barrle & barrel & giraff & giraffe & pilers & pliers\\
barrow & barrel & giraffee & giraffe & pliars & pliers\\
beatle & beetle & girafffe & giraffe & plier & pliers\\
\addlinespace
beer & bear & girrafe & giraffe & pliyers & pliers\\
bellpepp34 & bellpepper & girraffe & giraffe & plugin & plug\\
bettle & beetle & gitaur & guitar & plyers & pliers\\
bicucle & bicycle & gitter & guitar & potatoe & potato\\
bicyle & bicycle & glases & glasses & pottato & potato\\
\addlinespace
bittle & bottle & glass & glasses & pumkin & pumpkin\\
bittle & beetle & glassesbottle & bottle & pumpkim & pumpkin\\
blueberrys & blueberries & gloves & glove & punpkin & pumpkin\\
bolw & bowl & grape & grapes & rabit & rabbit\\
bootle & bottle & gutair & guitar & racoon & raccoon\\
\addlinespace
broon & broom & haircomb & comb & rubarb & rhubarb\\
broon & broom & hamp & harp & rule & ruler\\
brum & broom & hand5 & hand & seel & seal\\
busket & basket & harper & hamper & showel & shovel\\
bycycle & bicycle & hemmar & hammer & snakw & snake\\
\addlinespace
camal & camel & hose & house & soak & socks\\
canddle & candle & idk & no & specs & spectacles\\
canle & candle & kacket & jacket & spon & spoon\\
canon & cannon & kangroo & kangaroo & ssnowman & snowman\\
carott & carrot & ladders & ladder & steplader & stepladder\\
\addlinespace
carrots & carrot & lader & ladder & sterss & step\\
carrott & carrot & latter & ladder & sweetcirn & sweetcorn\\
celary & celery & leafe & leaf & tabaccopipe & tobaccopipe\\
celeary & celery & leamon & lemon & teakettle & kettle\\
cellary & celery & leema & lemur & thinbell & thimble\\
\addlinespace
cerlery & celery & lettace & lettuce & thmble & thimble\\
chain2 & chain & lip & lips & thunb & thumb\\
chestofdrawerserss & chest of drawers & longdress & dress & timbil & thimble\\
chestofdraws & chest of drawers & maledear & maledeer & timble & thimble\\
chisle & chisel & meercat & meerkat & toitouse & tortoise\\
\addlinespace
chissel & chisel & mercat & meerkat & tomatoe & tomato\\
chizel & chisel & mice & mouse & tomoato & tomato\\
claranet & clarinet & mit & mitten & tortise & tortoise\\
clouds & cloud & mittens & mitten & tortiste & tortoise\\
cochroach & cockroach & monkeybut & monkeynut & tortus & tortoise\\
\addlinespace
cock & cockerel & mortle & mortar & usplug & plug\\
cockaroach & cockroach & mousse & moose & valture & vulture\\
cockrel & cockerel & muscat & muskrat & vicescripts & vicegrips\\
combe & comb & nectarin & nectarine & vioin & violin\\
cycle & bicycle & nectarinee & nectarine & violen & violin\\
\addlinespace
dear & deer & nectrine & nectarine & volion & violin\\
deere & deer & neddle & needle & waistcoast & waistcoat\\
dock & duck & noise & nose & wale & well\\
dolly & doll & none & no & wastecoat & waistcoat\\
doormouse & dormouse & oencil & pencil & whisell & whistle\\
\addlinespace
 &  &  &  & whistel & whistle\\
 &  &  &  & whitle & whistle\\
 &  &  &  & whsitle & whistle\\
 &  &  &  & windown & window\\*
\end{longtable}
\endgroup{}
\end{landscape}

\newpage

\hypertarget{appendix-c-normative-data-for-all-photograph-items.}{%
\subsection{Appendix C: Normative data for all photograph
items.}\label{appendix-c-normative-data-for-all-photograph-items.}}

\begingroup\fontsize{8}{10}\selectfont

\begin{longtable}{>{\raggedright\arraybackslash}p{4cm}>{\raggedright\arraybackslash}p{2cm}>{\raggedright\arraybackslash}p{2cm}>{\raggedright\arraybackslash}p{2cm}>{\raggedright\arraybackslash}p{2cm}}
\toprule
Photograph & Familiarity & Visual Complexity & Colour Diagnosticity & Mental Imagery\\
\midrule
\endfirsthead
\multicolumn{5}{@{}l}{\textit{(continued)}}\\
\toprule
Photograph & Familiarity & Visual Complexity & Colour Diagnosticity & Mental Imagery\\
\midrule
\endhead

\endfoot
\bottomrule
\endlastfoot
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{anchor}}\\
\hspace{1em}anchor1-photo-colour & 3.55 (1.32) & 3 (1.11) & 2.77 (1.19) & 4.05 (1.05)\\
\hspace{1em}anchor1-photo-grey & 3.03 (1.47) & 2.81 (0.93) &  & 3.95 (0.89)\\
\hspace{1em}anchor2-photo-colour & 3.38 (1.56) & 3.45 (1.23) & 3.5 (1.19) & 3.75 (1.25)\\
\hspace{1em}anchor2-photo-grey & 2.82 (1.53) & 3 (0.97) &  & 3.52 (1.33)\\
\hspace{1em}anchor3-photo-colour & 3.5 (1.3) & 2.48 (0.93) & 2.76 (1.3) & 3.86 (1.01)\\
\hspace{1em}anchor3-photo-grey & 3.04 (1.43) & 2.46 (1.22) &  & 4.27 (0.77)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{apple}}\\
\hspace{1em}apple1-photo-colour & 4.8 (0.48) & 3.1 (1.14) & 3.43 (1.08) & 4.15 (0.88)\\
\hspace{1em}apple1-photo-grey & 4.85 (0.49) & 2.32 (1.21) &  & 3.05 (1.23)\\
\hspace{1em}apple2-photo-colour & 4.91 (0.29) & 3 (0.97) & 3.5 (1.32) & 3.76 (1.04)\\
\hspace{1em}apple2-photo-grey & 4.24 (1.14) & 2.4 (0.99) &  & 2.75 (1.45)\\
\hspace{1em}apple3-photo-colour & 4.77 (0.53) & 3.16 (1.37) & 3.68 (1.25) & 4.27 (0.98)\\
\hspace{1em}apple3-photo-grey & 4.73 (0.63) & 2.38 (1.07) &  & 3.38 (1.28)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{ashtray}}\\
\hspace{1em}ashtray1-photo-colour & 3.77 (1.43) & 3.05 (1.16) & 2.71 (1.1) & 3.9 (1.07)\\
\hspace{1em}ashtray1-photo-grey & 4.15 (1.14) & 2.95 (1.13) &  & 3.5 (1.28)\\
\hspace{1em}ashtray2-photo-colour & 3.86 (1.46) & 3 (1.08) & 2.25 (1.29) & 4.1 (1.3)\\
\hspace{1em}ashtray2-photo-grey & 3.52 (1.47) & 3 (1.12) &  & 3.5 (1.28)\\
\hspace{1em}ashtray3-photo-colour & 3.36 (1.47) & 3.75 (1.15) & 3.21 (1.32) & 3.5 (1.19)\\
\hspace{1em}ashtray3-photo-grey & 4.14 (0.99) & 3.09 (1.11) &  & 3.76 (1)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{balloon}}\\
\hspace{1em}balloon1-photo-colour & 4.4 (1.1) & 1.63 (1) & 2.35 (1.69) & 4.62 (0.92)\\
\hspace{1em}balloon1-photo-grey & 4.15 (1.18) & 1.8 (1.11) &  & 3.41 (1.1)\\
\hspace{1em}balloon2-photo-colour & 4.45 (1) & 2.14 (1.08) & 1.82 (1.3) & 4.5 (1)\\
\hspace{1em}balloon2-photo-grey & 4.35 (0.81) & 1.9 (1) &  & 4.05 (0.94)\\
\hspace{1em}balloon3-photo-colour & 4.09 (1.02) & 1.86 (1.04) & 1.86 (1.49) & 4.46 (0.88)\\
\hspace{1em}balloon3-photo-grey & 4.24 (0.94) & 1.68 (0.99) &  & 3.57 (1.4)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{banana}}\\
\hspace{1em}banana1-photo-colour & 4.65 (0.99) & 2.55 (1.5) & 4.55 (0.76) & 4.45 (0.86)\\
\hspace{1em}banana1-photo-grey & 4.8 (0.7) & 2.23 (1.1) & 2.36 (1.5) & 3.76 (0.94)\\
\hspace{1em}banana2-photo-colour & 4.8 (0.41) & 2.05 (1.24) & 4 (1.3) & 4.85 (0.37)\\
\hspace{1em}banana2-photo-grey & 4.9 (0.45) & 2.36 (1.36) &  & 3.3 (1.42)\\
\hspace{1em}banana3-photo-colour & 4.33 (1.02) & 2.05 (1.09) & 4.59 (0.96) & 4.67 (0.66)\\
\hspace{1em}banana3-photo-grey & 4.86 (0.47) & 2 (0.87) &  & 3.58 (1.1)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{barrel}}\\
\hspace{1em}barrel1-photo-colour & 3.53 (1.25) & 3.57 (0.93) & 3.95 (0.97) & 4.9 (0.45)\\
\hspace{1em}barrel1-photo-grey & 3.9 (1.29) & 3 (1.02) &  & 4.05 (1.05)\\
\hspace{1em}barrel2-photo-colour & 4 (1.02) & 3 (1.08) & 3.5 (1.15) & 4.43 (0.81)\\
\hspace{1em}barrel2-photo-grey & 3.81 (1.54) & 2.95 (1.1) &  & 4.15 (0.93)\\
\hspace{1em}barrel3-photo-colour & 3.5 (1.26) & 3.38 (1.17) & 2.96 (1.3) & 4.22 (0.95)\\
\hspace{1em}barrel3-photo-grey & 3.45 (1.5) & 2.68 (1.13) &  & 4 (0.95)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{basket}}\\
\hspace{1em}basket1-photo-colour & 4.13 (1.04) & 3.86 (0.96) & 3.62 (1.24) & 4.3 (1.13)\\
\hspace{1em}basket1-photo-grey & 4.5 (0.83) & 3.36 (1.09) &  & 3.85 (1.14)\\
\hspace{1em}basket2-photo-colour & 4.14 (1.08) & 3.05 (1) & 2.8 (1.36) & 3.95 (0.97)\\
\hspace{1em}basket2-photo-grey & 4.48 (0.93) & 2.9 (1.45) &  & 3.55 (1.23)\\
\hspace{1em}basket3-photo-colour & 4.27 (0.83) & 3.8 (1.08) & 3.48 (1.53) & 3.64 (1.14)\\
\hspace{1em}basket3-photo-grey & 4.45 (0.86) & 3.18 (1.1) &  & 3.95 (0.92)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{bear}}\\
\hspace{1em}bear1-photo-colour & 3.36 (1.53) & 3.9 (0.79) & 3.9 (0.72) & 4.15 (1.09)\\
\hspace{1em}bear1-photo-grey & 3.9 (1.34) & 3.5 (1.15) &  & 3.93 (1.08)\\
\hspace{1em}bear2-photo-colour & 3.85 (1.53) & 3.25 (0.91) & 4.3 (0.73) & 4.24 (1.22)\\
\hspace{1em}bear2-photo-grey & 3.25 (1.45) & 3.25 (1.16) &  & 4.27 (1.12)\\
\hspace{1em}bear3-photo-colour & 3.9 (1.37) & 3.81 (1.25) & 3.71 (1.1) & 4.09 (0.87)\\
\hspace{1em}bear3-photo-grey & 3.75 (1.48) & 3 (1.02) &  & 4 (1.23)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{beetle}}\\
\hspace{1em}beetle1-photo-colour & 3.1 (1.59) & 4 (0.79) & 3.15 (1.5) & 2.95 (1.07)\\
\hspace{1em}beetle1-photo-grey & 3.1 (1.45) & 3.1 (1.21) &  & 2.95 (1.21)\\
\hspace{1em}beetle2-photo-colour & 3.2 (1.4) & 3.73 (1.16) & 3 (1.38) & 2.95 (1.19)\\
\hspace{1em}beetle2-photo-grey & 3 (1.34) & 2.95 (1.24) &  & 2.7 (1.13)\\
\hspace{1em}beetle3-photo-colour & 2.68 (1.25) & 3.41 (0.96) & 3.05 (1.13) & 3.17 (1.05)\\
\hspace{1em}beetle3-photo-grey & 3 (1.26) & 3.18 (1.05) &  & 3.24 (1.04)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{bell}}\\
\hspace{1em}bell1-photo-colour & 4 (1.21) & 2.47 (1.41) & 3.55 (1.39) & 4 (1.05)\\
\hspace{1em}bell1-photo-grey & 3.8 (1.28) & 2.45 (1.05) &  & 3.64 (0.95)\\
\hspace{1em}bell2-photo-colour & 3.9 (1.14) & 3.32 (0.95) & 3.41 (1.3) & 3.95 (1.1)\\
\hspace{1em}bell2-photo-grey & 3.5 (1.15) & 2.24 (0.62) &  & 3.3 (0.86)\\
\hspace{1em}bell3-photo-colour & 3.43 (1.41) & 3.09 (1.02) & 2.91 (1.34) & 3.5 (1.06)\\
\hspace{1em}bell3-photo-grey & 3.62 (1.47) & 2.82 (0.96) &  & 3.05 (1.36)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{belt}}\\
\hspace{1em}belt1-photo-colour & 4.8 (0.52) & 2.86 (1.21) & 2.68 (1.46) & 3.95 (0.83)\\
\hspace{1em}belt1-photo-grey & 4.6 (0.89) & 3.05 (0.97) &  & 4 (0.92)\\
\hspace{1em}belt2-photo-colour & 4.71 (0.72) & 3 (1.38) & 2.85 (1.46) & 4.05 (1.05)\\
\hspace{1em}belt2-photo-grey & 4.64 (0.79) & 2.4 (1.1) &  & 4.48 (0.87)\\
\hspace{1em}belt3-photo-colour & 4.86 (0.64) & 2.43 (1.29) & 3.05 (1.43) & 4.24 (0.77)\\
\hspace{1em}belt3-photo-grey & 4.35 (1.03) & 2.21 (1.28) &  & 3.95 (1.09)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{bicycle}}\\
\hspace{1em}bicycle1-photo-colour & 4.3 (1.13) & 3.55 (1.1) & 2.45 (1.47) & 3.14 (1.17)\\
\hspace{1em}bicycle1-photo-grey & 4.5 (1) & 3.6 (1.04) & 1.73 (1.19) & 3.33 (1.2)\\
\hspace{1em}bicycle2-photo-colour & 4.65 (0.67) & 2.95 (1.12) & 1.57 (0.98) & 4.05 (0.94)\\
\hspace{1em}bicycle2-photo-grey & 4.76 (0.62) & 3.41 (1.05) &  & 3.65 (0.93)\\
\hspace{1em}bicycle3-photo-colour & 3.86 (1.15) & 3.27 (0.98) & 1.91 (1.27) & 3.38 (1.16)\\
\hspace{1em}bicycle3-photo-grey & 4.05 (1.05) & 3.48 (0.99) &  & 3.33 (1.46)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{book}}\\
\hspace{1em}book1-photo-colour & 4.85 (0.37) & 3.15 (1.23) & 2.4 (1.27) & 3.59 (1.14)\\
\hspace{1em}book1-photo-grey & 4.9 (0.45) & 2.7 (0.99) & 1.45 (0.93) & 3.62 (0.8)\\
\hspace{1em}book2-photo-colour & 4.75 (0.72) & 3.1 (1.09) & 1.71 (1.06) & 3.65 (1.35)\\
\hspace{1em}book2-photo-grey & 4.75 (0.55) & 2.86 (1.08) &  & 3.2 (1.15)\\
\hspace{1em}book3-photo-colour & 4.33 (0.91) & 3.05 (1.05) & 2.27 (1.24) & 3 (1.14)\\
\hspace{1em}book3-photo-grey & 4.04 (1.36) & 2.45 (0.51) &  & 3 (1.18)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{boot}}\\
\hspace{1em}boot1-photo-colour & 4.15 (1.18) & 2.95 (1.05) & 2.5 (1.47) & 3.27 (1.2)\\
\hspace{1em}boot1-photo-grey & 4.7 (0.47) & 2.93 (1.36) & 2.82 (1.6) & 2.76 (0.94)\\
\hspace{1em}boot2-photo-colour & 4.6 (0.6) & 2.95 (1.2) & 2.1 (0.94) & 4.25 (0.85)\\
\hspace{1em}boot2-photo-grey & 4.7 (0.66) & 3.41 (1.01) &  & 3.75 (1.02)\\
\hspace{1em}boot3-photo-colour & 4.29 (0.96) & 2.95 (1.09) & 2.45 (1.44) & 4.1 (1)\\
\hspace{1em}boot3-photo-grey & 4.52 (0.67) & 2.95 (1) &  & 3.79 (1.22)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{bottle}}\\
\hspace{1em}bottle1-photo-colour & 4.57 (0.73) & 3.33 (1.35) & 3.14 (1.2) & 3.7 (0.98)\\
\hspace{1em}bottle1-photo-grey & 4.85 (0.37) & 2.45 (1.1) &  & 3.15 (0.99)\\
\hspace{1em}bottle2-photo-colour & 4.82 (0.5) & 2.25 (1.07) & 2.25 (1.21) & 2.81 (1.5)\\
\hspace{1em}bottle2-photo-grey & 4.48 (1.12) & 1.85 (0.93) &  & 3.2 (1.11)\\
\hspace{1em}bottle3-photo-colour & 4.45 (0.91) & 1.92 (1.28) & 2.04 (1.23) & 2.55 (1.18)\\
\hspace{1em}bottle3-photo-grey & 4.5 (0.96) & 1.5 (1.01) &  & 3.33 (1.43)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{bowl}}\\
\hspace{1em}bowl1-photo-colour & 4.68 (0.78) & 2.25 (1.16) & 1.65 (0.99) & 3.7 (1.13)\\
\hspace{1em}bowl1-photo-grey & 4.81 (0.51) & 2 (0.86) &  & 3.03 (1)\\
\hspace{1em}bowl2-photo-colour & 4.8 (0.41) & 2.5 (1.1) & 1.9 (1.55) & 3.43 (1.16)\\
\hspace{1em}bowl2-photo-grey & 4.75 (0.44) & 1.9 (1.45) &  & 4.05 (1.09)\\
\hspace{1em}bowl3-photo-colour & 4.62 (0.67) & 2.19 (1.25) & 1.9 (1.45) & 3.27 (1.28)\\
\hspace{1em}bowl3-photo-grey & 4.52 (0.92) & 1.73 (0.98) &  & 3.09 (1.06)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{bread}}\\
\hspace{1em}bread1-photo-colour & 4.82 (0.66) & 3.45 (0.94) & 3.85 (1.04) & 3.8 (1.15)\\
\hspace{1em}bread1-photo-grey & 4.52 (0.87) & 2.8 (1.06) &  & 3.07 (1.01)\\
\hspace{1em}bread2-photo-colour & 5 (0) & 3.2 (1.24) & 3.75 (1.02) & 3.81 (1.21)\\
\hspace{1em}bread2-photo-grey & 4.9 (0.31) & 2.35 (1.31) &  & 3.36 (1.18)\\
\hspace{1em}bread3-photo-colour & 4.71 (0.64) & 3.48 (1.36) & 3.29 (1.27) & 3.41 (1.37)\\
\hspace{1em}bread3-photo-grey & 4.67 (0.64) & 2.59 (0.96) &  & 3.26 (1.18)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{broom}}\\
\hspace{1em}broom1-photo-colour & 4.09 (1.19) & 2.3 (1.08) & 2.55 (1.19) & 3.35 (1.35)\\
\hspace{1em}broom1-photo-grey & 4.29 (1.01) & 2.55 (1.05) &  & 3.27 (1.14)\\
\hspace{1em}broom2-photo-colour & 4.2 (1.15) & 2.85 (1.09) & 3.3 (1.3) & 3.14 (1.46)\\
\hspace{1em}broom2-photo-grey & 4.05 (0.76) & 2.1 (1.02) &  & 3.41 (1.37)\\
\hspace{1em}broom3-photo-colour & 4 (1) & 2.38 (1.02) & 2.67 (1.28) & 3.73 (1.45)\\
\hspace{1em}broom3-photo-grey & 4.12 (1.12) & 2.27 (1.24) &  & 3.32 (1.36)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{brush}}\\
\hspace{1em}brush1-photo-colour & 4.33 (0.91) & 3 (1.17) & 2.15 (1.42) & 2.27 (1.36)\\
\hspace{1em}brush1-photo-grey & 4.41 (0.8) & 2.8 (0.83) &  & 2.85 (1.39)\\
\hspace{1em}brush2-photo-colour & 4.1 (0.97) & 3.5 (1.24) & 3.65 (1.23) & 2.18 (1.22)\\
\hspace{1em}brush2-photo-grey & 4 (0.97) & 3.2 (1.11) &  & 2.24 (1.3)\\
\hspace{1em}brush3-photo-colour & 4.38 (0.97) & 3.13 (1.18) & 2.87 (1.42) & 2.64 (1.29)\\
\hspace{1em}brush3-photo-grey & 4 (0.95) & 3.14 (1.06) &  & 2.55 (1.22)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{button}}\\
\hspace{1em}button1-photo-colour & 4.45 (1) & 2.77 (1.27) & 1.91 (1.23) & 3.05 (1.54)\\
\hspace{1em}button1-photo-grey & 4.57 (0.77) & 2.33 (1.02) &  & 4.05 (1.23)\\
\hspace{1em}button2-photo-colour & 4.71 (0.78) & 1.55 (0.89) & 1.45 (0.83) & 4.45 (1.1)\\
\hspace{1em}button2-photo-grey & 4.82 (0.5) & 1.5 (0.83) &  & 4.24 (1.34)\\
\hspace{1em}button3-photo-colour & 4.68 (0.57) & 2.14 (1.46) & 1.77 (1.15) & 3.67 (1.28)\\
\hspace{1em}button3-photo-grey & 4.55 (0.74) & 2 (1.5) &  & 3.55 (1.14)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{cake}}\\
\hspace{1em}cake1-photo-colour & 4.62 (0.59) & 3.35 (1.04) & 2.5 (1.57) & 3.27 (1.01)\\
\hspace{1em}cake1-photo-grey & 4.73 (0.63) & 3.9 (0.91) &  & 3.35 (1.27)\\
\hspace{1em}cake2-photo-colour & 4.5 (0.69) & 4.4 (0.99) & 2.6 (1.93) & 3.68 (1.21)\\
\hspace{1em}cake2-photo-grey & 4.7 (0.57) & 4 (0.92) &  & 2.62 (1.2)\\
\hspace{1em}cake3-photo-colour & 4.79 (0.41) & 3.7 (0.97) & 2.91 (1.2) & 3.14 (1.32)\\
\hspace{1em}cake3-photo-grey & 4.19 (1.03) & 2.9 (1) &  & 2.55 (1.1)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{camel}}\\
\hspace{1em}camel1-photo-colour & 3.4 (1.57) & 3.6 (1.19) & 3.75 (1.21) & 4.18 (1.14)\\
\hspace{1em}camel1-photo-grey & 3.65 (1.6) & 3.8 (1.03) & 2.36 (1.5) & 3.95 (1.07)\\
\hspace{1em}camel2-photo-colour & 3.9 (1.17) & 3.52 (1.44) & 3.95 (1.16) & 3.85 (0.93)\\
\hspace{1em}camel2-photo-grey & 3.3 (1.72) & 3.82 (1.01) &  & 3.35 (0.99)\\
\hspace{1em}camel3-photo-colour & 3.29 (1.42) & 3.5 (1.01) & 4.41 (0.96) & 4.29 (0.9)\\
\hspace{1em}camel3-photo-grey & 2.87 (1.55) & 3.18 (1.01) &  & 3.92 (1.14)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{candle}}\\
\hspace{1em}candle1-photo-colour & 4.6 (0.68) & 2.33 (0.92) & 3 (1.21) & 3.67 (1.06)\\
\hspace{1em}candle1-photo-grey & 4.45 (0.89) & 1.8 (0.89) &  & 2.95 (1.09)\\
\hspace{1em}candle2-photo-colour & 4.71 (0.64) & 2.59 (1.01) & 2.45 (1.5) & 3.65 (1.14)\\
\hspace{1em}candle2-photo-grey & 4.35 (0.93) & 1.76 (1) &  & 3.8 (1.15)\\
\hspace{1em}candle3-photo-colour & 3.5 (1.06) & 2.95 (1) & 2.55 (1.14) & 3 (0.98)\\
\hspace{1em}candle3-photo-grey & 4.14 (0.79) & 2.41 (0.85) &  & 2.62 (1.28)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{cannon}}\\
\hspace{1em}cannon1-photo-colour & 3.2 (1.51) & 3.32 (1.13) & 3.32 (1.21) & 3.7 (0.92)\\
\hspace{1em}cannon1-photo-grey & 3.1 (1.49) & 3.43 (0.87) &  & 3.8 (1.36)\\
\hspace{1em}cannon2-photo-colour & 3.9 (1.34) & 3.3 (1.03) & 3.75 (1.02) & 3.95 (0.69)\\
\hspace{1em}cannon2-photo-grey & 3.45 (1.44) & 2.8 (0.95) &  & 3.71 (1.19)\\
\hspace{1em}cannon3-photo-colour & 3.32 (1.59) & 3.55 (1.1) & 2.91 (1.34) & 3.1 (1.26)\\
\hspace{1em}cannon3-photo-grey & 3 (1.38) & 3.24 (1.13) &  & 2.59 (1.5)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{carrot}}\\
\hspace{1em}carrot1-photo-colour & 4.91 (0.29) & 3 (1.12) & 4.15 (1.27) & 4.25 (0.85)\\
\hspace{1em}carrot1-photo-grey & 4.57 (0.6) & 2.25 (0.97) &  & 2.87 (1.04)\\
\hspace{1em}carrot2-photo-colour & 4.9 (0.31) & 3.1 (1.17) & 4.6 (0.68) & 4.1 (1.26)\\
\hspace{1em}carrot2-photo-grey & 4.75 (0.55) & 2.35 (0.99) &  & 3.55 (1.1)\\
\hspace{1em}carrot3-photo-colour & 4.71 (0.56) & 3.52 (1.21) & 4.19 (0.98) & 3.91 (1.11)\\
\hspace{1em}carrot3-photo-grey & 4.6 (0.58) & 3.23 (1.07) &  & 3.64 (1.09)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{celery}}\\
\hspace{1em}celery1-photo-colour & 4.4 (0.99) & 2.33 (1.35) & 4.5 (0.89) & 4.1 (1)\\
\hspace{1em}celery1-photo-grey & 4 (1.38) & 1.95 (1.23) &  & 2.91 (1.23)\\
\hspace{1em}celery2-photo-colour & 4.15 (1.27) & 3.32 (0.99) & 4.55 (0.91) & 3.9 (1.12)\\
\hspace{1em}celery2-photo-grey & 3.9 (1.12) & 3 (1.26) &  & 2.75 (1.21)\\
\hspace{1em}celery3-photo-colour & 3.22 (1.54) & 3 (1.02) & 4.27 (1.28) & 4.04 (1.16)\\
\hspace{1em}celery3-photo-grey & 3.71 (1.38) & 3.14 (1.08) &  & 2.86 (1.35)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{chain}}\\
\hspace{1em}chain1-photo-colour & 4.1 (1.25) & 2.3 (1.12) & 3.1 (1.37) & 3.67 (1.15)\\
\hspace{1em}chain1-photo-grey & 3.55 (1.39) & 2.1 (1.17) &  & 3.27 (1.55)\\
\hspace{1em}chain2-photo-colour & 4.2 (0.89) & 2.55 (1.1) & 2.82 (1.26) & 3.6 (1.35)\\
\hspace{1em}chain2-photo-grey & 3.75 (1.16) & 1.9 (0.89) &  & 4.55 (0.69)\\
\hspace{1em}chain3-photo-colour & 3.77 (1.41) & 2.7 (0.88) & 3.39 (1.27) & 4.08 (1.21)\\
\hspace{1em}chain3-photo-grey & 3.67 (1.39) & 2.32 (1.09) &  & 3.86 (1.11)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{chair}}\\
\hspace{1em}chair1-photo-colour & 4.76 (0.77) & 3.15 (1.14) & 2.9 (1.45) & 3.53 (1.28)\\
\hspace{1em}chair1-photo-grey & 4.64 (0.66) & 3.1 (0.72) &  & 3.4 (1.31)\\
\hspace{1em}chair2-photo-colour & 4.6 (0.75) & 3.1 (1.25) & 3 (1.56) & 3.77 (1.23)\\
\hspace{1em}chair2-photo-grey & 4.95 (0.22) & 2.7 (1.08) &  & 3.38 (1.36)\\
\hspace{1em}chair3-photo-colour & 5 (0) & 2.13 (1.18) & 3.04 (1.33) & 4.32 (0.89)\\
\hspace{1em}chair3-photo-grey & 4.76 (0.54) & 2.57 (0.98) &  & 3.41 (1.22)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{cherry}}\\
\hspace{1em}cherry1-photo-colour & 4.4 (0.94) & 2.55 (1.32) & 4.3 (0.8) & 4.18 (1.18)\\
\hspace{1em}cherry1-photo-grey & 4.2 (1.11) & 2.27 (1.11) & 1.73 (1.1) & 3.48 (1.03)\\
\hspace{1em}cherry2-photo-colour & 4.3 (0.8) & 2.19 (1.36) & 4.05 (1.2) & 4.7 (0.57)\\
\hspace{1em}cherry2-photo-grey & 4.45 (0.83) & 2.36 (1) &  & 3.25 (1.25)\\
\hspace{1em}cherry3-photo-colour & 4.14 (1.06) & 2.59 (1.18) & 4.41 (0.96) & 4.48 (0.75)\\
\hspace{1em}cherry3-photo-grey & 3.87 (1.18) & 2.23 (0.97) &  & 3.62 (1.06)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{chicken}}\\
\hspace{1em}chicken1-photo-colour & 4.33 (0.96) & 4.14 (1.06) & 3.81 (1.12) & 3.85 (0.93)\\
\hspace{1em}chicken1-photo-grey & 4.25 (1.12) & 3.59 (1.14) &  & 2.9 (1.17)\\
\hspace{1em}chicken2-photo-colour & 4.36 (1.05) & 4 (0.92) & 3.35 (1.04) & 4.43 (0.98)\\
\hspace{1em}chicken2-photo-grey & 4.38 (0.86) & 3.4 (1.47) &  & 3.7 (1.13)\\
\hspace{1em}chicken3-photo-colour & 4.14 (0.94) & 4.29 (0.86) & 3.79 (1.35) & 3.59 (1.1)\\
\hspace{1em}chicken3-photo-grey & 4 (1.11) & 3.59 (1.26) &  & 3.29 (1.15)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{chisel}}\\
\hspace{1em}chisel1-photo-colour & 3.91 (1.27) & 2.8 (1.15) & 2.4 (1.31) & 3.7 (1.17)\\
\hspace{1em}chisel1-photo-grey & 3.86 (1.2) & 2.45 (1.15) &  & 3.33 (1.35)\\
\hspace{1em}chisel2-photo-colour & 3.45 (1.36) & 3.6 (1.1) & 2.7 (1.45) & 3.62 (1.4)\\
\hspace{1em}chisel2-photo-grey & 2.6 (1.5) & 2.5 (1.4) &  & 3.91 (0.75)\\
\hspace{1em}chisel3-photo-colour & 3.1 (1.58) & 3.14 (1.11) & 2.62 (1.2) & 3.73 (1.16)\\
\hspace{1em}chisel3-photo-grey & 2.62 (1.31) & 2.27 (1.12) &  & 3.59 (1.33)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{clock}}\\
\hspace{1em}clock1-photo-colour & 5 (0) & 3.18 (0.96) & 2.82 (1.22) & 3.55 (1.19)\\
\hspace{1em}clock1-photo-grey & 4.73 (0.74) & 3.24 (1) &  & 4.2 (0.83)\\
\hspace{1em}clock2-photo-colour & 4.71 (0.64) & 3.15 (1.14) & 3.2 (1.51) & 2.9 (1.12)\\
\hspace{1em}clock2-photo-grey & 4.77 (0.43) & 2.6 (0.88) &  & 2.9 (1.3)\\
\hspace{1em}clock3-photo-colour & 4.82 (0.39) & 3.24 (1.04) & 2.38 (0.97) & 3.24 (1.34)\\
\hspace{1em}clock3-photo-grey & 4.36 (0.9) & 3.42 (1.38) &  & 2.59 (1.18)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{cloud}}\\
\hspace{1em}cloud1-photo-colour & 4.2 (1.15) & 2.9 (1.25) & 3.15 (1.04) & 4.05 (0.9)\\
\hspace{1em}cloud1-photo-grey & 4.75 (0.91) & 2.7 (1.26) & 3.64 (1.29) & 4 (1.14)\\
\hspace{1em}cloud2-photo-colour & 4.55 (0.94) & 2.86 (1.2) & 2.9 (1.34) & 3.15 (1.35)\\
\hspace{1em}cloud2-photo-grey & 4.2 (1.2) & 2.23 (1.15) &  & 2.55 (1.36)\\
\hspace{1em}cloud3-photo-colour & 4.48 (0.81) & 1.77 (0.92) & 4.32 (0.95) & 3.67 (1.32)\\
\hspace{1em}cloud3-photo-grey & 4.14 (1.17) & 2.18 (1.1) &  & 3.71 (1.04)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{comb}}\\
\hspace{1em}comb1-photo-colour & 4.55 (0.74) & 2.45 (1.23) & 2.25 (1.48) & 3.45 (1.23)\\
\hspace{1em}comb1-photo-grey & 4.67 (0.73) & 2.05 (1) &  & 3.6 (1.25)\\
\hspace{1em}comb2-photo-colour & 4.5 (0.89) & 2.85 (1.27) & 1.8 (1.32) & 4 (0.89)\\
\hspace{1em}comb2-photo-grey & 4.6 (0.75) & 1.85 (1.04) &  & 3.91 (0.87)\\
\hspace{1em}comb3-photo-colour & 4.57 (0.6) & 2.33 (1.06) & 1.81 (1.33) & 3.82 (1.22)\\
\hspace{1em}comb3-photo-grey & 4.54 (0.78) & 1.87 (0.97) &  & 4.23 (0.87)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{corn}}\\
\hspace{1em}corn1-photo-colour & 4.27 (0.88) & 3.8 (0.95) & 4.6 (0.75) & 4.25 (1.07)\\
\hspace{1em}corn1-photo-grey & 4.71 (0.56) & 2.9 (1.29) &  & 3.4 (1.13)\\
\hspace{1em}corn2-photo-colour & 4.55 (0.69) & 3.5 (1.19) & 4.55 (0.89) & 4.29 (1.27)\\
\hspace{1em}corn2-photo-grey & 4.45 (0.69) & 3 (1.34) &  & 4.18 (0.73)\\
\hspace{1em}corn3-photo-colour & 4.43 (0.81) & 3.57 (1.16) & 4.62 (0.59) & 4 (1.2)\\
\hspace{1em}corn3-photo-grey & 4.42 (0.83) & 3.05 (1.09) &  & 4.09 (0.92)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{crown}}\\
\hspace{1em}crown1-photo-colour & 3.77 (1.41) & 4.57 (0.6) & 4.38 (0.67) & 4.2 (0.95)\\
\hspace{1em}crown1-photo-grey & 4.2 (1.2) & 4.27 (1.08) &  & 3.4 (1.19)\\
\hspace{1em}crown2-photo-colour & 3.91 (1.48) & 4 (1.08) & 3.1 (1.41) & 4.19 (1.03)\\
\hspace{1em}crown2-photo-grey & 3.95 (1.47) & 3.5 (0.95) &  & 3.55 (1.23)\\
\hspace{1em}crown3-photo-colour & 3.27 (1.45) & 4.56 (0.71) & 4 (1.32) & 3.14 (1.21)\\
\hspace{1em}crown3-photo-grey & 3.45 (1.57) & 3.68 (1.21) &  & 3 (1.05)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{deer}}\\
\hspace{1em}deer1-photo-colour & 3.55 (1.54) & 3.55 (1.06) & 3.64 (1.18) & 3.15 (1.31)\\
\hspace{1em}deer1-photo-grey & 3.47 (1.5) & 3.29 (0.9) &  & 3.65 (1.18)\\
\hspace{1em}deer2-photo-colour & 3.43 (1.4) & 3.8 (1.15) & 4.4 (0.94) & 3.5 (1)\\
\hspace{1em}deer2-photo-grey & 3.36 (1.26) & 3.3 (1.22) &  & 3.1 (1.51)\\
\hspace{1em}deer3-photo-colour & 3.45 (1.34) & 3.64 (1.05) & 3.64 (1.26) & 3.86 (0.91)\\
\hspace{1em}deer3-photo-grey & 3.45 (1.3) & 3.42 (1.1) &  & 3.09 (1.16)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{doll}}\\
\hspace{1em}doll1-photo-colour & 4.4 (1.23) & 2.91 (1.06) & 2.73 (1.35) & 2.95 (1)\\
\hspace{1em}doll1-photo-grey & 3.8 (1.37) & 3.05 (0.74) &  & 3.2 (1.11)\\
\hspace{1em}doll2-photo-colour & 4.29 (1.06) & 4.05 (1.05) & 2.8 (1.28) & 3.35 (1.14)\\
\hspace{1em}doll2-photo-grey & 4.09 (1.19) & 3.4 (1.14) &  & 3.43 (1.33)\\
\hspace{1em}doll3-photo-colour & 4 (1.2) & 3.57 (1.25) & 3.05 (1.12) & 2.57 (1.16)\\
\hspace{1em}doll3-photo-grey & 3.55 (1.3) & 3.85 (1.35) &  & 2.68 (1.21)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{donkey}}\\
\hspace{1em}donkey1-photo-colour & 3.73 (1.2) & 3.55 (1.1) & 4.05 (0.94) & 4.45 (0.76)\\
\hspace{1em}donkey1-photo-grey & 4.14 (1.01) & 3.55 (1.19) &  & 3.93 (0.94)\\
\hspace{1em}donkey2-photo-colour & 4.15 (1.09) & 3.7 (1.13) & 3.6 (1.1) & 4.43 (0.98)\\
\hspace{1em}donkey2-photo-grey & 3.65 (1.27) & 3.05 (1.23) &  & 4.23 (0.97)\\
\hspace{1em}donkey3-photo-colour & 3.95 (1.12) & 3.62 (1.16) & 3.19 (1.21) & 4.32 (0.72)\\
\hspace{1em}donkey3-photo-grey & 3.46 (1.53) & 3.14 (1.17) &  & 4.09 (0.97)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{door}}\\
\hspace{1em}door1-photo-colour & 4.95 (0.22) & 2.33 (1.12) & 2.8 (1.51) & 3.43 (1.12)\\
\hspace{1em}door1-photo-grey & 4.8 (0.52) & 2.2 (1.15) &  & 3.27 (1.16)\\
\hspace{1em}door2-photo-colour & 4.8 (0.52) & 3.68 (1.09) & 1.91 (1.44) & 2.9 (1.17)\\
\hspace{1em}door2-photo-grey & 4.5 (0.89) & 2.71 (1.06) &  & 2.9 (0.97)\\
\hspace{1em}door3-photo-colour & 4.82 (0.39) & 2.32 (0.95) & 1.82 (1.05) & 3.96 (1.08)\\
\hspace{1em}door3-photo-grey & 4.81 (0.51) & 1.82 (0.8) &  & 3.57 (0.98)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{dress}}\\
\hspace{1em}dress1-photo-colour & 4.09 (1.11) & 3.45 (0.83) & 1.6 (1.1) & 2.8 (1.44)\\
\hspace{1em}dress1-photo-grey & 4.38 (0.74) & 2.7 (0.98) &  & 2.37 (1.03)\\
\hspace{1em}dress2-photo-colour & 4.7 (0.8) & 3.9 (0.97) & 2.2 (1.64) & 2.19 (1.21)\\
\hspace{1em}dress2-photo-grey & 4.15 (1.27) & 3.4 (1.31) &  & 2.82 (1.3)\\
\hspace{1em}dress3-photo-colour & 4 (1.05) & 2.71 (1.01) & 1.62 (0.97) & 2.77 (0.97)\\
\hspace{1em}dress3-photo-grey & 4.42 (0.97) & 2.05 (0.95) &  & 3.27 (0.88)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{dresser}}\\
\hspace{1em}dresser1-photo-colour & 4.25 (1.25) & 2.4 (1.27) & 2.15 (1.14) & 3.14 (1.32)\\
\hspace{1em}dresser1-photo-grey & 4.8 (0.52) & 2.27 (1.08) & 2.27 (1.42) & 3.1 (1.34)\\
\hspace{1em}dresser2-photo-colour & 4.5 (0.69) & 2.76 (0.89) & 1.62 (1.12) & 2.65 (1.31)\\
\hspace{1em}dresser2-photo-grey & 4.6 (0.6) & 2.77 (0.92) &  & 2.9 (1.45)\\
\hspace{1em}dresser3-photo-colour & 4.33 (0.8) & 3 (1.02) & 2.68 (1.17) & 3 (1.26)\\
\hspace{1em}dresser3-photo-grey & 4.55 (0.6) & 2.95 (1.05) &  & 3.52 (1.29)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{drum}}\\
\hspace{1em}drum1-photo-colour & 3.9 (1.41) & 3.59 (1.05) & 2.91 (1.31) & 3.6 (1.19)\\
\hspace{1em}drum1-photo-grey & 4 (1.02) & 3.48 (0.87) &  & 3.95 (0.89)\\
\hspace{1em}drum2-photo-colour & 3.81 (1.36) & 3.5 (1.1) & 2.45 (1.23) & 3.55 (1.15)\\
\hspace{1em}drum2-photo-grey & 4.05 (1.25) & 3.45 (1.05) &  & 4.1 (1.18)\\
\hspace{1em}drum3-photo-colour & 3.86 (1.46) & 3.24 (1.18) & 2.76 (1.26) & 3.9 (0.89)\\
\hspace{1em}drum3-photo-grey & 3.96 (1.22) & 3.25 (1.03) &  & 3.23 (1.27)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{duck}}\\
\hspace{1em}duck1-photo-colour & 4.71 (0.64) & 3.75 (1.25) & 3.85 (1.18) & 4.03 (0.96)\\
\hspace{1em}duck1-photo-grey & 4.09 (1.23) & 3.9 (1.07) &  & 3.55 (0.94)\\
\hspace{1em}duck2-photo-colour & 4.35 (0.99) & 4.65 (0.75) & 3.75 (1.41) & 4.23 (0.97)\\
\hspace{1em}duck2-photo-grey & 4.4 (0.82) & 4.1 (0.91) &  & 3.67 (1.32)\\
\hspace{1em}duck3-photo-colour & 4.04 (1.12) & 3.23 (1.23) & 3.59 (1.01) & 3.59 (1.18)\\
\hspace{1em}duck3-photo-grey & 4.62 (0.59) & 3.38 (1.07) &  & 3.18 (1.14)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{eagle}}\\
\hspace{1em}eagle1-photo-colour & 3.65 (1.5) & 3.87 (1.14) & 4.3 (1.17) & 4 (1.05)\\
\hspace{1em}eagle1-photo-grey & 3.15 (1.63) & 2.95 (1.19) &  & 3.23 (1.19)\\
\hspace{1em}eagle2-photo-colour & 3.4 (1.5) & 4.05 (1.33) & 4.23 (1.07) & 3.95 (1.15)\\
\hspace{1em}eagle2-photo-grey & 3.4 (1.19) & 3.71 (1.01) &  & 3.75 (1.07)\\
\hspace{1em}eagle3-photo-colour & 3.13 (1.46) & 3.5 (1.01) & 4.36 (0.95) & 4.46 (0.88)\\
\hspace{1em}eagle3-photo-grey & 3.14 (1.35) & 3.73 (1.03) &  & 3.48 (1.03)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{fence}}\\
\hspace{1em}fence1-photo-colour & 4.5 (0.74) & 2.25 (1.07) & 2.6 (1.23) & 3.5 (1.05)\\
\hspace{1em}fence1-photo-grey & 4.57 (0.68) & 1.95 (1) &  & 3.23 (0.94)\\
\hspace{1em}fence2-photo-colour & 4.75 (0.55) & 3.1 (1.02) & 2.75 (1.48) & 3.33 (1.2)\\
\hspace{1em}fence2-photo-grey & 4.5 (0.61) & 2.9 (1.41) &  & 2.86 (1.28)\\
\hspace{1em}fence3-photo-colour & 4.57 (0.87) & 3.05 (1.43) & 2.52 (1.36) & 3.86 (1.21)\\
\hspace{1em}fence3-photo-grey & 4.46 (0.83) & 2.41 (1.26) &  & 3.36 (1.29)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{fish}}\\
\hspace{1em}fish1-photo-colour & 4.62 (0.59) & 3.6 (1.14) & 3 (1.41) & 3.53 (1.17)\\
\hspace{1em}fish1-photo-grey & 4 (1.11) & 3.05 (0.94) &  & 3.3 (1.49)\\
\hspace{1em}fish2-photo-colour & 4.2 (0.95) & 4.05 (0.94) & 2.9 (1.37) & 3.23 (1.41)\\
\hspace{1em}fish2-photo-grey & 4.4 (0.75) & 4 (0.92) &  & 3.05 (1.32)\\
\hspace{1em}fish3-photo-colour & 4.38 (1.1) & 3.32 (1.25) & 2.91 (1.38) & 3.5 (1.34)\\
\hspace{1em}fish3-photo-grey & 4.1 (0.89) & 3.29 (1.15) &  & 3.95 (0.95)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{flag}}\\
\hspace{1em}flag1-photo-colour & 4.62 (0.8) & 2.4 (1.1) & 2.1 (1.33) & 2.9 (1.42)\\
\hspace{1em}flag1-photo-grey & 3.73 (1.39) & 2.15 (0.88) &  & 3.3 (1.38)\\
\hspace{1em}flag2-photo-colour & 4.05 (1.1) & 2.85 (1.35) & 4.25 (1.25) & 2.95 (1.46)\\
\hspace{1em}flag2-photo-grey & 4.6 (0.68) & 2.25 (0.91) &  & 2.48 (1.33)\\
\hspace{1em}flag3-photo-colour & 4.28 (1.02) & 2.5 (1.1) & 2.09 (1.31) & 3.09 (1.19)\\
\hspace{1em}flag3-photo-grey & 3.81 (1.17) & 2.29 (0.96) &  & 2.73 (1.52)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{flower}}\\
\hspace{1em}flower1-photo-colour & 4.45 (1) & 3.8 (1.36) & 3.1 (1.41) & 3.5 (1.34)\\
\hspace{1em}flower1-photo-grey & 4.65 (0.67) & 3.37 (1.03) & 1.82 (1.08) & 3.14 (1.31)\\
\hspace{1em}flower2-photo-colour & 4.25 (1.07) & 3.62 (1.16) & 1.81 (0.98) & 3.2 (1.2)\\
\hspace{1em}flower2-photo-grey & 3.9 (1.21) & 3.95 (1) &  & 2.4 (0.99)\\
\hspace{1em}flower3-photo-colour & 4.14 (0.85) & 3.82 (0.85) & 3.05 (1.33) & 3.14 (1.42)\\
\hspace{1em}flower3-photo-grey & 4.22 (0.8) & 3.59 (1.01) &  & 2.92 (1.1)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{flute}}\\
\hspace{1em}flute1-photo-colour & 3.35 (1.23) & 3.8 (1.03) & 4.1 (1.07) & 3.95 (1.24)\\
\hspace{1em}flute1-photo-grey & 3.3 (1.45) & 3.25 (1.16) &  & 3.77 (1.11)\\
\hspace{1em}flute2-photo-colour & 2.55 (1.39) & 2.86 (1.08) & 2.55 (1.26) & 2.8 (1.36)\\
\hspace{1em}flute2-photo-grey & 2.95 (1.5) & 2.48 (1.17) &  & 3.05 (1.43)\\
\hspace{1em}flute3-photo-colour & 3.04 (1.72) & 3.32 (0.95) & 3.59 (1.14) & 3.92 (1.35)\\
\hspace{1em}flute3-photo-grey & 3.05 (1.75) & 2.95 (1.05) &  & 4.05 (1.07)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{foot}}\\
\hspace{1em}foot1-photo-colour & 4.95 (0.22) & 2.8 (1.24) & 3.3 (1.42) & 4.27 (0.98)\\
\hspace{1em}foot1-photo-grey & 5 (0) & 2.97 (0.93) & 1.82 (0.98) & 4.05 (0.8)\\
\hspace{1em}foot2-photo-colour & 4.85 (0.49) & 2.62 (1.36) & 2.29 (1.27) & 3.55 (1.32)\\
\hspace{1em}foot2-photo-grey & 4.65 (0.81) & 3.36 (1.14) &  & 3.2 (1.2)\\
\hspace{1em}foot3-photo-colour & 4.81 (0.51) & 2.18 (1.01) & 2.95 (1.36) & 3.9 (1.37)\\
\hspace{1em}foot3-photo-grey & 4.91 (0.43) & 2.59 (1.14) &  & 3.96 (1.12)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{frog}}\\
\hspace{1em}frog1-photo-colour & 4.2 (1.32) & 3.86 (1.28) & 3.77 (1.07) & 3.95 (1.05)\\
\hspace{1em}frog1-photo-grey & 4.27 (0.87) & 3.9 (0.94) &  & 3.75 (0.97)\\
\hspace{1em}frog2-photo-colour & 4.05 (1.16) & 3.85 (1.09) & 3.95 (1.1) & 4 (1.03)\\
\hspace{1em}frog2-photo-grey & 4 (1.31) & 3.55 (1.19) &  & 3.81 (1.25)\\
\hspace{1em}frog3-photo-colour & 4 (1.07) & 3.86 (1.15) & 3.71 (1.38) & 4.14 (0.96)\\
\hspace{1em}frog3-photo-grey & 4.05 (1.13) & 3.88 (1.2) &  & 3.32 (0.99)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{giraffe}}\\
\hspace{1em}giraffe1-photo-colour & 4.43 (1.03) & 4.1 (1.07) & 4.85 (0.37) & 4.5 (0.97)\\
\hspace{1em}giraffe1-photo-grey & 3.41 (1.59) & 3.65 (1.09) &  & 4.15 (1.18)\\
\hspace{1em}giraffe2-photo-colour & 3.5 (1.36) & 4.25 (0.91) & 4.75 (0.55) & 4.59 (0.96)\\
\hspace{1em}giraffe2-photo-grey & 4 (1.41) & 3.8 (0.77) &  & 4.24 (1.09)\\
\hspace{1em}giraffe3-photo-colour & 3.83 (1.43) & 3.78 (1.09) & 4.39 (0.94) & 4.86 (0.47)\\
\hspace{1em}giraffe3-photo-grey & 4.14 (1.2) & 3.71 (1.19) &  & 4.18 (1.05)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{glasses}}\\
\hspace{1em}glasses1-photo-colour & 4.57 (0.6) & 2.6 (1.19) & 1.95 (1.32) & 3.87 (1.04)\\
\hspace{1em}glasses1-photo-grey & 4.64 (0.85) & 2.1 (0.79) &  & 4 (0.97)\\
\hspace{1em}glasses2-photo-colour & 4.8 (0.41) & 2.35 (1.23) & 2.35 (1.63) & 4.09 (0.92)\\
\hspace{1em}glasses2-photo-grey & 4.65 (0.81) & 2.15 (1.04) &  & 3.71 (1.45)\\
\hspace{1em}glasses3-photo-colour & 4.88 (0.45) & 2.68 (0.84) & 2.18 (1.14) & 3.05 (1.09)\\
\hspace{1em}glasses3-photo-grey & 4.33 (0.91) & 2.43 (1.03) &  & 3.32 (1.21)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{goat}}\\
\hspace{1em}goat1-photo-colour & 4.19 (1.03) & 3.9 (1.07) & 3.8 (0.95) & 4 (1.05)\\
\hspace{1em}goat1-photo-grey & 3.23 (1.31) & 3.75 (0.55) &  & 3.7 (1.08)\\
\hspace{1em}goat2-photo-colour & 3.6 (1.1) & 4 (0.97) & 3.25 (1.45) & 4.09 (0.97)\\
\hspace{1em}goat2-photo-grey & 3.95 (1) & 3.7 (1.03) &  & 3.9 (1.14)\\
\hspace{1em}goat3-photo-colour & 3.38 (1.53) & 3.91 (1.04) & 3.83 (1.15) & 3.32 (1.13)\\
\hspace{1em}goat3-photo-grey & 3.43 (1.21) & 3.81 (1.25) &  & 2.86 (1.21)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{grapes}}\\
\hspace{1em}grapes1-photo-colour & 4.65 (0.75) & 3.53 (1.14) & 4.2 (0.89) & 3.76 (1)\\
\hspace{1em}grapes1-photo-grey & 4.7 (0.57) & 2.85 (1.31) &  & 3 (1.31)\\
\hspace{1em}grapes2-photo-colour & 4.45 (0.76) & 3.82 (1.18) & 3.64 (1.14) & 3.25 (1.16)\\
\hspace{1em}grapes2-photo-grey & 4.2 (1.01) & 3.48 (0.98) &  & 3 (0.97)\\
\hspace{1em}grapes3-photo-colour & 4.61 (0.66) & 3.32 (0.99) & 3.68 (0.95) & 3.96 (1.04)\\
\hspace{1em}grapes3-photo-grey & 4.43 (0.68) & 3.45 (0.91) &  & 3.14 (1.01)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{guitar}}\\
\hspace{1em}guitar1-photo-colour & 4.15 (1.27) & 3.35 (1.09) & 3.05 (1.23) & 4.45 (0.86)\\
\hspace{1em}guitar1-photo-grey & 4.35 (0.99) & 3.3 (1.02) & 2 (1.1) & 3.9 (0.7)\\
\hspace{1em}guitar2-photo-colour & 4.45 (0.89) & 2.86 (1.2) & 2.1 (1) & 4.3 (1.03)\\
\hspace{1em}guitar2-photo-grey & 4.25 (1.12) & 3.5 (1.1) &  & 3.85 (1.09)\\
\hspace{1em}guitar3-photo-colour & 3.67 (1.46) & 2.86 (1.04) & 3.32 (1.25) & 3.95 (1.16)\\
\hspace{1em}guitar3-photo-grey & 4.3 (0.93) & 3.05 (0.72) &  & 4.17 (1.05)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{hammer}}\\
\hspace{1em}hammer1-photo-colour & 4.5 (0.89) & 2.4 (1.22) & 3.7 (1.22) & 4.62 (0.5)\\
\hspace{1em}hammer1-photo-grey & 4.5 (0.76) & 2.1 (1.02) &  & 3.5 (1.19)\\
\hspace{1em}hammer2-photo-colour & 4.75 (0.55) & 2.95 (1.05) & 3.23 (1.19) & 4.4 (0.88)\\
\hspace{1em}hammer2-photo-grey & 4.55 (0.83) & 2.43 (1.12) &  & 4.55 (1)\\
\hspace{1em}hammer3-photo-colour & 4.32 (0.95) & 2.77 (0.97) & 2.68 (1.52) & 4.25 (1.03)\\
\hspace{1em}hammer3-photo-grey & 4.29 (1.01) & 2.36 (0.85) &  & 3.71 (1.19)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{hand}}\\
\hspace{1em}hand1-photo-colour & 4.9 (0.4) & 3.33 (0.91) & 3.14 (1.56) & 4.6 (0.75)\\
\hspace{1em}hand1-photo-grey & 5 (0) & 3.14 (1.28) &  & 4.2 (0.89)\\
\hspace{1em}hand2-photo-colour & 4.73 (0.88) & 3.4 (1.23) & 3.15 (1.39) & 4.62 (0.67)\\
\hspace{1em}hand2-photo-grey & 5 (0) & 3.05 (1.32) &  & 3.9 (0.91)\\
\hspace{1em}hand3-photo-colour & 4.86 (0.64) & 3.62 (1.44) & 2.92 (1.28) & 2.73 (1.24)\\
\hspace{1em}hand3-photo-grey & 4.86 (0.47) & 3.24 (1.04) &  & 3.43 (1.25)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{harp}}\\
\hspace{1em}harp1-photo-colour & 3.25 (1.77) & 3.7 (1.02) & 3.55 (1.32) & 3.81 (0.75)\\
\hspace{1em}harp1-photo-grey & 2.75 (1.48) & 3.15 (1.31) &  & 3.68 (1.09)\\
\hspace{1em}harp2-photo-colour & 3.15 (1.57) & 4.09 (1.06) & 2.91 (1.27) & 4.15 (0.88)\\
\hspace{1em}harp2-photo-grey & 3.4 (1.14) & 3.14 (1.06) &  & 4.25 (0.85)\\
\hspace{1em}harp3-photo-colour & 2.64 (1.47) & 3.41 (0.96) & 2.91 (1.31) & 4.46 (0.78)\\
\hspace{1em}harp3-photo-grey & 3 (1.58) & 3.09 (0.92) &  & 3.76 (1.22)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{horse}}\\
\hspace{1em}horse1-photo-colour & 4.27 (0.94) & 3.45 (1.23) & 2.45 (1.15) & 4.3 (0.86)\\
\hspace{1em}horse1-photo-grey & 4.48 (0.93) & 3.35 (0.99) &  & 3.73 (0.94)\\
\hspace{1em}horse2-photo-colour & 4.4 (0.88) & 3.75 (0.97) & 3.55 (1) & 3.86 (1.06)\\
\hspace{1em}horse2-photo-grey & 3.9 (1.17) & 3.55 (1.32) &  & 3.68 (1.17)\\
\hspace{1em}horse3-photo-colour & 4.14 (1.06) & 3.62 (1.2) & 3.19 (1.33) & 4.14 (1.13)\\
\hspace{1em}horse3-photo-grey & 3.96 (1.37) & 3.23 (1.19) &  & 3.73 (0.98)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{house}}\\
\hspace{1em}house1-photo-colour & 4.57 (0.98) & 2.95 (1.05) & 2.15 (1.23) & 2.57 (1.17)\\
\hspace{1em}house1-photo-grey & 4.5 (1.06) & 2.45 (0.89) &  & 2.8 (1.4)\\
\hspace{1em}house2-photo-colour & 4.75 (0.44) & 3.55 (1.19) & 2.6 (1.6) & 2.86 (0.83)\\
\hspace{1em}house2-photo-grey & 4.75 (0.55) & 3.35 (0.93) &  & 2.33 (1.11)\\
\hspace{1em}house3-photo-colour & 4.67 (0.87) & 4.09 (1.2) & 3.04 (1.52) & 2.64 (1.26)\\
\hspace{1em}house3-photo-grey & 4.29 (1.01) & 3.95 (1.32) &  & 2 (0.93)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{iron}}\\
\hspace{1em}iron1-photo-colour & 4.37 (1.07) & 3.71 (1.06) & 2.9 (1.45) & 3.95 (1.39)\\
\hspace{1em}iron1-photo-grey & 4.9 (0.45) & 2.95 (1.25) &  & 4.3 (0.98)\\
\hspace{1em}iron2-photo-colour & 4.59 (0.73) & 3.45 (1.28) & 2.65 (1.57) & 3.9 (1.45)\\
\hspace{1em}iron2-photo-grey & 4.33 (1.32) & 3.75 (1.37) &  & 4.2 (0.83)\\
\hspace{1em}iron3-photo-colour & 4.14 (0.99) & 2.72 (1.17) & 2.48 (1.42) & 2.73 (1.39)\\
\hspace{1em}iron3-photo-grey & 4.27 (1.12) & 1.95 (1.05) &  & 3.9 (0.83)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{jacket}}\\
\hspace{1em}jacket1-photo-colour & 4.5 (0.89) & 3.15 (1.14) & 2.95 (1.36) & 2.41 (1.14)\\
\hspace{1em}jacket1-photo-grey & 4.8 (0.41) & 3.33 (1.06) & 2.27 (1.56) & 2.52 (1.12)\\
\hspace{1em}jacket2-photo-colour & 4.55 (0.51) & 2.76 (0.89) & 2.71 (1.27) & 3 (1.21)\\
\hspace{1em}jacket2-photo-grey & 4.7 (0.47) & 3.14 (0.94) &  & 3.1 (1.17)\\
\hspace{1em}jacket3-photo-colour & 4.43 (0.75) & 2.55 (0.91) & 1.73 (0.94) & 2.71 (1.19)\\
\hspace{1em}jacket3-photo-grey & 4.32 (0.84) & 2.91 (0.9) &  & 3.29 (1.16)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{kettle}}\\
\hspace{1em}kettle1-photo-colour & 4.37 (1.22) & 3.05 (0.8) & 2.81 (1.54) & 3.3 (1.03)\\
\hspace{1em}kettle1-photo-grey & 4.75 (0.64) & 2.68 (1.25) &  & 2.7 (1.17)\\
\hspace{1em}kettle2-photo-colour & 4.5 (0.8) & 2.85 (1.23) & 2.6 (1.05) & 3.1 (1.41)\\
\hspace{1em}kettle2-photo-grey & 4.29 (1.06) & 2.75 (1.29) &  & 2.6 (1.23)\\
\hspace{1em}kettle3-photo-colour & 4.09 (1.19) & 2.64 (1.11) & 2.2 (1.08) & 2.14 (1.13)\\
\hspace{1em}kettle3-photo-grey & 4.5 (0.67) & 2.32 (1.04) &  & 2.05 (0.97)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{kite}}\\
\hspace{1em}kite1-photo-colour & 4.25 (1.16) & 3.1 (1.06) & 2.45 (1.67) & 4.05 (0.74)\\
\hspace{1em}kite1-photo-grey & 4.2 (1.06) & 2.4 (1.23) &  & 3.32 (1.13)\\
\hspace{1em}kite2-photo-colour & 4.2 (1.11) & 3.05 (1.17) & 2 (1.38) & 3.85 (0.99)\\
\hspace{1em}kite2-photo-grey & 3.6 (1.05) & 2.33 (1.06) &  & 3.45 (1.15)\\
\hspace{1em}kite3-photo-colour & 3.23 (1.45) & 3.48 (0.73) & 2.09 (1.5) & 3.08 (1.35)\\
\hspace{1em}kite3-photo-grey & 3.29 (1.35) & 3.14 (0.77) &  & 2.14 (1.01)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{knife}}\\
\hspace{1em}knife1-photo-colour & 4.57 (0.86) & 2.67 (0.91) & 3.43 (0.93) & 3.5 (1.15)\\
\hspace{1em}knife1-photo-grey & 4.95 (0.22) & 2.32 (1.09) &  & 3.6 (0.99)\\
\hspace{1em}knife2-photo-colour & 4.91 (0.29) & 2.6 (0.82) & 3.15 (1.18) & 3.67 (1.2)\\
\hspace{1em}knife2-photo-grey & 4.67 (0.91) & 2.2 (0.77) &  & 3.7 (1.3)\\
\hspace{1em}knife3-photo-colour & 4.23 (1.23) & 3.21 (1.02) & 3.08 (1.35) & 2.14 (0.99)\\
\hspace{1em}knife3-photo-grey & 4.27 (0.94) & 2.81 (1.03) &  & 2.62 (0.92)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{ladder}}\\
\hspace{1em}ladder1-photo-colour & 4.75 (0.55) & 2 (1.07) & 2.95 (1.4) & 3.1 (1.37)\\
\hspace{1em}ladder1-photo-grey & 4.3 (1.06) & 1.62 (0.67) &  & 3.95 (1.05)\\
\hspace{1em}ladder2-photo-colour & 4.52 (0.98) & 1.95 (1.28) & 1.8 (1.01) & 4.1 (0.97)\\
\hspace{1em}ladder2-photo-grey & 4.5 (0.74) & 1.6 (0.94) &  & 4.24 (1.09)\\
\hspace{1em}ladder3-photo-colour & 4.5 (0.96) & 2.41 (1.22) & 2.91 (1.41) & 3.19 (1.29)\\
\hspace{1em}ladder3-photo-grey & 4.27 (0.98) & 1.71 (0.95) &  & 3.5 (1.06)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{lamp}}\\
\hspace{1em}lamp1-photo-colour & 4.5 (0.86) & 2.76 (0.77) & 2.9 (1.14) & 3.55 (1.28)\\
\hspace{1em}lamp1-photo-grey & 4.85 (0.49) & 2.41 (0.85) &  & 3.2 (1.2)\\
\hspace{1em}lamp2-photo-colour & 4.64 (0.9) & 3.35 (0.67) & 2.55 (1.28) & 4.05 (1.02)\\
\hspace{1em}lamp2-photo-grey & 4.71 (0.56) & 2.95 (1) &  & 3.6 (1.05)\\
\hspace{1em}lamp3-photo-colour & 4.45 (1.06) & 3.92 (1.1) & 2.62 (1.24) & 2.91 (1.15)\\
\hspace{1em}lamp3-photo-grey & 4.77 (0.53) & 3.32 (0.95) &  & 2.81 (1.03)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{leaf}}\\
\hspace{1em}leaf1-photo-colour & 4.8 (0.52) & 3.55 (1.1) & 3.14 (1.28) & 3.35 (1.35)\\
\hspace{1em}leaf1-photo-grey & 4.63 (0.89) & 3.43 (1.21) &  & 3.4 (1.19)\\
\hspace{1em}leaf2-photo-colour & 4.76 (0.54) & 2.85 (1.31) & 3.05 (1.15) & 4.1 (1.07)\\
\hspace{1em}leaf2-photo-grey & 4.86 (0.64) & 2.9 (1.02) &  & 3.48 (1.33)\\
\hspace{1em}leaf3-photo-colour & 4.68 (0.57) & 3.1 (1.26) & 2.9 (0.94) & 3.38 (1.32)\\
\hspace{1em}leaf3-photo-grey & 4.55 (0.96) & 2.62 (1.24) &  & 2.77 (1.27)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{lemon}}\\
\hspace{1em}lemon1-photo-colour & 4.76 (0.7) & 3.05 (1.32) & 4.5 (0.76) & 3.8 (1.19)\\
\hspace{1em}lemon1-photo-grey & 4.27 (0.98) & 2.45 (0.94) &  & 3.35 (1.35)\\
\hspace{1em}lemon2-photo-colour & 4.65 (0.59) & 3.05 (1.43) & 4.7 (0.57) & 4.91 (0.29)\\
\hspace{1em}lemon2-photo-grey & 4.5 (0.69) & 2.95 (1.23) &  & 3.76 (1.14)\\
\hspace{1em}lemon3-photo-colour & 4.75 (0.61) & 2.26 (1.48) & 4.26 (1.18) & 5 (0)\\
\hspace{1em}lemon3-photo-grey & 3.81 (1.17) & 2.62 (1.02) &  & 3.45 (1.34)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{lion}}\\
\hspace{1em}lion1-photo-colour & 4.1 (1.21) & 3.64 (1.05) & 4.32 (0.99) & 4.7 (0.57)\\
\hspace{1em}lion1-photo-grey & 4.2 (1) & 3.33 (1.24) &  & 4.35 (0.81)\\
\hspace{1em}lion2-photo-colour & 4.1 (1.37) & 3.75 (0.91) & 4.65 (0.67) & 4.65 (0.93)\\
\hspace{1em}lion2-photo-grey & 4.05 (1.21) & 3.4 (1.1) &  & 4.29 (0.78)\\
\hspace{1em}lion3-photo-colour & 3.95 (1.29) & 3.95 (1.09) & 4.32 (1.09) & 4.67 (0.48)\\
\hspace{1em}lion3-photo-grey & 3.41 (1.37) & 3.75 (1.39) &  & 3.41 (1.18)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{lips}}\\
\hspace{1em}lips1-photo-colour & 4.8 (0.62) & 3.23 (1.07) & 3.09 (0.97) & 3.8 (0.95)\\
\hspace{1em}lips1-photo-grey & 4.87 (0.51) & 3.29 (1.01) &  & 3.8 (0.95)\\
\hspace{1em}lips2-photo-colour & 4.86 (0.65) & 2.15 (0.81) & 3.25 (1.29) & 4.55 (0.6)\\
\hspace{1em}lips2-photo-grey & 4.82 (0.85) & 2.15 (0.99) &  & 4.14 (1.28)\\
\hspace{1em}lips3-photo-colour & 4.82 (0.66) & 2.41 (1.05) & 3.27 (1.49) & 4.05 (0.92)\\
\hspace{1em}lips3-photo-grey & 4.77 (0.53) & 1.96 (1.21) &  & 3.32 (1.25)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{lobster}}\\
\hspace{1em}lobster1-photo-colour & 3.45 (1.5) & 4.17 (1.15) & 4.15 (0.99) & 4.43 (0.68)\\
\hspace{1em}lobster1-photo-grey & 3.5 (1.5) & 3.65 (1.27) &  & 3.36 (1.09)\\
\hspace{1em}lobster2-photo-colour & 4.24 (1.14) & 4.05 (1) & 4.18 (1.05) & 4.15 (0.81)\\
\hspace{1em}lobster2-photo-grey & 3.75 (1.33) & 3 (1.3) &  & 3.35 (1.23)\\
\hspace{1em}lobster3-photo-colour & 2.95 (1.53) & 3.5 (0.91) & 4.27 (0.83) & 4.44 (0.71)\\
\hspace{1em}lobster3-photo-grey & 2.95 (1.4) & 3.18 (0.91) &  & 3.29 (1.31)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{lock}}\\
\hspace{1em}lock1-photo-colour & 4.3 (0.99) & 3.81 (1.21) & 4.05 (0.92) & 4.15 (1.18)\\
\hspace{1em}lock1-photo-grey & 4.5 (0.69) & 3.32 (1.25) &  & 3.45 (1.39)\\
\hspace{1em}lock2-photo-colour & 4.27 (1.08) & 3.4 (1.19) & 2.7 (1.03) & 3.48 (1.4)\\
\hspace{1em}lock2-photo-grey & 4.29 (1.1) & 2.6 (1.35) &  & 4.1 (0.97)\\
\hspace{1em}lock3-photo-colour & 4.04 (1.02) & 3.54 (1.22) & 3.75 (1.26) & 3.82 (1.14)\\
\hspace{1em}lock3-photo-grey & 4.36 (0.85) & 2.86 (0.94) &  & 3.57 (1.25)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{mitten}}\\
\hspace{1em}mitten1-photo-colour & 4.05 (1.25) & 3.95 (0.94) & 1.85 (1.14) & 3.35 (1.18)\\
\hspace{1em}mitten1-photo-grey & 4.48 (0.68) & 3.2 (1.11) &  & 3.67 (1.06)\\
\hspace{1em}mitten2-photo-colour & 4.1 (1.17) & 3.35 (0.88) & 2 (1.59) & 3.38 (1.32)\\
\hspace{1em}mitten2-photo-grey & 3.75 (1.21) & 2.3 (1.26) &  & 3.82 (1.05)\\
\hspace{1em}mitten3-photo-colour & 4.14 (0.96) & 2.43 (1.33) & 1.86 (1.49) & 3.68 (1.36)\\
\hspace{1em}mitten3-photo-grey & 4.33 (0.87) & 1.91 (1.06) &  & 3.77 (0.97)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{monkey}}\\
\hspace{1em}monkey1-photo-colour & 3.62 (1.24) & 3.95 (1.32) & 3.85 (1.14) & 3.47 (1.2)\\
\hspace{1em}monkey1-photo-grey & 3.09 (1.6) & 3.9 (0.97) &  & 3.1 (1.25)\\
\hspace{1em}monkey2-photo-colour & 3.1 (1.25) & 4.15 (1.14) & 4.15 (1.14) & 3.59 (1.01)\\
\hspace{1em}monkey2-photo-grey & 3.65 (1.42) & 3.85 (0.99) &  & 3.1 (1.18)\\
\hspace{1em}monkey3-photo-colour & 3.79 (1.41) & 3.36 (1.22) & 3.59 (1.01) & 3.55 (0.96)\\
\hspace{1em}monkey3-photo-grey & 3.62 (1.24) & 3.29 (1.15) &  & 3.23 (1.23)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{moon}}\\
\hspace{1em}moon1-photo-colour & 4.6 (0.68) & 2.6 (1) & 2.8 (1.15) & 2.71 (1.27)\\
\hspace{1em}moon1-photo-grey & 4.05 (1.47) & 2.25 (1.02) &  & 2.95 (1.4)\\
\hspace{1em}moon2-photo-colour & 4.1 (1.17) & 2.45 (1.14) & 3.36 (1.05) & 2.55 (1.28)\\
\hspace{1em}moon2-photo-grey & 3.55 (1.39) & 1.9 (0.94) &  & 2.6 (1.27)\\
\hspace{1em}moon3-photo-colour & 4.26 (1.01) & 2.73 (1.28) & 3.32 (0.99) & 2.46 (1.25)\\
\hspace{1em}moon3-photo-grey & 4.14 (1.11) & 2.09 (0.97) &  & 2.24 (1.37)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{mouse}}\\
\hspace{1em}mouse1-photo-colour & 3.68 (1.25) & 3.75 (0.91) & 3.6 (1.19) & 3.75 (1.29)\\
\hspace{1em}mouse1-photo-grey & 4.43 (0.87) & 3.35 (1.09) &  & 3.5 (1.17)\\
\hspace{1em}mouse2-photo-colour & 4.15 (0.99) & 3.9 (0.91) & 3.7 (1.03) & 3.76 (1.45)\\
\hspace{1em}mouse2-photo-grey & 3.8 (1.24) & 3.1 (1.37) &  & 3.95 (1.05)\\
\hspace{1em}mouse3-photo-colour & 3.76 (1.04) & 3.9 (1.26) & 3.33 (1.24) & 3.41 (1.18)\\
\hspace{1em}mouse3-photo-grey & 3.71 (1.43) & 3.13 (1.18) &  & 3 (1.38)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{nail}}\\
\hspace{1em}nail1-photo-colour & 4.17 (1.21) & 2.14 (1.31) & 3.57 (1.43) & 3.7 (1.75)\\
\hspace{1em}nail1-photo-grey & 4.5 (0.95) & 2.18 (1.14) &  & 3.4 (1.7)\\
\hspace{1em}nail2-photo-colour & 4.32 (0.95) & 2.05 (1.05) & 2.7 (1.22) & 3.33 (1.77)\\
\hspace{1em}nail2-photo-grey & 4.67 (0.58) & 1.5 (0.76) &  & 3.85 (1.27)\\
\hspace{1em}nail3-photo-colour & 4.18 (1.14) & 2.12 (1.17) & 3.88 (1.51) & 3.77 (1.69)\\
\hspace{1em}nail3-photo-grey & 4.41 (1.05) & 1.77 (1.07) &  & 4.14 (1.39)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{needle}}\\
\hspace{1em}needle1-photo-colour & 3.87 (1.22) & 2.48 (1.4) & 3.48 (1.08) & 4.6 (0.82)\\
\hspace{1em}needle1-photo-grey & 4.45 (1.05) & 2.27 (1.24) &  & 4.4 (0.99)\\
\hspace{1em}needle2-photo-colour & 4.09 (1.38) & 1.9 (0.85) & 2.4 (1.23) & 4 (1.34)\\
\hspace{1em}needle2-photo-grey & 4.38 (0.97) & 1.7 (1.03) &  & 3.95 (1.15)\\
\hspace{1em}needle3-photo-colour & 3.64 (1.18) & 1.92 (1.32) & 3.76 (1.54) & 4.05 (1.05)\\
\hspace{1em}needle3-photo-grey & 3.82 (1.22) & 1.95 (0.74) &  & 3.81 (1.29)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{nose}}\\
\hspace{1em}nose1-photo-colour & 5 (0) & 2.83 (1.42) & 3.15 (1.76) & 4 (0.84)\\
\hspace{1em}nose1-photo-grey & 5 (0) & 2.55 (1.19) &  & 3.82 (1.26)\\
\hspace{1em}nose2-photo-colour & 4.95 (0.22) & 3.23 (1.11) & 2.68 (1.52) & 3.85 (1.09)\\
\hspace{1em}nose2-photo-grey & 4.7 (0.66) & 2.38 (1.02) &  & 3.6 (0.99)\\
\hspace{1em}nose3-photo-colour & 4.86 (0.47) & 3.17 (0.94) & 3.13 (1.36) & 4.21 (0.98)\\
\hspace{1em}nose3-photo-grey & 4.76 (0.7) & 2.55 (1.26) &  & 3.29 (1.19)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{onion}}\\
\hspace{1em}onion1-photo-colour & 4.9 (0.31) & 2.83 (1.29) & 3.9 (1.33) & 4.67 (0.73)\\
\hspace{1em}onion1-photo-grey & 4.8 (0.52) & 2.55 (1.15) &  & 3.36 (1.22)\\
\hspace{1em}onion2-photo-colour & 4.8 (0.7) & 3.45 (1.37) & 3.82 (0.96) & 4.25 (1.07)\\
\hspace{1em}onion2-photo-grey & 4.5 (0.69) & 2.95 (1.2) &  & 3.65 (0.93)\\
\hspace{1em}onion3-photo-colour & 4.48 (0.79) & 2.59 (1.22) & 3.86 (1.08) & 4.75 (0.68)\\
\hspace{1em}onion3-photo-grey & 4.38 (0.92) & 2.23 (0.97) &  & 3.24 (1.18)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{orange}}\\
\hspace{1em}orange1-photo-colour & 4.68 (0.65) & 2.3 (1.45) & 4.7 (0.73) & 4.75 (0.55)\\
\hspace{1em}orange1-photo-grey & 4.48 (0.87) & 2.35 (1.04) &  & 2.83 (1.29)\\
\hspace{1em}orange2-photo-colour & 4.9 (0.31) & 3.25 (1.37) & 4.85 (0.37) & 4.81 (0.68)\\
\hspace{1em}orange2-photo-grey & 4.25 (0.91) & 1.9 (1.37) &  & 3.68 (1.04)\\
\hspace{1em}orange3-photo-colour & 4.86 (0.36) & 3.57 (1.33) & 4.67 (0.58) & 4.45 (1.06)\\
\hspace{1em}orange3-photo-grey & 4.17 (1.2) & 2.26 (1.14) &  & 3.23 (1.07)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{ostrich}}\\
\hspace{1em}ostrich1-photo-colour & 3.47 (1.38) & 3.81 (0.68) & 4.19 (1.12) & 4.7 (0.47)\\
\hspace{1em}ostrich1-photo-grey & 3.4 (1.57) & 3.18 (1.01) &  & 4.3 (0.73)\\
\hspace{1em}ostrich2-photo-colour & 3.27 (1.35) & 3.85 (0.99) & 3.55 (0.89) & 4.52 (0.68)\\
\hspace{1em}ostrich2-photo-grey & 3.24 (1.41) & 3.5 (1.43) &  & 3.9 (1.07)\\
\hspace{1em}ostrich3-photo-colour & 3.18 (1.59) & 3.8 (1) & 4.12 (1.01) & 3.77 (1.15)\\
\hspace{1em}ostrich3-photo-grey & 2.95 (1.7) & 3.36 (1.26) &  & 3.43 (1.25)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{peach}}\\
\hspace{1em}peach1-photo-colour & 4.45 (1) & 3.14 (1.13) & 3.91 (1.02) & 3.95 (1.1)\\
\hspace{1em}peach1-photo-grey & 4.23 (1.1) & 2.95 (1.2) &  & 2.95 (1.39)\\
\hspace{1em}peach2-photo-colour & 4.19 (1.29) & 3.2 (1.28) & 4.2 (1.01) & 4.45 (0.76)\\
\hspace{1em}peach2-photo-grey & 4.18 (1.05) & 2.2 (0.95) &  & 2.9 (1.41)\\
\hspace{1em}peach3-photo-colour & 4.14 (1.08) & 2.29 (0.96) & 3.95 (1.16) & 4 (1.05)\\
\hspace{1em}peach3-photo-grey & 3.68 (1.52) & 1.83 (1.01) &  & 1.73 (0.98)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{peacock}}\\
\hspace{1em}peacock1-photo-colour & 3.87 (1.36) & 4.43 (0.68) & 4.76 (0.44) & 4.4 (0.68)\\
\hspace{1em}peacock1-photo-grey & 3.7 (1.56) & 3.59 (1.3) &  & 3.1 (1.12)\\
\hspace{1em}peacock2-photo-colour & 3.73 (1.49) & 4.55 (0.83) & 4.2 (1.06) & 4 (1.1)\\
\hspace{1em}peacock2-photo-grey & 3.52 (1.47) & 3.85 (1.31) &  & 2.55 (1.05)\\
\hspace{1em}peacock3-photo-colour & 3.45 (1.41) & 4.44 (0.65) & 4.56 (0.92) & 4.05 (0.95)\\
\hspace{1em}peacock3-photo-grey & 3.5 (1.47) & 3.82 (1.33) &  & 3.24 (1.14)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{peanut}}\\
\hspace{1em}peanut1-photo-colour & 4.38 (0.86) & 3.2 (1.2) & 4.1 (1.02) & 3.97 (1.38)\\
\hspace{1em}peanut1-photo-grey & 3.91 (1.11) & 2.75 (1.12) &  & 3.35 (1.31)\\
\hspace{1em}peanut2-photo-colour & 4 (0.97) & 3.45 (1.15) & 4.4 (0.75) & 3.95 (1.46)\\
\hspace{1em}peanut2-photo-grey & 4.2 (0.89) & 3.45 (0.94) &  & 3.86 (1.28)\\
\hspace{1em}peanut3-photo-colour & 4.25 (1.03) & 2.83 (1.19) & 4.13 (1.1) & 4.05 (1.17)\\
\hspace{1em}peanut3-photo-grey & 4.05 (1.12) & 3.05 (0.86) &  & 4.14 (1.04)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{pear}}\\
\hspace{1em}pear1-photo-colour & 4.57 (0.86) & 3.14 (1.24) & 4.48 (0.6) & 5 (0)\\
\hspace{1em}pear1-photo-grey & 4.8 (0.41) & 2.59 (1.22) &  & 3.55 (1.23)\\
\hspace{1em}pear2-photo-colour & 4.68 (0.78) & 2.8 (1.2) & 3.6 (1.1) & 4.33 (0.73)\\
\hspace{1em}pear2-photo-grey & 4.33 (1.06) & 2.45 (1.05) &  & 3.55 (1.05)\\
\hspace{1em}pear3-photo-colour & 4.32 (0.99) & 3.08 (1.19) & 4.12 (1.13) & 4.09 (0.92)\\
\hspace{1em}pear3-photo-grey & 4.41 (1.05) & 2.32 (1.13) &  & 3.14 (0.96)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{pencil}}\\
\hspace{1em}pencil1-photo-colour & 4.95 (0.22) & 2.25 (1.55) & 2.15 (1.6) & 3.77 (1.19)\\
\hspace{1em}pencil1-photo-grey & 4.5 (0.91) & 1.75 (1.02) &  & 3.85 (1.04)\\
\hspace{1em}pencil2-photo-colour & 4.8 (0.7) & 2.8 (1.54) & 2.3 (1.49) & 3.86 (1.13)\\
\hspace{1em}pencil2-photo-grey & 4.9 (0.31) & 2.6 (1.23) &  & 3.71 (1.01)\\
\hspace{1em}pencil3-photo-colour & 4.83 (0.48) & 1.86 (1.04) & 2.41 (1.14) & 3.77 (0.97)\\
\hspace{1em}pencil3-photo-grey & 4.52 (0.75) & 1.86 (0.96) &  & 2.64 (1.22)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{penguin}}\\
\hspace{1em}penguin1-photo-colour & 4 (1.45) & 3.4 (1.33) & 4.5 (0.95) & 4.62 (0.59)\\
\hspace{1em}penguin1-photo-grey & 3.5 (1.4) & 2.65 (1.18) &  & 3.91 (0.87)\\
\hspace{1em}penguin2-photo-colour & 3.85 (1.57) & 3.82 (1.26) & 4.55 (0.6) & 4.65 (0.59)\\
\hspace{1em}penguin2-photo-grey & 4.05 (1.15) & 2.9 (1.26) &  & 4.5 (0.69)\\
\hspace{1em}penguin3-photo-colour & 3.59 (1.53) & 3.45 (0.91) & 4.18 (0.91) & 4.5 (0.78)\\
\hspace{1em}penguin3-photo-grey & 3.52 (1.44) & 2.77 (0.75) &  & 3.71 (1.1)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{pepper}}\\
\hspace{1em}pepper1-photo-colour & 4.73 (0.46) & 2.2 (1.36) & 2.95 (1.1) & 3.1 (1.48)\\
\hspace{1em}pepper1-photo-grey & 4.71 (0.64) & 2.4 (1.1) &  & 2.77 (1.3)\\
\hspace{1em}pepper2-photo-colour & 4.65 (0.67) & 3.1 (1.29) & 3.5 (1.36) & 2.52 (1.66)\\
\hspace{1em}pepper2-photo-grey & 4.55 (0.6) & 2.15 (1.39) &  & 3.05 (1.33)\\
\hspace{1em}pepper3-photo-colour & 4.38 (0.67) & 3.33 (1.32) & 3 (1.18) & 2.82 (1.22)\\
\hspace{1em}pepper3-photo-grey & 4.29 (1) & 2.35 (0.78) &  & 2.95 (1.46)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{piano}}\\
\hspace{1em}piano1-photo-colour & 4.48 (0.75) & 3.9 (1.25) & 3.55 (1.19) & 3.87 (1.11)\\
\hspace{1em}piano1-photo-grey & 3.95 (1.13) & 3.95 (1.15) &  & 4.2 (0.95)\\
\hspace{1em}piano2-photo-colour & 4.15 (0.81) & 4.15 (1.09) & 3.6 (1.27) & 4.45 (0.74)\\
\hspace{1em}piano2-photo-grey & 4.15 (1.23) & 3.4 (0.94) &  & 4.14 (1.15)\\
\hspace{1em}piano3-photo-colour & 4.29 (1.04) & 3.77 (0.97) & 3.5 (1.1) & 3.86 (0.89)\\
\hspace{1em}piano3-photo-grey & 4.14 (1.01) & 3.71 (1.15) &  & 3.95 (0.9)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{pipe}}\\
\hspace{1em}pipe1-photo-colour & 3.43 (1.25) & 4.1 (1.33) & 3.2 (1.11) & 2.8 (1.71)\\
\hspace{1em}pipe1-photo-grey & 2.82 (1.5) & 4.35 (0.88) &  & 2.8 (1.47)\\
\hspace{1em}pipe2-photo-colour & 3 (1.38) & 2.75 (1.62) & 3.55 (1.23) & 2.77 (1.6)\\
\hspace{1em}pipe2-photo-grey & 3.65 (1.23) & 2.6 (1.1) &  & 2.86 (1.53)\\
\hspace{1em}pipe3-photo-colour & 3 (1.53) & 2.26 (1.01) & 3.17 (1.3) & 2.86 (1.49)\\
\hspace{1em}pipe3-photo-grey & 3.29 (1.52) & 2.38 (1.12) &  & 2.68 (1.7)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{pitcher}}\\
\hspace{1em}pitcher1-photo-colour & 4.25 (1.07) & 3.3 (1.26) & 3.45 (1.36) & 3.18 (1.4)\\
\hspace{1em}pitcher1-photo-grey & 4.5 (0.76) & 2.5 (0.9) & 2.27 (1.1) & 2.9 (1.18)\\
\hspace{1em}pitcher2-photo-colour & 4.45 (0.6) & 2.81 (1.17) & 1.57 (1.12) & 2.3 (0.98)\\
\hspace{1em}pitcher2-photo-grey & 3.85 (1.14) & 2.64 (1) &  & 3.1 (1.25)\\
\hspace{1em}pitcher3-photo-colour & 3.67 (1.2) & 2.18 (1.14) & 1.55 (0.96) & 2.29 (1.01)\\
\hspace{1em}pitcher3-photo-grey & 3.39 (1.08) & 2.09 (0.81) &  & 2.67 (1.27)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{pliers}}\\
\hspace{1em}pliers1-photo-colour & 4.09 (1.31) & 3 (1.08) & 2.4 (1.05) & 3.9 (0.97)\\
\hspace{1em}pliers1-photo-grey & 3.95 (1.16) & 3.05 (1.05) &  & 3.4 (1.16)\\
\hspace{1em}pliers2-photo-colour & 4.25 (0.79) & 2.75 (1.33) & 2.9 (1.37) & 4.19 (0.98)\\
\hspace{1em}pliers2-photo-grey & 3.6 (1.31) & 2.45 (1.23) &  & 3.73 (1.2)\\
\hspace{1em}pliers3-photo-colour & 4.05 (1.16) & 2.67 (1.06) & 2.33 (1.32) & 3.82 (1.05)\\
\hspace{1em}pliers3-photo-grey & 3.58 (1.18) & 2.09 (0.97) &  & 3.82 (1.1)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{plug}}\\
\hspace{1em}plug1-photo-colour & 4.05 (1.36) & 2.65 (1.14) & 3 (1.17) & 2.09 (1.27)\\
\hspace{1em}plug1-photo-grey & 4.45 (0.83) & 2.7 (1.15) & 3.18 (1.4) & 2.33 (1.39)\\
\hspace{1em}plug2-photo-colour & 4.1 (1.29) & 2.19 (0.93) & 2.86 (1.31) & 2 (1.49)\\
\hspace{1em}plug2-photo-grey & 4.5 (1.15) & 3.18 (1.1) &  & 2.35 (1.5)\\
\hspace{1em}plug3-photo-colour & 3.81 (1.4) & 2.5 (0.86) & 3.5 (1.19) & 2.24 (1.3)\\
\hspace{1em}plug3-photo-grey & 3 (1.45) & 2.73 (1.12) &  & 2.48 (1.42)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{potato}}\\
\hspace{1em}potato1-photo-colour & 4.67 (1.03) & 2.71 (1.45) & 4 (1.26) & 5 (0)\\
\hspace{1em}potato1-photo-grey & 4.85 (0.37) & 2.45 (1.1) &  & 4 (1.12)\\
\hspace{1em}potato2-photo-colour & 4.82 (0.5) & 2.75 (1.12) & 3.7 (1.3) & 4.52 (0.81)\\
\hspace{1em}potato2-photo-grey & 4.38 (1.24) & 2.45 (1.15) &  & 3.5 (1.24)\\
\hspace{1em}potato3-photo-colour & 5 (0) & 2.6 (1.55) & 4.08 (1.08) & 4.55 (0.67)\\
\hspace{1em}potato3-photo-grey & 4.82 (0.5) & 2.48 (1.08) &  & 3.76 (1)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{pumpkin}}\\
\hspace{1em}pumpkin1-photo-colour & 4.23 (1.23) & 3 (1.17) & 4.2 (1.28) & 4.6 (0.75)\\
\hspace{1em}pumpkin1-photo-grey & 4.1 (1.04) & 2.55 (1) &  & 3.2 (1.27)\\
\hspace{1em}pumpkin2-photo-colour & 4 (1.08) & 2.95 (1.23) & 4.45 (0.83) & 4.14 (1.2)\\
\hspace{1em}pumpkin2-photo-grey & 3.5 (1.19) & 2.25 (1.02) &  & 3.18 (1.05)\\
\hspace{1em}pumpkin3-photo-colour & 4.05 (0.97) & 3.24 (1.37) & 4.52 (0.98) & 4.55 (0.74)\\
\hspace{1em}pumpkin3-photo-grey & 3.79 (1.25) & 2.35 (1.15) &  & 3.55 (1.06)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{rabbit}}\\
\hspace{1em}rabbit1-photo-colour & 4.35 (1.18) & 3.45 (1.37) & 3.64 (0.95) & 3.9 (0.85)\\
\hspace{1em}rabbit1-photo-grey & 4.3 (0.99) & 3.38 (0.97) &  & 4.05 (1.05)\\
\hspace{1em}rabbit2-photo-colour & 4.14 (1.28) & 3.2 (1.06) & 3.6 (1.1) & 3.7 (1.22)\\
\hspace{1em}rabbit2-photo-grey & 4 (1.23) & 3.1 (1.17) &  & 3.43 (1.12)\\
\hspace{1em}rabbit3-photo-colour & 4.23 (0.97) & 3.95 (1.2) & 3.81 (1.25) & 3.9 (1.09)\\
\hspace{1em}rabbit3-photo-grey & 4.09 (1.11) & 3.8 (1.04) &  & 3.77 (0.81)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{raccoon}}\\
\hspace{1em}raccoon1-photo-colour & 3.45 (1.73) & 3.53 (1.14) & 4.15 (0.88) & 4.33 (0.86)\\
\hspace{1em}raccoon1-photo-grey & 3.45 (1.36) & 3.25 (1.33) &  & 4 (1.02)\\
\hspace{1em}raccoon2-photo-colour & 3.6 (1.47) & 4.09 (1.06) & 4.55 (0.67) & 3.95 (1.19)\\
\hspace{1em}raccoon2-photo-grey & 3.65 (1.27) & 3.62 (1.4) &  & 4.3 (0.73)\\
\hspace{1em}raccoon3-photo-colour & 2.83 (1.56) & 3.59 (1.01) & 4.32 (1.04) & 4.46 (0.72)\\
\hspace{1em}raccoon3-photo-grey & 2.86 (1.35) & 3.27 (1.12) &  & 3.62 (1.12)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{ring}}\\
\hspace{1em}ring1-photo-colour & 4.62 (0.67) & 2.35 (0.75) & 2.9 (1.17) & 3.3 (1.29)\\
\hspace{1em}ring1-photo-grey & 4.23 (1.07) & 2.7 (0.98) &  & 3.4 (1.39)\\
\hspace{1em}ring2-photo-colour & 2.55 (1.61) & 3.45 (1.19) & 3.2 (1.36) & 2.09 (0.87)\\
\hspace{1em}ring2-photo-grey & 2.75 (1.71) & 2.85 (1.04) &  & 2 (1.18)\\
\hspace{1em}ring3-photo-colour & 4.08 (1.15) & 1.82 (0.85) & 2.14 (1.13) & 3.27 (1.24)\\
\hspace{1em}ring3-photo-grey & 4 (1.14) & 1.9 (0.94) &  & 2.59 (1.3)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{ruler}}\\
\hspace{1em}ruler1-photo-colour & 4.76 (0.44) & 2 (1.26) & 2.15 (1.39) & 3.33 (1.24)\\
\hspace{1em}ruler1-photo-grey & 4.45 (1.06) & 2.05 (1.05) &  & 3.3 (1.17)\\
\hspace{1em}ruler2-photo-colour & 4.4 (0.82) & 3 (1.59) & 3.2 (1.61) & 3.86 (1.08)\\
\hspace{1em}ruler2-photo-grey & 4.55 (0.69) & 2.65 (1.04) &  & 4.1 (0.89)\\
\hspace{1em}ruler3-photo-colour & 4.4 (1.12) & 2.55 (1.14) & 2.45 (1.14) & 3.27 (1.49)\\
\hspace{1em}ruler3-photo-grey & 4.1 (1.04) & 2.62 (1.02) &  & 3.68 (0.99)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{screw}}\\
\hspace{1em}screw1-photo-colour & 4.8 (0.62) & 3.09 (1.15) & 3.27 (1.39) & 4.6 (0.6)\\
\hspace{1em}screw1-photo-grey & 4.4 (1) & 3.38 (1.16) &  & 4.9 (0.31)\\
\hspace{1em}screw2-photo-colour & 4.67 (0.66) & 3.1 (1.41) & 3.4 (1.43) & 4.45 (0.69)\\
\hspace{1em}screw2-photo-grey & 4.77 (0.53) & 2.6 (1.05) &  & 4.38 (0.92)\\
\hspace{1em}screw3-photo-colour & 4.5 (0.74) & 3.05 (1.13) & 3.23 (1.45) & 4.48 (0.68)\\
\hspace{1em}screw3-photo-grey & 4.09 (1.35) & 2.67 (1.34) &  & 4.41 (0.8)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{seal}}\\
\hspace{1em}seal1-photo-colour & 3.8 (1.44) & 3.23 (1.23) & 3.59 (1.33) & 3.95 (1.1)\\
\hspace{1em}seal1-photo-grey & 3.63 (1.43) & 3.48 (1.08) &  & 3.8 (1.15)\\
\hspace{1em}seal2-photo-colour & 3.76 (1.41) & 2.95 (1.15) & 4.15 (1.04) & 3.95 (1.15)\\
\hspace{1em}seal2-photo-grey & 3.68 (1.36) & 3.25 (1.07) &  & 4.38 (0.97)\\
\hspace{1em}seal3-photo-colour & 3.64 (1.47) & 3.57 (1.16) & 4.1 (1.3) & 3.71 (1.01)\\
\hspace{1em}seal3-photo-grey & 3.32 (1.43) & 2.84 (1.07) &  & 3.27 (1.16)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{sheep}}\\
\hspace{1em}sheep1-photo-colour & 4.3 (1.03) & 3.64 (1.29) & 3.64 (1.14) & 3.95 (1.15)\\
\hspace{1em}sheep1-photo-grey & 4.1 (1.16) & 3.43 (0.87) &  & 4 (0.97)\\
\hspace{1em}sheep2-photo-colour & 4 (1.22) & 3.75 (1.25) & 4.3 (0.66) & 3.85 (1.09)\\
\hspace{1em}sheep2-photo-grey & 4.18 (0.91) & 3.6 (1.1) &  & 4 (0.89)\\
\hspace{1em}sheep3-photo-colour & 3.91 (1.02) & 3.41 (1.26) & 3.95 (1.29) & 3.95 (0.97)\\
\hspace{1em}sheep3-photo-grey & 3.95 (1.05) & 3.32 (1.11) &  & 3.68 (1.21)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{shirt}}\\
\hspace{1em}shirt1-photo-colour & 4.6 (0.75) & 3.35 (1.14) & 2.25 (1.45) & 3.36 (1.22)\\
\hspace{1em}shirt1-photo-grey & 4.75 (0.64) & 3.17 (0.87) & 2.09 (1.22) & 3.71 (1.01)\\
\hspace{1em}shirt2-photo-colour & 4.45 (0.89) & 2.52 (1.29) & 2.33 (1.2) & 3.1 (1.41)\\
\hspace{1em}shirt2-photo-grey & 4.75 (0.55) & 3.27 (1.12) &  & 2.6 (1.39)\\
\hspace{1em}shirt3-photo-colour & 4.57 (0.51) & 3.09 (1.23) & 1.82 (1.18) & 3.38 (1.12)\\
\hspace{1em}shirt3-photo-grey & 4.59 (0.73) & 3.18 (0.66) &  & 3.76 (1.01)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{shoe}}\\
\hspace{1em}shoe1-photo-colour & 4.8 (0.61) & 3.19 (1.08) & 2.67 (1.2) & 4.05 (1.32)\\
\hspace{1em}shoe1-photo-grey & 4.95 (0.22) & 2.64 (0.9) &  & 3.6 (1.14)\\
\hspace{1em}shoe2-photo-colour & 4.77 (0.69) & 3.55 (0.94) & 2.95 (1.1) & 3.52 (1.44)\\
\hspace{1em}shoe2-photo-grey & 4.76 (0.89) & 3.05 (1.36) &  & 3.35 (1.35)\\
\hspace{1em}shoe3-photo-colour & 4.64 (0.73) & 3.67 (1.24) & 2.79 (1.56) & 3.41 (1.59)\\
\hspace{1em}shoe3-photo-grey & 4.91 (0.29) & 2.95 (1.21) &  & 3.86 (0.91)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{skirt}}\\
\hspace{1em}skirt1-photo-colour & 4.15 (1.09) & 3.23 (1.3) & 2.3 (1.63) & 2.81 (1.08)\\
\hspace{1em}skirt1-photo-grey & 3.95 (1.36) & 3.05 (1.23) &  & 2.77 (1.15)\\
\hspace{1em}skirt2-photo-colour & 4.15 (1.18) & 3.23 (1.19) & 1.68 (1.39) & 2.6 (1.27)\\
\hspace{1em}skirt2-photo-grey & 4 (1.08) & 3.05 (1.02) &  & 2.4 (0.94)\\
\hspace{1em}skirt3-photo-colour & 3.59 (1.26) & 2.95 (0.79) & 1.77 (1.02) & 3.25 (1.19)\\
\hspace{1em}skirt3-photo-grey & 4 (0.95) & 2.73 (0.94) &  & 2.67 (1.06)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{skunk}}\\
\hspace{1em}skunk1-photo-colour & 3.19 (1.66) & 3.65 (0.93) & 4.4 (0.99) & 4.17 (1.34)\\
\hspace{1em}skunk1-photo-grey & 3.09 (1.66) & 3.7 (1.08) &  & 4.15 (0.88)\\
\hspace{1em}skunk2-photo-colour & 2.85 (1.53) & 3.65 (1.04) & 4.35 (0.88) & 3.91 (0.87)\\
\hspace{1em}skunk2-photo-grey & 3 (1.45) & 3.35 (1.14) &  & 3.43 (1.25)\\
\hspace{1em}skunk2-photo-grey2 & NaN NA & NaN NA &  & 2 NA\\
\hspace{1em}skunk3-photo-colour & 2.54 (1.35) & 3.45 (1.1) & 3.55 (1.44) & 3.23 (1.15)\\
\hspace{1em}skunk3-photo-grey & 2.76 (1.45) & 3.27 (1.08) &  & 2.82 (1.18)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{snail}}\\
\hspace{1em}snail1-photo-colour & 4.14 (0.94) & 4.1 (0.72) & 3.25 (1.21) & 4.15 (1.04)\\
\hspace{1em}snail1-photo-grey & 4.57 (0.6) & 3 (1.03) &  & 3.63 (1.03)\\
\hspace{1em}snail2-photo-colour & 4.55 (0.69) & 3.95 (1.1) & 4.25 (0.72) & 4.24 (1)\\
\hspace{1em}snail2-photo-grey & 4.2 (1.2) & 3.5 (1.32) &  & 3.95 (1.09)\\
\hspace{1em}snail3-photo-colour & 4.14 (1.24) & 4.05 (1.2) & 2.95 (1.2) & 3.5 (1.1)\\
\hspace{1em}snail3-photo-grey & 4.29 (1.04) & 3.7 (1.06) &  & 4.05 (0.79)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{snake}}\\
\hspace{1em}snake1-photo-colour & 4.1 (1.45) & 3.05 (1.17) & 2.82 (0.91) & 3.65 (1.09)\\
\hspace{1em}snake1-photo-grey & 4 (1.29) & 3.1 (0.94) &  & 3.55 (1)\\
\hspace{1em}snake2-photo-colour & 4.38 (1.02) & 2.95 (1.1) & 2.6 (1.23) & 3.45 (0.94)\\
\hspace{1em}snake2-photo-grey & 3.77 (1.48) & 2.65 (0.99) &  & 3.86 (1.11)\\
\hspace{1em}snake3-photo-colour & 3.5 (1.41) & 3.05 (0.97) & 2.71 (1.15) & 3.57 (1.03)\\
\hspace{1em}snake3-photo-grey & 3.5 (1.41) & 3.08 (1.18) &  & 3.5 (0.96)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{snowman}}\\
\hspace{1em}snowman1-photo-colour & 4.25 (1.07) & 2.41 (1.18) & 3.73 (1.52) & 3.05 (1.19)\\
\hspace{1em}snowman1-photo-grey & 4.17 (0.99) & 2.33 (1.15) &  & 3.6 (1.19)\\
\hspace{1em}snowman2-photo-colour & 4.14 (1.28) & 3.4 (1.14) & 4.4 (1.05) & 3.9 (0.91)\\
\hspace{1em}snowman2-photo-grey & 4.05 (1.25) & 2.6 (1.14) &  & 4.1 (0.94)\\
\hspace{1em}snowman3-photo-colour & 4.23 (1.02) & 3.05 (1.12) & 4.29 (1.23) & 3.33 (0.97)\\
\hspace{1em}snowman3-photo-grey & 3.74 (1.39) & 2.88 (1.19) &  & 2.68 (1.21)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{socks}}\\
\hspace{1em}socks1-photo-colour & 4.9 (0.45) & 2.27 (1.12) & 2 (1.38) & 2.9 (1.29)\\
\hspace{1em}socks1-photo-grey & 4.8 (0.81) & 1.81 (0.87) &  & 4.05 (1.1)\\
\hspace{1em}socks2-photo-colour & 4.81 (0.87) & 2.05 (0.94) & 1.65 (0.99) & 3.55 (1.39)\\
\hspace{1em}socks2-photo-grey & 4.91 (0.43) & 2 (0.86) &  & 3.29 (1.45)\\
\hspace{1em}socks3-photo-colour & 5 (0) & 2.67 (1.35) & 1.9 (1.34) & 3.14 (1.2)\\
\hspace{1em}socks3-photo-grey & 4.73 (0.88) & 2.25 (1.26) &  & 3.04 (1.19)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{spider}}\\
\hspace{1em}spider1-photo-colour & 4.37 (1.13) & 4 (0.77) & 3.38 (1.16) & 3.3 (1.45)\\
\hspace{1em}spider1-photo-grey & 4.35 (0.99) & 3.68 (1.21) &  & 3.15 (1.27)\\
\hspace{1em}spider2-photo-colour & 4.59 (0.85) & 4.25 (0.91) & 3.2 (1.2) & 3.33 (1.49)\\
\hspace{1em}spider2-photo-grey & 4.48 (0.75) & 3.95 (1.1) &  & 2.85 (1.04)\\
\hspace{1em}spider3-photo-colour & 4.05 (1.17) & 4.54 (0.93) & 3.5 (1.38) & 2.27 (1.39)\\
\hspace{1em}spider3-photo-grey & 4.18 (1.22) & 4.05 (1.09) &  & 3.14 (1.24)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{spoon}}\\
\hspace{1em}spoon1-photo-colour & 4.95 (0.22) & 2.65 (1.42) & 3.85 (1.46) & 4.37 (0.85)\\
\hspace{1em}spoon1-photo-grey & 4.73 (0.88) & 2.5 (1.24) &  & 4.35 (0.88)\\
\hspace{1em}spoon2-photo-colour & 4.6 (0.68) & 2.7 (1.26) & 2.95 (1.39) & 3.82 (1.14)\\
\hspace{1em}spoon2-photo-grey & 4.9 (0.31) & 2.55 (1.1) &  & 3.67 (1.28)\\
\hspace{1em}spoon3-photo-colour & 4.92 (0.28) & 2.14 (1.28) & 3.64 (1.43) & 4.3 (1.06)\\
\hspace{1em}spoon3-photo-grey & 4.76 (0.54) & 2.62 (1.24) &  & 4.36 (1.09)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{stool}}\\
\hspace{1em}stool1-photo-colour & 3.5 (1.3) & 2.85 (1.04) & 2.85 (1.18) & 2.45 (1.36)\\
\hspace{1em}stool1-photo-grey & 3.52 (1.25) & 2.35 (0.88) &  & 1.93 (1.05)\\
\hspace{1em}stool2-photo-colour & 4.3 (0.8) & 3.1 (1.02) & 2.8 (1.4) & 3.71 (1.19)\\
\hspace{1em}stool2-photo-grey & 4.3 (0.86) & 2.55 (1) &  & 3.23 (1.15)\\
\hspace{1em}stool3-photo-colour & 4.19 (0.93) & 2.86 (1.15) & 2.24 (1.26) & 3.14 (1.21)\\
\hspace{1em}stool3-photo-grey & 4.42 (0.65) & 2.32 (0.78) &  & 3.41 (1.22)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{swan}}\\
\hspace{1em}swan1-photo-colour & 4.62 (0.59) & 3.45 (1.28) & 4.4 (0.99) & 4.27 (1.01)\\
\hspace{1em}swan1-photo-grey & 3.91 (1.11) & 3.2 (1.15) &  & 3.65 (1.35)\\
\hspace{1em}swan2-photo-colour & 3.9 (1.17) & 4.15 (0.88) & 4.45 (1.1) & 4.64 (0.58)\\
\hspace{1em}swan2-photo-grey & 4.3 (1.03) & 3.9 (0.85) &  & 3.81 (1.17)\\
\hspace{1em}swan3-photo-colour & 4 (1.35) & 2.59 (1.22) & 4 (1.2) & 4.45 (0.96)\\
\hspace{1em}swan3-photo-grey & 4.33 (0.8) & 2.62 (1.16) &  & 4.05 (0.84)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{swing}}\\
\hspace{1em}swing1-photo-colour & 4.03 (1.38) & 2.33 (1.06) & 3.05 (1.28) & 3.65 (0.93)\\
\hspace{1em}swing1-photo-grey & 4.25 (1.12) & 2.09 (0.87) &  & 2.95 (1.28)\\
\hspace{1em}swing2-photo-colour & 4.05 (1.25) & 2.35 (0.88) & 2.8 (1.28) & 3.14 (1.35)\\
\hspace{1em}swing2-photo-grey & 4.05 (1.2) & 1.9 (0.64) &  & 2.95 (1.39)\\
\hspace{1em}swing3-photo-colour & 3.45 (1.41) & 2.72 (1.14) & 3.28 (1.34) & 2.86 (1.28)\\
\hspace{1em}swing3-photo-grey & 3.82 (1.37) & 2.14 (0.83) &  & 3.29 (0.96)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{table}}\\
\hspace{1em}table1-photo-colour & 4.91 (0.43) & 2.15 (1.27) & 2.8 (1.36) & 3.95 (1)\\
\hspace{1em}table1-photo-grey & 4.9 (0.44) & 1.9 (0.91) &  & 3.47 (1.14)\\
\hspace{1em}table2-photo-colour & 4.95 (0.22) & 1.95 (1.15) & 1.8 (1.32) & 3.52 (1.36)\\
\hspace{1em}table2-photo-grey & 4.8 (0.62) & 1.5 (0.95) &  & 3.32 (1.13)\\
\hspace{1em}table3-photo-colour & 4.14 (1.24) & 3.48 (1.08) & 2.19 (1.21) & 2.27 (0.98)\\
\hspace{1em}table3-photo-grey & 4.29 (0.91) & 3.27 (1.12) &  & 2.23 (0.97)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{thimble}}\\
\hspace{1em}thimble1-photo-colour & 3.4 (1.64) & 2.87 (1.04) & 3.4 (1.31) & 3.95 (1.28)\\
\hspace{1em}thimble1-photo-grey & 3.45 (1.64) & 2.4 (1.1) &  & 3.91 (1.38)\\
\hspace{1em}thimble2-photo-colour & 3.25 (1.62) & 3.86 (1.13) & 2.64 (1.47) & 3.7 (1.03)\\
\hspace{1em}thimble2-photo-grey & 3.15 (1.14) & 3.33 (1.46) &  & 4.55 (0.89)\\
\hspace{1em}thimble3-photo-colour & 2.73 (1.39) & 3.09 (1.34) & 3.41 (1.4) & 4.08 (1.35)\\
\hspace{1em}thimble3-photo-grey & 2.86 (1.56) & 2.59 (1.3) &  & 3.48 (1.6)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{thumb}}\\
\hspace{1em}thumb1-photo-colour & 4.9 (0.31) & 2.95 (1.28) & 3.2 (1.44) & 3.77 (1.34)\\
\hspace{1em}thumb1-photo-grey & 5 (0) & 2.63 (1.22) & 1.82 (0.87) & 3.52 (1.29)\\
\hspace{1em}thumb2-photo-colour & 4.55 (0.69) & 2.57 (1.12) & 2.81 (1.54) & 4.15 (0.99)\\
\hspace{1em}thumb2-photo-grey & 4.67 (0.91) & 3.05 (0.9) &  & 3.3 (1.45)\\
\hspace{1em}thumb3-photo-colour & 4.67 (0.73) & 3.32 (1.09) & 2.77 (1.34) & 3.52 (1.44)\\
\hspace{1em}thumb3-photo-grey & 4.43 (1.08) & 3.14 (1.32) &  & 4.04 (1.12)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{tiger}}\\
\hspace{1em}tiger1-photo-colour & 3.45 (1.71) & 4.1 (0.91) & 4.45 (0.76) & 4.55 (0.83)\\
\hspace{1em}tiger1-photo-grey & 4.1 (1.18) & 3.55 (1.23) &  & 3.53 (1.07)\\
\hspace{1em}tiger2-photo-colour & 4.15 (1.18) & 4.05 (0.83) & 4.65 (0.59) & 4.57 (0.81)\\
\hspace{1em}tiger2-photo-grey & 3.6 (1.35) & 3.2 (1.28) &  & 4.18 (0.73)\\
\hspace{1em}tiger3-photo-colour & 4 (1.26) & 4.05 (1.2) & 4.14 (1.06) & 4.59 (0.67)\\
\hspace{1em}tiger3-photo-grey & 3.75 (1.57) & 3.45 (1.22) &  & 4.18 (0.85)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{toaster}}\\
\hspace{1em}toaster1-photo-colour & 4.7 (0.66) & 2.9 (1.02) & 2.6 (1.35) & 3.32 (1.13)\\
\hspace{1em}toaster1-photo-grey & 4.9 (0.31) & 2.87 (1.07) & 2.55 (1.69) & 3.48 (0.93)\\
\hspace{1em}toaster2-photo-colour & 4.75 (0.55) & 3.05 (1.28) & 1.9 (1.04) & 3.95 (1.23)\\
\hspace{1em}toaster2-photo-grey & 4.4 (0.75) & 3.68 (1.13) &  & 4.1 (0.91)\\
\hspace{1em}toaster3-photo-colour & 4.57 (0.6) & 3.36 (1.05) & 1.73 (1.2) & 3.19 (1.33)\\
\hspace{1em}toaster3-photo-grey & 4.41 (0.59) & 3.5 (0.74) &  & 3.12 (1.3)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{tomato}}\\
\hspace{1em}tomato1-photo-colour & 4.85 (0.49) & 2.5 (1.36) & 4.35 (1.14) & 4.67 (0.58)\\
\hspace{1em}tomato1-photo-grey & 4.5 (0.95) & 2.2 (1.15) &  & 3 (1.27)\\
\hspace{1em}tomato2-photo-colour & 4.76 (0.54) & 3.45 (1.3) & 4.18 (0.91) & 4.3 (0.73)\\
\hspace{1em}tomato2-photo-grey & 4.3 (1.08) & 2.43 (0.93) &  & 3.05 (1.32)\\
\hspace{1em}tomato3-photo-colour & 4.35 (0.93) & 2.36 (1.22) & 4.41 (0.85) & 4.92 (0.28)\\
\hspace{1em}tomato3-photo-grey & 4.38 (0.97) & 2.27 (1.16) &  & 3.14 (1.39)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{train}}\\
\hspace{1em}train1-photo-colour & 4.36 (0.9) & 4.55 (0.6) & 2.6 (1.35) & 3.3 (1.69)\\
\hspace{1em}train1-photo-grey & 4.05 (1.02) & 4.1 (1.33) &  & 2.57 (1.1)\\
\hspace{1em}train2-photo-colour & 4.15 (0.93) & 4.3 (0.47) & 2.3 (1.53) & 2.81 (1.25)\\
\hspace{1em}train2-photo-grey & 3.85 (1.14) & 3.5 (1.5) &  & 3.05 (1.25)\\
\hspace{1em}train3-photo-colour & 4.52 (0.68) & 4 (1.26) & 2.57 (1.36) & 2.91 (0.87)\\
\hspace{1em}train3-photo-grey & 4.42 (1.02) & 3.95 (1) &  & 3.18 (1.22)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{tree}}\\
\hspace{1em}tree1-photo-colour & 4.9 (0.3) & 4.05 (1.28) & 3.7 (1.03) & 3.8 (1.24)\\
\hspace{1em}tree1-photo-grey & 4.64 (0.95) & 4.2 (0.83) &  & 3.55 (1.23)\\
\hspace{1em}tree2-photo-colour & 4.9 (0.31) & 4.1 (1.07) & 4.05 (1.19) & 4.59 (0.59)\\
\hspace{1em}tree2-photo-grey & 4.9 (0.31) & 3.4 (1.1) &  & 3.67 (1.46)\\
\hspace{1em}tree3-photo-colour & 4.88 (0.34) & 3.64 (1.18) & 4.14 (0.94) & 4.05 (1.21)\\
\hspace{1em}tree3-photo-grey & 4.38 (1.07) & 3.29 (1.27) &  & 3.27 (1.12)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{trumpet}}\\
\hspace{1em}trumpet1-photo-colour & 3.3 (1.59) & 3.6 (1.14) & 3.5 (0.95) & 3.77 (1.11)\\
\hspace{1em}trumpet1-photo-grey & 3.55 (1.54) & 3.43 (1.01) & 2.82 (0.98) & 3.81 (1.17)\\
\hspace{1em}trumpet2-photo-colour & 3.8 (1.2) & 2.9 (1.3) & 4.33 (0.97) & 4.9 (0.31)\\
\hspace{1em}trumpet2-photo-grey & 3.5 (1.54) & 3.5 (1.01) &  & 4.05 (1)\\
\hspace{1em}trumpet3-photo-colour & 3.38 (1.53) & 3.36 (0.85) & 3.95 (1.25) & 4.19 (0.81)\\
\hspace{1em}trumpet3-photo-grey & 2.77 (1.31) & 3.27 (0.83) &  & 4.12 (1.12)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{turtle}}\\
\hspace{1em}turtle1-photo-colour & 3.45 (1.43) & 3.25 (1.12) & 3.65 (1.14) & 3.41 (1.22)\\
\hspace{1em}turtle1-photo-grey & 3.65 (1.39) & 3.43 (0.97) & 2 (1.1) & 3.24 (1.18)\\
\hspace{1em}turtle2-photo-colour & 3.95 (1.19) & 3.24 (1.41) & 4.29 (1.01) & 3.1 (1.37)\\
\hspace{1em}turtle2-photo-grey & 3.35 (1.39) & 3.68 (1.21) &  & 2.55 (1.39)\\
\hspace{1em}turtle3-photo-colour & 3.52 (1.44) & 4.09 (0.92) & 4.18 (1.1) & 3.81 (1.54)\\
\hspace{1em}turtle3-photo-grey & 3.36 (1.43) & 3.35 (1.11) &  & 3.5 (1.5)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{vest}}\\
\hspace{1em}vest1-photo-colour & 4.05 (1.28) & 1.95 (1.13) & 1.86 (1.21) & 1.85 (1.09)\\
\hspace{1em}vest1-photo-grey & 3.73 (1.26) & 2 (1.22) &  & 2.7 (1.38)\\
\hspace{1em}vest2-photo-colour & 4.05 (1.16) & 2.05 (0.94) & 2.05 (1.15) & 2.2 (1.28)\\
\hspace{1em}vest2-photo-grey & 4 (1.15) & 2.1 (0.91) &  & 2.76 (1.48)\\
\hspace{1em}vest3-photo-colour & 3.68 (1.25) & 3.05 (1.05) & 2.18 (1.1) & 2.33 (1.2)\\
\hspace{1em}vest3-photo-grey & 3.23 (1.38) & 2.8 (1.15) &  & 1.95 (1.17)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{violin}}\\
\hspace{1em}violin1-photo-colour & 4 (0.89) & 3.7 (1.17) & 4.2 (0.95) & 4.47 (1.07)\\
\hspace{1em}violin1-photo-grey & 3.36 (1.47) & 3.1 (0.91) &  & 4 (1.12)\\
\hspace{1em}violin2-photo-colour & 3.6 (1.54) & 3.4 (1.14) & 4.05 (1.1) & 4.5 (0.91)\\
\hspace{1em}violin2-photo-grey & 3.7 (1.53) & 3.25 (0.85) &  & 4.19 (0.87)\\
\hspace{1em}violin3-photo-colour & 3.08 (1.56) & 3.41 (1.22) & 3.77 (1.27) & 4.05 (1)\\
\hspace{1em}violin3-photo-grey & 3.57 (1.21) & 3.52 (1.33) &  & 3.32 (1.17)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{watch}}\\
\hspace{1em}watch1-photo-colour & 4.6 (0.5) & 3.05 (1.05) & 2.85 (1.5) & 3.59 (1.18)\\
\hspace{1em}watch1-photo-grey & 4.8 (0.7) & 2.87 (0.97) & 2.45 (1.63) & 3.19 (1.08)\\
\hspace{1em}watch2-photo-colour & 4.85 (0.37) & 3.33 (0.97) & 1.86 (1.2) & 3.8 (1.06)\\
\hspace{1em}watch2-photo-grey & 4.7 (0.66) & 3.36 (1.14) &  & 3.15 (1.31)\\
\hspace{1em}watch3-photo-colour & 4.43 (0.81) & 3.09 (1.15) & 2.05 (1.17) & 3.43 (1.12)\\
\hspace{1em}watch3-photo-grey & 4.41 (0.85) & 3.23 (1.02) &  & 3.83 (1.2)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{well}}\\
\hspace{1em}well1-photo-colour & 3.71 (1.1) & 3.9 (1.25) & 3.45 (1.36) & 4.23 (1.14)\\
\hspace{1em}well1-photo-grey & 2.95 (1.43) & 3.65 (0.75) &  & 4.1 (1.02)\\
\hspace{1em}well2-photo-colour & 3.25 (1.52) & 3.65 (1.23) & 3 (1.69) & 4 (1.2)\\
\hspace{1em}well2-photo-grey & 3.95 (1.1) & 3.45 (0.94) &  & 4.05 (1.07)\\
\hspace{1em}well3-photo-colour & 2.88 (1.42) & 3.91 (0.75) & 3 (1.07) & 3.86 (1.08)\\
\hspace{1em}well3-photo-grey & 3.14 (1.31) & 3.67 (1.11) &  & 3.59 (1.1)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{whistle}}\\
\hspace{1em}whistle1-photo-colour & 4.05 (1.15) & 2.75 (1.33) & 2.9 (1.21) & 4.27 (0.83)\\
\hspace{1em}whistle1-photo-grey & 4.25 (1.21) & 2.2 (1.13) & 3 (1) & 4.24 (0.94)\\
\hspace{1em}whistle2-photo-colour & 4.3 (1.13) & 1.95 (0.8) & 2.9 (1.18) & 4.35 (0.99)\\
\hspace{1em}whistle2-photo-grey & 4 (1.08) & 2.95 (1) &  & 4.25 (1.02)\\
\hspace{1em}whistle3-photo-colour & 3.43 (1.29) & 2.18 (1.01) & 3.27 (1.35) & 4.29 (1.06)\\
\hspace{1em}whistle3-photo-grey & 3.48 (1.34) & 2.55 (0.96) &  & 4.46 (1.14)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{window}}\\
\hspace{1em}window1-photo-colour & 4.7 (0.57) & 2.75 (1.25) & 2.3 (1.22) & 2.82 (1.26)\\
\hspace{1em}window1-photo-grey & 4.9 (0.45) & 2.87 (1.11) & 1.91 (1.3) & 2.81 (1.17)\\
\hspace{1em}window2-photo-colour & 4.75 (0.79) & 3.62 (0.97) & 2 (1.14) & 4 (1.12)\\
\hspace{1em}window2-photo-grey & 4.55 (0.69) & 3.45 (1.3) &  & 3.4 (1.19)\\
\hspace{1em}window3-photo-colour & 4.57 (0.6) & 2.64 (0.9) & 2.27 (1.2) & 3.05 (1.32)\\
\hspace{1em}window3-photo-grey & 4.82 (0.39) & 2.64 (0.9) &  & 3.92 (0.72)\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{zebra}}\\
\hspace{1em}zebra1-photo-colour & 3.41 (1.56) & 3.8 (1.11) & 4.75 (0.44) & 4.6 (0.6)\\
\hspace{1em}zebra1-photo-grey & 4.29 (1.06) & 3.25 (1.12) &  & 4.13 (1.17)\\
\hspace{1em}zebra2-photo-colour & 3.9 (1.37) & 3.8 (1.01) & 4.55 (0.89) & 4.52 (0.81)\\
\hspace{1em}zebra2-photo-grey & 3.45 (1.5) & 3.9 (1.33) &  & 4.73 (0.55)\\
\hspace{1em}zebra3-photo-colour & 4.1 (1.26) & 3.62 (1.07) & 4.76 (0.44) & 4.23 (1.11)\\
\hspace{1em}zebra3-photo-grey & 3.5 (1.59) & 3.23 (1.23) &  & 4.68 (0.65)\\*
\end{longtable}
\endgroup{}

\end{document}
